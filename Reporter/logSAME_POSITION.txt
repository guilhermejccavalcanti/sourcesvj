############################

C:\Users\user\Desktop\gjcc\amostra\projects\robolectric\revisions\rev_0700222_5410f9a\rev_left_0700222\src\com\xtremelabs\droidsugar\view\FakeView.java,C:\Users\user\Desktop\gjcc\amostra\projects\robolectric\revisions\rev_0700222_5410f9a\rev_base_fe999f5\src\com\xtremelabs\droidsugar\view\FakeView.java,C:\Users\user\Desktop\gjcc\amostra\projects\robolectric\revisions\rev_0700222_5410f9a\rev_right_5410f9a\src\com\xtremelabs\droidsugar\view\FakeView.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
layoutParams
=======
new ViewGroup.LayoutParams(0, 0)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public ViewGroup.LayoutParams getLayoutParams() {
    return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\robolectric\revisions\rev_0700222_5410f9a\rev_left_0700222\src\com\xtremelabs\droidsugar\view\FakeView.java
layoutParams
=======
new ViewGroup.LayoutParams(0, 0)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\robolectric\revisions\rev_0700222_5410f9a\rev_right_5410f9a\src\com\xtremelabs\droidsugar\view\FakeView.java
;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_90690bb_7fe6cf7\rev_left_90690bb\DesktopStatistics\src\org\gephi\desktop\statistics\StatisticsFrontEnd.java,C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_90690bb_7fe6cf7\rev_base_d692b52\DesktopStatistics\src\org\gephi\desktop\statistics\StatisticsFrontEnd.java,C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_90690bb_7fe6cf7\rev_right_7fe6cf7\DesktopStatistics\src\org\gephi\desktop\statistics\StatisticsFrontEnd.java
CONCLUSAO: FP. MUDANÇAS COMPLEMENTARES (REFATORAMENTO?).
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (report != null) {
        SwingUtilities.invokeLater(new Runnable() {
            public void run() {
              SimpleHTMLReport dialog = new SimpleHTMLReport(WindowManager.getDefault().getMainWindow(), report);
            }
        });
      }
=======
SwingUtilities.invokeLater(new Runnable() {
          public void run() {
            StatisticsReportPanel dialog = new StatisticsReportPanel(WindowManager.getDefault().getMainWindow(), report);
          }
      });
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void showReport() {
    final String report = currentModel.getReport(statisticsUI);
    if (report != null) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_90690bb_7fe6cf7\rev_left_90690bb\DesktopStatistics\src\org\gephi\desktop\statistics\StatisticsFrontEnd.java
if (report != null) {
        SwingUtilities.invokeLater(new Runnable() {
            public void run() {
              SimpleHTMLReport dialog = new SimpleHTMLReport(WindowManager.getDefault().getMainWindow(), report);
            }
        });
      }
=======
SwingUtilities.invokeLater(new Runnable() {
          public void run() {
            StatisticsReportPanel dialog = new StatisticsReportPanel(WindowManager.getDefault().getMainWindow(), report);
          }
      });
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_90690bb_7fe6cf7\rev_right_7fe6cf7\DesktopStatistics\src\org\gephi\desktop\statistics\StatisticsFrontEnd.java

      if (report != null) {
        SwingUtilities.invokeLater(new Runnable() {
            public void run() {
              SimpleHTMLReport dialog = new SimpleHTMLReport(WindowManager.getDefault().getMainWindow(), report);
            }
        });
      }
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hector\revisions\rev_f488227_c832174\rev_left_f488227\src\test\java\me\prettyprint\cassandra\service\KeyspaceTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\hector\revisions\rev_f488227_c832174\rev_base_a720902\src\test\java\me\prettyprint\cassandra\service\KeyspaceTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\hector\revisions\rev_f488227_c832174\rev_right_c832174\src\test\java\me\prettyprint\cassandra\service\KeyspaceTest.java
CONCLUSAO: FP. NÃO HOUVE MUDANÇAS DE UM DOS DEVS (BUG?)
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
FailoverPolicy.ON_FAIL_TRY_ALL_AVAILABLE
=======
connectionManager
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Before public void setupCase() throws IllegalStateException, PoolExhaustedException, Exception {
    super.setupClient();
    keyspace = new KeyspaceServiceImpl("Keyspace1", new QuorumAllConsistencyLevelPolicy(), connectionManager, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hector\revisions\rev_f488227_c832174\rev_left_f488227\src\test\java\me\prettyprint\cassandra\service\KeyspaceTest.java
FailoverPolicy.ON_FAIL_TRY_ALL_AVAILABLE
=======
connectionManager
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hector\revisions\rev_f488227_c832174\rev_right_c832174\src\test\java\me\prettyprint\cassandra\service\KeyspaceTest.java
);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_3ee53a1_d5fbd56\rev_left_3ee53a1\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_3ee53a1_d5fbd56\rev_base_f5a8774\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_3ee53a1_d5fbd56\rev_right_d5fbd56\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
this.acceptors.add(plainTextAcceptor)
=======
this.acceptor = new Acceptor(host, port, processors, sendBufferSize, recvBufferSize, metrics)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void start() throws IOException, InterruptedException {
    logger.info("Starting {} processor threads", numProcessorThreads);
    for (int i = 0; i < numProcessorThreads; i++) {
      processors.add(i, new Processor(i, maxRequestSize, requestResponseChannel, metrics));
      Utils.newThread("ambry-processor-" + port + " " + i, processors.get(i), false).start();
    }
    requestResponseChannel.addResponseListener(new ResponseListener() {
        @Override public void onResponse(int processorId) {
          processors.get(processorId).wakeup();
        }
    });
    logger.info("Starting acceptor threads");
    Acceptor plainTextAcceptor = new Acceptor(host, port, processors, sendBufferSize, recvBufferSize);
    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_3ee53a1_d5fbd56\rev_left_3ee53a1\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java
this.acceptors.add(plainTextAcceptor)
=======
this.acceptor = new Acceptor(host, port, processors, sendBufferSize, recvBufferSize, metrics)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_3ee53a1_d5fbd56\rev_right_d5fbd56\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java
;
    Utils.newThread("ambry-acceptor", plainTextAcceptor, false).start();
    Port sslPort = ports.get(PortType.SSL);
    if (sslPort != null) {
      SSLAcceptor sslAcceptor = new SSLAcceptor(host, sslPort.getPort(), processors, sendBufferSize, recvBufferSize);
      acceptors.add(sslAcceptor);
      Utils.newThread("ambry-sslacceptor", sslAcceptor, false).start();
    }
    for (Acceptor acceptor : acceptors) {
      acceptor.awaitStartup();
    }
    logger.info("Started server");
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-messageformat\src\main\java\com.github.ambry.messageformat\MessageFormatSend.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_base_faf5e48\ambry-messageformat\src\main\java\com.github.ambry.messageformat\MessageFormatSend.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-messageformat\src\main\java\com.github.ambry.messageformat\MessageFormatSend.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
long startTime = SystemTime.getInstance().milliseconds();
=======
this.metrics = metrics;
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public MessageFormatSend(MessageReadSet readSet, MessageFormatFlags flag, MessageFormatMetrics metrics) throws IOException, MessageFormatException {
    this.readSet = readSet;
    this.flag = flag;
    totalSizeToWrite = 0;
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-messageformat\src\main\java\com.github.ambry.messageformat\MessageFormatSend.java
long startTime = SystemTime.getInstance().milliseconds();
=======
this.metrics = metrics;
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-messageformat\src\main\java\com.github.ambry.messageformat\MessageFormatSend.java

    calculateOffsets();
    metrics.calculateOffsetMessageSendTime.update(SystemTime.getInstance().milliseconds() - startTime);
    sizeWritten = 0;
    currentWriteIndex = 0;
    sizeWrittenFromCurrentIndex = 0;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_base_faf5e48\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE. EXEMPLO
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
onSendStart()
=======
setStartSendTime(SystemTime.getInstance().milliseconds())
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void processNewResponses() throws InterruptedException, IOException {
    SocketServerResponse curr = (SocketServerResponse)channel.receiveResponse(id);
    while (curr != null){
      curr.onDequeueFromResponseQueue();
      curr.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java
onSendStart()
=======
setStartSendTime(SystemTime.getInstance().milliseconds())
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java
;
      SocketServerRequest request = (SocketServerRequest)curr.getRequest();
      SelectionKey key = (SelectionKey)request.getRequestKey();
      try {
        if (curr.getPayload() == null) {
          logger.trace("Socket server received no response and hence closing the connection");
          close(key);
        }
        else {
          logger.trace("Socket server received response to send, registering for write: {}", curr);
          key.interestOps(SelectionKey.OP_WRITE);
          key.attach(curr);
          metrics.sendInFlight.inc();
        }
      }
      catch (CancelledKeyException e) {
        logger.debug("Ignoring response for closed socket.");
        close(key);
      }
      finally {
        curr = (SocketServerResponse)channel.receiveResponse(id);
      }
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_base_faf5e48\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
getStartTimeInMs()
=======
getStartTime()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void handlePutRequest(Request request) throws IOException, InterruptedException {
    PutRequest putRequest = PutRequest.readFrom(new DataInputStream(request.getInputStream()), clusterMap);
    metrics.putBlobRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
    metrics.putBlobRequestRate.mark();
    long startTime = SystemTime.getInstance().milliseconds();
    PutResponse response = null;
    try {
      ServerErrorCode error = validateRequest(putRequest.getBlobId().getPartition(), true);
      if (error != ServerErrorCode.No_Error) {
        logger.error("Validating put request failed with error {}", error);
        response = new PutResponse(putRequest.getCorrelationId(), putRequest.getClientId(), error);
      }
      else {
        MessageFormatInputStream stream = new PutMessageFormatInputStream(putRequest.getBlobId(), putRequest.getBlobProperties(), putRequest.getUsermetadata(), putRequest.getData(), putRequest.getBlobProperties().getBlobSize());
        MessageInfo info = new MessageInfo(putRequest.getBlobId(), stream.getSize(), putRequest.getBlobProperties().getTimeToLiveInMs());
        ArrayList<MessageInfo> infoList = new ArrayList<MessageInfo>();
        infoList.add(info);
        MessageFormatWriteSet writeset = new MessageFormatWriteSet(stream, infoList);
        Store storeToPut = storeManager.getStore(putRequest.getBlobId().getPartition());
        storeToPut.put(writeset);
        response = new PutResponse(putRequest.getCorrelationId(), putRequest.getClientId(), ServerErrorCode.No_Error);
      }
    }
    catch (StoreException e) {
      logger.error("Store exception on a put with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == StoreErrorCodes.Already_Exist) 
        metrics.idAlreadyExistError.inc();
      else 
        if (e.getErrorCode() == StoreErrorCodes.IOError) 
          metrics.storeIOError.inc();
        else 
          metrics.unExpectedStorePutError.inc();
      response = new PutResponse(putRequest.getCorrelationId(), putRequest.getClientId(), ErrorMapping.getStoreErrorMapping(e.getErrorCode()));
    }
    catch (Exception e) {
      logger.error("Unknown exception on a put {} ", e);
      response = new PutResponse(putRequest.getCorrelationId(), putRequest.getClientId(), ServerErrorCode.Unknown_Error);
    }
    finally {
      metrics.putBlobProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
    }
    requestResponseChannel.sendResponse(response, request, new HistogramMeasurement(metrics.putBlobResponseQueueTime), new HistogramMeasurement(metrics.putBlobSendTime));
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_base_faf5e48\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
getStartTimeInMs()
=======
getStartTime()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void handleGetRequest(Request request) throws IOException, InterruptedException {
    GetRequest getRequest = GetRequest.readFrom(new DataInputStream(request.getInputStream()), clusterMap);
    HistogramMeasurement responseQueueMeasurement = null;
    HistogramMeasurement responseSendMeasurement = null;
    if (getRequest.getMessageFormatFlag() == MessageFormatFlags.Blob) {
      metrics.getBlobRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
      metrics.getBlobRequestRate.mark();
      responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobResponseQueueTime);
      responseSendMeasurement = new HistogramMeasurement(metrics.getBlobSendTime);
    }
    else 
      if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobProperties) {
        metrics.getBlobPropertiesRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
        metrics.getBlobPropertiesRequestRate.mark();
        responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobPropertiesResponseQueueTime);
        responseSendMeasurement = new HistogramMeasurement(metrics.getBlobPropertiesSendTime);
      }
      else 
        if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobUserMetadata) {
          metrics.getBlobUserMetadataRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
          metrics.getBlobUserMetadataRequestRate.mark();
          responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobUserMetadataResponseQueueTime);
          responseSendMeasurement = new HistogramMeasurement(metrics.getBlobUserMetadataSendTime);
        }
    long startTime = SystemTime.getInstance().milliseconds();
    GetResponse response = null;
    try {
      ServerErrorCode error = validateRequest(getRequest.getPartition(), false);
      if (error != ServerErrorCode.No_Error) {
        logger.error("Validating get request failed with error {}", error);
        response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), error);
      }
      else {
        Store storeToGet = storeManager.getStore(getRequest.getPartition());
        StoreInfo info = storeToGet.get(getRequest.getBlobIds());
        Send blobsToSend = new MessageFormatSend(info.getMessageReadSet(), getRequest.getMessageFormatFlag(), messageFormatMetrics);
        response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), info.getMessageReadSetInfo(), blobsToSend, ServerErrorCode.No_Error);
      }
    }
    catch (StoreException e) {
      logger.error("Store exception on a get with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == StoreErrorCodes.ID_Not_Found) 
        metrics.idNotFoundError.inc();
      else 
        if (e.getErrorCode() == StoreErrorCodes.TTL_Expired) 
          metrics.ttlExpiredError.inc();
        else 
          if (e.getErrorCode() == StoreErrorCodes.ID_Deleted) 
            metrics.idDeletedError.inc();
          else 
            metrics.unExpectedStoreGetError.inc();
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ErrorMapping.getStoreErrorMapping(e.getErrorCode()));
    }
    catch (MessageFormatException e) {
      logger.error("Message format exception on a get with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == MessageFormatErrorCodes.Data_Corrupt) 
        metrics.dataCorruptError.inc();
      else 
        if (e.getErrorCode() == MessageFormatErrorCodes.Unknown_Format_Version) 
          metrics.unknownFormatError.inc();
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ErrorMapping.getMessageFormatErrorMapping(e.getErrorCode()));
    }
    catch (Exception e) {
      logger.error("Unknown exception on a get {}", e);
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ServerErrorCode.Unknown_Error);
    }
    finally {
      if (getRequest.getMessageFormatFlag() == MessageFormatFlags.Blob) 
        metrics.getBlobProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
      else 
        if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobProperties) 
          metrics.getBlobPropertiesProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
        else 
          if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobUserMetadata) 
            metrics.getBlobUserMetadataProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
    }
    requestResponseChannel.sendResponse(response, request, responseQueueMeasurement, responseSendMeasurement);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_base_faf5e48\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
getStartTimeInMs()
=======
getStartTime()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void handleGetRequest(Request request) throws IOException, InterruptedException {
    GetRequest getRequest = GetRequest.readFrom(new DataInputStream(request.getInputStream()), clusterMap);
    HistogramMeasurement responseQueueMeasurement = null;
    HistogramMeasurement responseSendMeasurement = null;
    if (getRequest.getMessageFormatFlag() == MessageFormatFlags.Blob) {
      metrics.getBlobRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
      metrics.getBlobRequestRate.mark();
      responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobResponseQueueTime);
      responseSendMeasurement = new HistogramMeasurement(metrics.getBlobSendTime);
    }
    else 
      if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobProperties) {
        metrics.getBlobPropertiesRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
        metrics.getBlobPropertiesRequestRate.mark();
        responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobPropertiesResponseQueueTime);
        responseSendMeasurement = new HistogramMeasurement(metrics.getBlobPropertiesSendTime);
      }
      else 
        if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobUserMetadata) {
          metrics.getBlobUserMetadataRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
          metrics.getBlobUserMetadataRequestRate.mark();
          responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobUserMetadataResponseQueueTime);
          responseSendMeasurement = new HistogramMeasurement(metrics.getBlobUserMetadataSendTime);
        }
    long startTime = SystemTime.getInstance().milliseconds();
    GetResponse response = null;
    try {
      ServerErrorCode error = validateRequest(getRequest.getPartition(), false);
      if (error != ServerErrorCode.No_Error) {
        logger.error("Validating get request failed with error {}", error);
        response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), error);
      }
      else {
        Store storeToGet = storeManager.getStore(getRequest.getPartition());
        StoreInfo info = storeToGet.get(getRequest.getBlobIds());
        Send blobsToSend = new MessageFormatSend(info.getMessageReadSet(), getRequest.getMessageFormatFlag(), messageFormatMetrics);
        response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), info.getMessageReadSetInfo(), blobsToSend, ServerErrorCode.No_Error);
      }
    }
    catch (StoreException e) {
      logger.error("Store exception on a get with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == StoreErrorCodes.ID_Not_Found) 
        metrics.idNotFoundError.inc();
      else 
        if (e.getErrorCode() == StoreErrorCodes.TTL_Expired) 
          metrics.ttlExpiredError.inc();
        else 
          if (e.getErrorCode() == StoreErrorCodes.ID_Deleted) 
            metrics.idDeletedError.inc();
          else 
            metrics.unExpectedStoreGetError.inc();
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ErrorMapping.getStoreErrorMapping(e.getErrorCode()));
    }
    catch (MessageFormatException e) {
      logger.error("Message format exception on a get with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == MessageFormatErrorCodes.Data_Corrupt) 
        metrics.dataCorruptError.inc();
      else 
        if (e.getErrorCode() == MessageFormatErrorCodes.Unknown_Format_Version) 
          metrics.unknownFormatError.inc();
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ErrorMapping.getMessageFormatErrorMapping(e.getErrorCode()));
    }
    catch (Exception e) {
      logger.error("Unknown exception on a get {}", e);
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ServerErrorCode.Unknown_Error);
    }
    finally {
      if (getRequest.getMessageFormatFlag() == MessageFormatFlags.Blob) 
        metrics.getBlobProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
      else 
        if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobProperties) 
          metrics.getBlobPropertiesProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
        else 
          if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobUserMetadata) 
            metrics.getBlobUserMetadataProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
    }
    requestResponseChannel.sendResponse(response, request, responseQueueMeasurement, responseSendMeasurement);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_base_faf5e48\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
getStartTimeInMs()
=======
getStartTime()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void handleGetRequest(Request request) throws IOException, InterruptedException {
    GetRequest getRequest = GetRequest.readFrom(new DataInputStream(request.getInputStream()), clusterMap);
    HistogramMeasurement responseQueueMeasurement = null;
    HistogramMeasurement responseSendMeasurement = null;
    if (getRequest.getMessageFormatFlag() == MessageFormatFlags.Blob) {
      metrics.getBlobRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
      metrics.getBlobRequestRate.mark();
      responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobResponseQueueTime);
      responseSendMeasurement = new HistogramMeasurement(metrics.getBlobSendTime);
    }
    else 
      if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobProperties) {
        metrics.getBlobPropertiesRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
        metrics.getBlobPropertiesRequestRate.mark();
        responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobPropertiesResponseQueueTime);
        responseSendMeasurement = new HistogramMeasurement(metrics.getBlobPropertiesSendTime);
      }
      else 
        if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobUserMetadata) {
          metrics.getBlobUserMetadataRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
          metrics.getBlobUserMetadataRequestRate.mark();
          responseQueueMeasurement = new HistogramMeasurement(metrics.getBlobUserMetadataResponseQueueTime);
          responseSendMeasurement = new HistogramMeasurement(metrics.getBlobUserMetadataSendTime);
        }
    long startTime = SystemTime.getInstance().milliseconds();
    GetResponse response = null;
    try {
      ServerErrorCode error = validateRequest(getRequest.getPartition(), false);
      if (error != ServerErrorCode.No_Error) {
        logger.error("Validating get request failed with error {}", error);
        response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), error);
      }
      else {
        Store storeToGet = storeManager.getStore(getRequest.getPartition());
        StoreInfo info = storeToGet.get(getRequest.getBlobIds());
        Send blobsToSend = new MessageFormatSend(info.getMessageReadSet(), getRequest.getMessageFormatFlag(), messageFormatMetrics);
        response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), info.getMessageReadSetInfo(), blobsToSend, ServerErrorCode.No_Error);
      }
    }
    catch (StoreException e) {
      logger.error("Store exception on a get with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == StoreErrorCodes.ID_Not_Found) 
        metrics.idNotFoundError.inc();
      else 
        if (e.getErrorCode() == StoreErrorCodes.TTL_Expired) 
          metrics.ttlExpiredError.inc();
        else 
          if (e.getErrorCode() == StoreErrorCodes.ID_Deleted) 
            metrics.idDeletedError.inc();
          else 
            metrics.unExpectedStoreGetError.inc();
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ErrorMapping.getStoreErrorMapping(e.getErrorCode()));
    }
    catch (MessageFormatException e) {
      logger.error("Message format exception on a get with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == MessageFormatErrorCodes.Data_Corrupt) 
        metrics.dataCorruptError.inc();
      else 
        if (e.getErrorCode() == MessageFormatErrorCodes.Unknown_Format_Version) 
          metrics.unknownFormatError.inc();
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ErrorMapping.getMessageFormatErrorMapping(e.getErrorCode()));
    }
    catch (Exception e) {
      logger.error("Unknown exception on a get {}", e);
      response = new GetResponse(getRequest.getCorrelationId(), getRequest.getClientId(), ServerErrorCode.Unknown_Error);
    }
    finally {
      if (getRequest.getMessageFormatFlag() == MessageFormatFlags.Blob) 
        metrics.getBlobProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
      else 
        if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobProperties) 
          metrics.getBlobPropertiesProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
        else 
          if (getRequest.getMessageFormatFlag() == MessageFormatFlags.BlobUserMetadata) 
            metrics.getBlobUserMetadataProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
    }
    requestResponseChannel.sendResponse(response, request, responseQueueMeasurement, responseSendMeasurement);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_base_faf5e48\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
getStartTimeInMs()
=======
getStartTime()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void handleDeleteRequest(Request request) throws IOException, InterruptedException {
    DeleteRequest deleteRequest = DeleteRequest.readFrom(new DataInputStream(request.getInputStream()), clusterMap);
    metrics.deleteBlobRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
    metrics.deleteBlobRequestRate.mark();
    long startTime = SystemTime.getInstance().milliseconds();
    DeleteResponse response = null;
    try {
      ServerErrorCode error = validateRequest(deleteRequest.getBlobId().getPartition(), false);
      if (error != ServerErrorCode.No_Error) {
        logger.error("Validating delete request failed with error {}", error);
        response = new DeleteResponse(deleteRequest.getCorrelationId(), deleteRequest.getClientId(), error);
      }
      else {
        MessageFormatInputStream stream = new DeleteMessageFormatInputStream(deleteRequest.getBlobId());
        MessageInfo info = new MessageInfo(deleteRequest.getBlobId(), stream.getSize());
        ArrayList<MessageInfo> infoList = new ArrayList<MessageInfo>();
        infoList.add(info);
        MessageFormatWriteSet writeset = new MessageFormatWriteSet(stream, infoList);
        Store storeToDelete = storeManager.getStore(deleteRequest.getBlobId().getPartition());
        storeToDelete.delete(writeset);
        response = new DeleteResponse(deleteRequest.getCorrelationId(), deleteRequest.getClientId(), ServerErrorCode.No_Error);
      }
    }
    catch (StoreException e) {
      logger.error("Store exception on a put with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == StoreErrorCodes.ID_Not_Found) 
        metrics.idNotFoundError.inc();
      else 
        if (e.getErrorCode() == StoreErrorCodes.TTL_Expired) 
          metrics.ttlExpiredError.inc();
        else 
          if (e.getErrorCode() == StoreErrorCodes.ID_Deleted) 
            metrics.idDeletedError.inc();
          else 
            metrics.unExpectedStoreDeleteError.inc();
      response = new DeleteResponse(deleteRequest.getCorrelationId(), deleteRequest.getClientId(), ErrorMapping.getStoreErrorMapping(e.getErrorCode()));
    }
    catch (Exception e) {
      logger.error("Unknown exception on delete {}", e);
      response = new DeleteResponse(deleteRequest.getCorrelationId(), deleteRequest.getClientId(), ServerErrorCode.Unknown_Error);
    }
    finally {
      metrics.deleteBlobProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
    }
    requestResponseChannel.sendResponse(response, request, new HistogramMeasurement(metrics.deleteBlobResponseQueueTime), new HistogramMeasurement(metrics.deleteBlobSendTime));
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_base_faf5e48\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
getStartTimeInMs()
=======
getStartTime()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void handleTTLRequest(Request request) throws IOException, InterruptedException {
    TTLRequest ttlRequest = TTLRequest.readFrom(new DataInputStream(request.getInputStream()), clusterMap);
    metrics.ttlBlobRequestQueueTime.update(SystemTime.getInstance().milliseconds() - request.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_left_2cb49af\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
getStartTimeInMs()
=======
getStartTime()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_2cb49af_4a6a7fc\rev_right_4a6a7fc\ambry-server\src\main\java\com.github.ambry.server\AmbryRequests.java
);
    metrics.ttlBlobRequestRate.mark();
    long startTime = SystemTime.getInstance().milliseconds();
    TTLResponse response = null;
    try {
      ServerErrorCode error = validateRequest(ttlRequest.getBlobId().getPartition(), false);
      if (error != ServerErrorCode.No_Error) {
        logger.error("Validating ttl request failed with error {}", error);
        response = new TTLResponse(ttlRequest.getCorrelationId(), ttlRequest.getClientId(), error);
      }
      else {
        MessageFormatInputStream stream = new TTLMessageFormatInputStream(ttlRequest.getBlobId(), ttlRequest.getNewTTL());
        MessageInfo info = new MessageInfo(ttlRequest.getBlobId(), stream.getSize(), ttlRequest.getNewTTL());
        ArrayList<MessageInfo> infoList = new ArrayList<MessageInfo>();
        infoList.add(info);
        MessageFormatWriteSet writeset = new MessageFormatWriteSet(stream, infoList);
        Store storeToUpdateTTL = storeManager.getStore(ttlRequest.getBlobId().getPartition());
        storeToUpdateTTL.updateTTL(writeset);
        response = new TTLResponse(ttlRequest.getCorrelationId(), ttlRequest.getClientId(), ServerErrorCode.No_Error);
      }
    }
    catch (StoreException e) {
      logger.error("Store exception on a put with error code {} and exception {}", e.getErrorCode(), e);
      if (e.getErrorCode() == StoreErrorCodes.ID_Not_Found) 
        metrics.idNotFoundError.inc();
      else 
        if (e.getErrorCode() == StoreErrorCodes.TTL_Expired) 
          metrics.ttlExpiredError.inc();
        else 
          if (e.getErrorCode() == StoreErrorCodes.ID_Deleted) 
            metrics.idDeletedError.inc();
          else 
            metrics.unExpectedStoreTTLError.inc();
      response = new TTLResponse(ttlRequest.getCorrelationId(), ttlRequest.getClientId(), ErrorMapping.getStoreErrorMapping(e.getErrorCode()));
    }
    catch (Exception e) {
      logger.error("Unknown exception on ttl {}", e);
      response = new TTLResponse(ttlRequest.getCorrelationId(), ttlRequest.getClientId(), ServerErrorCode.Unknown_Error);
    }
    finally {
      metrics.ttlBlobProcessingTime.update(SystemTime.getInstance().milliseconds() - startTime);
    }
    requestResponseChannel.sendResponse(response, request, new HistogramMeasurement(metrics.ttlBlobResponseQueueTime), new HistogramMeasurement(metrics.ttlBlobSendTime));
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_left_9050781\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterEdgeSequence.java,C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_base_aa4381f\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterEdgeSequence.java,C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_right_396f9cf\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterEdgeSequence.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE. EXEMPLO
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
this.start = this.start + this.graph.getBufferSize();
=======
if (this.queue.size() == bufferSize) {
      this.start = this.start + bufferSize;
      this.end = this.end + bufferSize;
    }
    else {
      this.start = this.end;
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  protected void fillBuffer() {
    final int bufferSize = this.graph.getBufferSize();
    final JSONObject object = RestHelper.get(this.uri + this.createSeparator() + RexsterTokens.REXSTER_OFFSET_START + RexsterTokens.EQUALS + this.start + RexsterTokens.AND + RexsterTokens.REXSTER_OFFSET_END + RexsterTokens.EQUALS + this.end);
    for (final Object edge : (JSONArray)object.get(RexsterTokens.RESULTS)) {
      this.queue.add(new RexsterEdge((JSONObject)edge, this.graph));
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_left_9050781\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterEdgeSequence.java
this.start = this.start + this.graph.getBufferSize();
=======
if (this.queue.size() == bufferSize) {
      this.start = this.start + bufferSize;
      this.end = this.end + bufferSize;
    }
    else {
      this.start = this.end;
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_right_396f9cf\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterEdgeSequence.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_left_9050781\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterVertexSequence.java,C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_base_aa4381f\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterVertexSequence.java,C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_right_396f9cf\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterVertexSequence.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
this.start = this.start + this.graph.getBufferSize();
=======
if (this.queue.size() == bufferSize) {
      this.start = this.start + bufferSize;
      this.end = this.end + bufferSize;
    }
    else {
      this.start = this.end;
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  protected void fillBuffer() {
    final int bufferSize = this.graph.getBufferSize();
    final JSONObject object = RestHelper.get(this.uri + this.createSeparator() + RexsterTokens.REXSTER_OFFSET_START + RexsterTokens.EQUALS + this.start + RexsterTokens.AND + RexsterTokens.REXSTER_OFFSET_END + RexsterTokens.EQUALS + this.end);
    for (final Object vertex : (JSONArray)object.get(RexsterTokens.RESULTS)) {
      this.queue.add(new RexsterVertex((JSONObject)vertex, this.graph));
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_left_9050781\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterVertexSequence.java
this.start = this.start + this.graph.getBufferSize();
=======
if (this.queue.size() == bufferSize) {
      this.start = this.start + bufferSize;
      this.end = this.end + bufferSize;
    }
    else {
      this.start = this.end;
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\blueprints\revisions\rev_9050781_396f9cf\rev_right_396f9cf\blueprints-rexster-graph\src\main\java\com\tinkerpop\blueprints\pgm\impls\rexster\util\RexsterVertexSequence.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\integration\okhttp\src\main\java\com\bumptech\glide\integration\okhttp\OkHttpStreamFetcher.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\integration\okhttp\src\main\java\com\bumptech\glide\integration\okhttp\OkHttpStreamFetcher.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\integration\okhttp\src\main\java\com\bumptech\glide\integration\okhttp\OkHttpStreamFetcher.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (stream != null) {
      try {
        stream.close();
      }
      catch (IOException e) {
      }
    }
=======
try {
      if (stream != null) {
        stream.close();
      }
    }
    catch (IOException e) {
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void cleanup() {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\integration\okhttp\src\main\java\com\bumptech\glide\integration\okhttp\OkHttpStreamFetcher.java
if (stream != null) {
      try {
        stream.close();
      }
      catch (IOException e) {
      }
    }
=======
try {
      if (stream != null) {
        stream.close();
      }
    }
    catch (IOException e) {
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\integration\okhttp\src\main\java\com\bumptech\glide\integration\okhttp\OkHttpStreamFetcher.java

    if (responseBody != null) {
      try {
        responseBody.close();
      }
      catch (IOException e) {
      }
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\androidTest\java\com\bumptech\glide\load\data\HttpUrlFetcherServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\androidTest\java\com\bumptech\glide\load\data\HttpUrlFetcherServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\androidTest\java\com\bumptech\glide\load\data\HttpUrlFetcherServerTest.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
new HashMap<String, String>()
=======
new HashMap<>()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Test public void testAppliesHeadersInGlideUrl() throws Exception {
    mockWebServer.enqueue(new MockResponse().setResponseCode(200));
    String headerField = "field";
    String headerValue = "value";
    Map<String, String> headersMap = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\androidTest\java\com\bumptech\glide\load\data\HttpUrlFetcherServerTest.java
new HashMap<String, String>()
=======
new HashMap<>()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\androidTest\java\com\bumptech\glide\load\data\HttpUrlFetcherServerTest.java
;
    headersMap.put(headerField, headerValue);
    Headers headers = mock(Headers.class);
    when(headers.getHeaders()).thenReturn(headersMap);
    getFetcher(headers).loadData(Priority.HIGH);
    assertThat(mockWebServer.takeRequest().getHeader(headerField)).isEqualTo(headerValue);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
return 0;
=======
result = 0;
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
    @Override public long skip(long byteCount) throws IOException {
      final long result;
      if (returnZeroFlag) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java
return 0;
=======
result = 0;
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java

      }
      else {
        result = super.skip(byteCount);
      }
      returnZeroFlag = !returnZeroFlag;
      return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java
super.skip(byteCount)
=======
result
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java
;
    }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
super.skip(byteCount)
=======
result
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
    @Override public long skip(long byteCount) throws IOException {
      final long result;
      if (returnZeroFlag) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java
return 0;
=======
result = 0;
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java

      }
      else {
        result = super.skip(byteCount);
      }
      returnZeroFlag = !returnZeroFlag;
      return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java
super.skip(byteCount)
=======
result
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\ImageHeaderParserTest.java
;
    }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\Glide.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\main\java\com\bumptech\glide\Glide.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\Glide.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
getEngine().clearDiskCache()
=======
engine.clearDiskCache()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void clearDiskCache() {
    Util.assertBackgroundThread();
    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\Glide.java
getEngine().clearDiskCache()
=======
engine.clearDiskCache()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\Glide.java
;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\load\data\HttpUrlFetcher.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\main\java\com\bumptech\glide\load\data\HttpUrlFetcher.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\load\data\HttpUrlFetcher.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE. EXEMPLO ONDE O SSMERGE CONFLITO FOI PIOR
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
return getStreamForSuccessfulRequest(urlConnection);
=======
stream = ContentLengthInputStream.obtain(urlConnection.getInputStream(), contentLength);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private InputStream loadDataWithRedirects(URL url, int redirects, URL lastUrl, Map<String, String> headers) throws IOException {
    if (redirects >= MAXIMUM_REDIRECTS) {
      throw new IOException("Too many (> " + MAXIMUM_REDIRECTS + ") redirects!");
    }
    else {
      try {
        if (lastUrl != null && url.toURI().equals(lastUrl.toURI())) {
          throw new IOException("In re-direct loop");
        }
      }
      catch (URISyntaxException e) {
      }
    }
    urlConnection = connectionFactory.build(url);
    for (Map.Entry<String, String> headerEntry : headers.entrySet()) {
      urlConnection.addRequestProperty(headerEntry.getKey(), headerEntry.getValue());
    }
    if (TextUtils.isEmpty(urlConnection.getRequestProperty(ENCODING_HEADER))) {
      urlConnection.setRequestProperty(ENCODING_HEADER, DEFAULT_ENCODING);
    }
    urlConnection.setConnectTimeout(timeout);
    urlConnection.setReadTimeout(timeout);
    urlConnection.setUseCaches(false);
    urlConnection.setDoInput(true);
    urlConnection.connect();
    if (isCancelled) {
      return null;
    }
    final int statusCode = urlConnection.getResponseCode();
    if (statusCode / 100 == 2) {
      String contentLength = urlConnection.getHeaderField(CONTENT_LENGTH_HEADER);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\load\data\HttpUrlFetcher.java
return getStreamForSuccessfulRequest(urlConnection);
=======
stream = ContentLengthInputStream.obtain(urlConnection.getInputStream(), contentLength);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\load\data\HttpUrlFetcher.java

    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\load\engine\EngineKey.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\main\java\com\bumptech\glide\load\engine\EngineKey.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\load\engine\EngineKey.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (stringKey == null) {
      stringKey = new StringBuilder().append("EngineKey{").append(id).append('+').append(signature).append("+[").append(width).append('x').append(height).append("]+").append('\'').append(cacheDecoder != null ? cacheDecoder.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(decoder != null ? decoder.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(transformation != null ? transformation.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(encoder != null ? encoder.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(transcoder != null ? transcoder.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(sourceEncoder != null ? sourceEncoder.getId() : EMPTY_LOG_STRING).append('\'').append('}').toString();
    }
=======
return "EngineKey{" + "model=" + model + ", width=" + width + ", height=" + height + ", resourceClass=" + resourceClass + ", transcodeClass=" + transcodeClass + ", signature=" + signature + ", hashCode=" + hashCode + ", transformations=" + transformations + ", options=" + options + '}';
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public String toString() {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\load\engine\EngineKey.java
if (stringKey == null) {
      stringKey = new StringBuilder().append("EngineKey{").append(id).append('+').append(signature).append("+[").append(width).append('x').append(height).append("]+").append('\'').append(cacheDecoder != null ? cacheDecoder.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(decoder != null ? decoder.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(transformation != null ? transformation.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(encoder != null ? encoder.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(transcoder != null ? transcoder.getId() : EMPTY_LOG_STRING).append('\'').append('+').append('\'').append(sourceEncoder != null ? sourceEncoder.getId() : EMPTY_LOG_STRING).append('\'').append('}').toString();
    }
=======
return "EngineKey{" + "model=" + model + ", width=" + width + ", height=" + height + ", resourceClass=" + resourceClass + ", transcodeClass=" + transcodeClass + ", signature=" + signature + ", hashCode=" + hashCode + ", transformations=" + transformations + ", options=" + options + '}';
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\load\engine\EngineKey.java

    return stringKey;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\load\engine\bitmap_recycle\LruBitmapPool.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\main\java\com\bumptech\glide\load\engine\bitmap_recycle\LruBitmapPool.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\load\engine\bitmap_recycle\LruBitmapPool.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (Log.isLoggable(TAG, Log.DEBUG)) {
      Log.d(TAG, "clearMemory");
    }
=======
trimToSize(0);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void clearMemory() {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\load\engine\bitmap_recycle\LruBitmapPool.java
if (Log.isLoggable(TAG, Log.DEBUG)) {
      Log.d(TAG, "clearMemory");
    }
=======
trimToSize(0);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\load\engine\bitmap_recycle\LruBitmapPool.java

    trimToSize(0);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
new HashSet<RequestManagerFragment>()
=======
new HashSet<>()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @TargetApi(value = Build.VERSION_CODES.JELLY_BEAN_MR1) public Set<RequestManagerFragment> getDescendantRequestManagerFragments() {
    if (rootRequestManagerFragment == this) {
      return Collections.unmodifiableSet(childRequestManagerFragments);
    }
    else 
      if (rootRequestManagerFragment == null || Build.VERSION.SDK_INT < Build.VERSION_CODES.JELLY_BEAN_MR1) {
        return Collections.emptySet();
      }
      else {
        HashSet<RequestManagerFragment> descendants = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java
new HashSet<RequestManagerFragment>()
=======
new HashSet<>()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java
;
        for (RequestManagerFragment fragment : rootRequestManagerFragment.getDescendantRequestManagerFragments()) {
          if (isDescendant(fragment.getParentFragment())) {
            descendants.add(fragment);
          }
        }
        return Collections.unmodifiableSet(descendants);
      }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
new HashSet<RequestManager>(descendantFragments.size())
=======
new HashSet<>(descendantFragments.size())
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
    @Override public Set<RequestManager> getDescendants() {
      Set<RequestManagerFragment> descendantFragments = getDescendantRequestManagerFragments();
      HashSet<RequestManager> descendants = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java
new HashSet<RequestManager>(descendantFragments.size())
=======
new HashSet<>(descendantFragments.size())
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\manager\RequestManagerFragment.java
;
      for (RequestManagerFragment fragment : descendantFragments) {
        if (fragment.getRequestManager() != null) {
          descendants.add(fragment.getRequestManager());
        }
      }
      return descendants;
    }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
new HashSet<SupportRequestManagerFragment>()
=======
new HashSet<>()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Set<SupportRequestManagerFragment> getDescendantRequestManagerFragments() {
    if (rootRequestManagerFragment == null) {
      return Collections.emptySet();
    }
    else 
      if (rootRequestManagerFragment == this) {
        return Collections.unmodifiableSet(childRequestManagerFragments);
      }
      else {
        HashSet<SupportRequestManagerFragment> descendants = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java
new HashSet<SupportRequestManagerFragment>()
=======
new HashSet<>()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java
;
        for (SupportRequestManagerFragment fragment : rootRequestManagerFragment.getDescendantRequestManagerFragments()) {
          if (isDescendant(fragment.getParentFragment())) {
            descendants.add(fragment);
          }
        }
        return Collections.unmodifiableSet(descendants);
      }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
new HashSet<RequestManager>(descendantFragments.size())
=======
new HashSet<>(descendantFragments.size())
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
    @Override public Set<RequestManager> getDescendants() {
      Set<SupportRequestManagerFragment> descendantFragments = getDescendantRequestManagerFragments();
      HashSet<RequestManager> descendants = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java
new HashSet<RequestManager>(descendantFragments.size())
=======
new HashSet<>(descendantFragments.size())
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\library\src\main\java\com\bumptech\glide\manager\SupportRequestManagerFragment.java
;
      for (SupportRequestManagerFragment fragment : descendantFragments) {
        if (fragment.getRequestManager() != null) {
          descendants.add(fragment.getRequestManager());
        }
      }
      return descendants;
    }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\samples\flickr\src\main\java\com\bumptech\glide\samples\flickr\FlickrPhotoGrid.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_base_431ccaf\samples\flickr\src\main\java\com\bumptech\glide\samples\flickr\FlickrPhotoGrid.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\samples\flickr\src\main\java\com\bumptech\glide\samples\flickr\FlickrPhotoGrid.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE. EXEMPLO
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
diskCacheStrategy(DiskCacheStrategy.SOURCE).crossFade(R.anim.fade_in, 150).override(Api.SQUARE_THUMB_SIZE, Api.SQUARE_THUMB_SIZE)
=======
transition(withCrossFade(R.anim.fade_in, 150)).apply(diskCacheStrategyOf(DiskCacheStrategy.DATA).centerCrop(getActivity()).override(Api.SQUARE_THUMB_SIZE, Api.SQUARE_THUMB_SIZE))
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) {
    Bundle args = getArguments();
    photoSize = args.getInt(IMAGE_SIZE_KEY);
    thumbnail = args.getBoolean(THUMBNAIL_KEY);
    fullRequest = Glide.with(this).asDrawable().transition(withCrossFade(R.anim.fade_in, 150)).apply(centerCropTransform(getActivity()));
    thumbnailRequest = Glide.with(this).asDrawable().
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_left_e161ca9\samples\flickr\src\main\java\com\bumptech\glide\samples\flickr\FlickrPhotoGrid.java
diskCacheStrategy(DiskCacheStrategy.SOURCE).crossFade(R.anim.fade_in, 150).override(Api.SQUARE_THUMB_SIZE, Api.SQUARE_THUMB_SIZE)
=======
transition(withCrossFade(R.anim.fade_in, 150)).apply(diskCacheStrategyOf(DiskCacheStrategy.DATA).centerCrop(getActivity()).override(Api.SQUARE_THUMB_SIZE, Api.SQUARE_THUMB_SIZE))
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_e161ca9_7e0f873\rev_right_7e0f873\samples\flickr\src\main\java\com\bumptech\glide\samples\flickr\FlickrPhotoGrid.java
;
    preloadRequest = thumbnail ? thumbnailRequest.clone().priority(Priority.HIGH) : fullRequest;
    final View result = inflater.inflate(R.layout.flickr_photo_grid, container, false);
    grid = (GridView)result.findViewById(R.id.images);
    grid.setColumnWidth(photoSize);
    adapter = new PhotoAdapter();
    grid.setAdapter(adapter);
    final FixedPreloadSizeProvider<Photo> preloadSizeProvider = new FixedPreloadSizeProvider<Photo>(photoSize, photoSize);
    final ListPreloader<Photo> preloader = new ListPreloader<Photo>(adapter, preloadSizeProvider, args.getInt(PRELOAD_KEY));
    grid.setOnScrollListener(preloader);
    if (currentPhotos != null) {
      adapter.setPhotos(currentPhotos);
    }
    if (savedInstanceState != null) {
      int index = savedInstanceState.getInt(STATE_POSITION_INDEX);
      grid.setSelection(index);
    }
    return result;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_e499124_f45f8f4\rev_left_e499124\src\main\com\mongodb\DBCursor.java,C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_e499124_f45f8f4\rev_base_9f5214b\src\main\com\mongodb\DBCursor.java,C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_e499124_f45f8f4\rev_right_f45f8f4\src\main\com\mongodb\DBCursor.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (hasSpecialQueryFields()) {
      foo = _specialFields == null ? new BasicDBObject() : _specialFields;
      _addToQueryObject(foo, "query", _query, true);
      _addToQueryObject(foo, "orderby", _orderBy, false);
      if (_hint != null) 
        _addToQueryObject(foo, "$hint", _hint);
      if (_hintDBObj != null) 
        _addToQueryObject(foo, "$hint", _hintDBObj);
      if (_explain) 
        foo.put("$explain", true);
      if (_snapshot) 
        foo.put("$snapshot", true);
      if (_readPref != null) 
        foo.put("$readPreference", _readPref.toDBObject());
    }
=======
_it = _collection.__find(queryOp, _keysWanted, _skip, _batchSize, _limit, _options, _readPref, getDecoder());
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void _check() throws MongoException {
    if (_it != null) 
      return ;
    _lookForHints();
    DBObject queryOp = new QueryOpBuilder().addQuery(_query).addOrderBy(_orderBy).addHint(_hintDBObj).addHint(_hint).addExplain(_explain).addSnapshot(_snapshot).addSpecialFields(_specialFields).get();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_e499124_f45f8f4\rev_left_e499124\src\main\com\mongodb\DBCursor.java
if (hasSpecialQueryFields()) {
      foo = _specialFields == null ? new BasicDBObject() : _specialFields;
      _addToQueryObject(foo, "query", _query, true);
      _addToQueryObject(foo, "orderby", _orderBy, false);
      if (_hint != null) 
        _addToQueryObject(foo, "$hint", _hint);
      if (_hintDBObj != null) 
        _addToQueryObject(foo, "$hint", _hintDBObj);
      if (_explain) 
        foo.put("$explain", true);
      if (_snapshot) 
        foo.put("$snapshot", true);
      if (_readPref != null) 
        foo.put("$readPreference", _readPref.toDBObject());
    }
=======
_it = _collection.__find(queryOp, _keysWanted, _skip, _batchSize, _limit, _options, _readPref, getDecoder());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_e499124_f45f8f4\rev_right_f45f8f4\src\main\com\mongodb\DBCursor.java

    _it = _collection.__find(foo, _keysWanted, _skip, _batchSize, _limit, _options, _readPref, getDecoder());
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_5c6ec4a_84557c9\rev_left_5c6ec4a\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_5c6ec4a_84557c9\rev_base_1e02853\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_5c6ec4a_84557c9\rev_right_84557c9\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (columns != null && (columns.size() == 1 ? columns.iterator().next() != null : true)) {
      for (Column c : thriftRow.getColumns()) {
        String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(c.getName());
        byte[] thriftColumnValue = c.getValue();
        if (null == thriftColumnValue) {
          continue ;
        }
        com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
        if (column != null) {
          try {
            PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
          }
          catch (PropertyAccessException pae) {
            log.warn(pae.getMessage());
          }
        }
        else {
          if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
            String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
            relations.put(thriftColumnName, value);
          }
        }
      }
    }
    else {
      for (SuperColumn c : thriftRow.getSuperColumns()) {
        for (Column cc : c.getColumns()) {
          String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(cc.getName());
          byte[] thriftColumnValue = cc.getValue();
          if (null == thriftColumnValue) {
            continue ;
          }
          com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
          if (column != null) {
            try {
              PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
            }
            catch (PropertyAccessException pae) {
              log.warn(pae.getMessage());
            }
          }
          else {
            if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
              String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
              relations.put(thriftColumnName, value);
            }
          }
        }
      }
    }
=======
return isWrapperReq ? new EnhanceEntity(entity, thriftRow.getId(), relations) : entity;
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Object fromColumnThriftRow(Class<?> clazz, EntityMetadata m, ThriftRow thriftRow, List<String> relationNames, boolean isWrapperReq) throws Exception {
    Object entity = clazz.newInstance();
    Map<String, Object> relations = new HashMap<String, Object>();
    PropertyAccessorHelper.setId(entity, m, thriftRow.getId());
    for (Column c : thriftRow.getColumns()) {
      String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(c.getName());
      byte[] thriftColumnValue = c.getValue();
      if (null == thriftColumnValue) {
        continue ;
      }
      com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
      if (column != null) {
        try {
          PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
        }
        catch (PropertyAccessException pae) {
          log.warn(pae.getMessage());
        }
      }
      else {
        if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
          String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
          relations.put(thriftColumnName, value);
        }
      }
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_5c6ec4a_84557c9\rev_left_5c6ec4a\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java
if (columns != null && (columns.size() == 1 ? columns.iterator().next() != null : true)) {
      for (Column c : thriftRow.getColumns()) {
        String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(c.getName());
        byte[] thriftColumnValue = c.getValue();
        if (null == thriftColumnValue) {
          continue ;
        }
        com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
        if (column != null) {
          try {
            PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
          }
          catch (PropertyAccessException pae) {
            log.warn(pae.getMessage());
          }
        }
        else {
          if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
            String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
            relations.put(thriftColumnName, value);
          }
        }
      }
    }
    else {
      for (SuperColumn c : thriftRow.getSuperColumns()) {
        for (Column cc : c.getColumns()) {
          String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(cc.getName());
          byte[] thriftColumnValue = cc.getValue();
          if (null == thriftColumnValue) {
            continue ;
          }
          com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
          if (column != null) {
            try {
              PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
            }
            catch (PropertyAccessException pae) {
              log.warn(pae.getMessage());
            }
          }
          else {
            if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
              String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
              relations.put(thriftColumnName, value);
            }
          }
        }
      }
    }
=======
return isWrapperReq ? new EnhanceEntity(entity, thriftRow.getId(), relations) : entity;
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_5c6ec4a_84557c9\rev_right_84557c9\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java

    if (columns != null && (columns.size() == 1 ? columns.iterator().next() != null : true)) {
      for (Column c : thriftRow.getColumns()) {
        String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(c.getName());
        byte[] thriftColumnValue = c.getValue();
        if (null == thriftColumnValue) {
          continue ;
        }
        com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
        if (column != null) {
          try {
            PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
          }
          catch (PropertyAccessException pae) {
            log.warn(pae.getMessage());
          }
        }
        else {
          if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
            String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
            relations.put(thriftColumnName, value);
          }
        }
      }
    }
    else {
      for (SuperColumn c : thriftRow.getSuperColumns()) {
        for (Column cc : c.getColumns()) {
          String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(cc.getName());
          byte[] thriftColumnValue = cc.getValue();
          if (null == thriftColumnValue) {
            continue ;
          }
          com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
          if (column != null) {
            try {
              PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
            }
            catch (PropertyAccessException pae) {
              log.warn(pae.getMessage());
            }
          }
          else {
            if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
              String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
              relations.put(thriftColumnName, value);
            }
          }
        }
      }
    }
    return isWrapperReq ? new EnhanceEntity(entity, thriftRow.getId(), relations) : entity;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_8889a15_80ac3f3\rev_left_8889a15\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_8889a15_80ac3f3\rev_base_4bc081b\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_8889a15_80ac3f3\rev_right_80ac3f3\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
v = vertexCache.get(vertexid, externalVertexRetriever);
=======
try {
      v = vertexCache.get(vertexid, externalVertexRetriever);
    }
    catch (InvalidIDException e) {
      log.debug("Illegal vertex ID", e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public TitanVertex getVertex(long vertexid) {
    verifyOpen();
    if (null != config.getGroupName()) {
      MetricManager.INSTANCE.getCounter(config.getGroupName(), "db", "getVertexByID").inc();
    }
    if (!isValidVertexId(vertexid)) 
      return null;
    if (idInspector.isPartitionedVertex(vertexid)) 
      vertexid = idManager.getCanonicalVertexId(vertexid);
    InternalVertex v = null;
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_8889a15_80ac3f3\rev_left_8889a15\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java
v = vertexCache.get(vertexid, externalVertexRetriever);
=======
try {
      v = vertexCache.get(vertexid, externalVertexRetriever);
    }
    catch (InvalidIDException e) {
      log.debug("Illegal vertex ID", e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_8889a15_80ac3f3\rev_right_80ac3f3\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java

    return (null == v || v.isRemoved()) ? null : v;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_95bfd92_6c2d71c\rev_left_95bfd92\ql\src\java\org\apache\hadoop\hive\ql\plan\ExprNodeGenericFuncDesc.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_95bfd92_6c2d71c\rev_base_451381c\ql\src\java\org\apache\hadoop\hive\ql\plan\ExprNodeGenericFuncDesc.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_95bfd92_6c2d71c\rev_right_6c2d71c\ql\src\java\org\apache\hadoop\hive\ql\plan\ExprNodeGenericFuncDesc.java
CONCLUSAO: FP. MUDANÇAS COMPLEMENTARES. EXEMPLO SSMERGE QUEBRA BUILD?
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
chidren.get(i).toString()
=======
chidren.get(i)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append(genericUDF.getClass().getSimpleName());
    sb.append("(");
    if (chidren != null) {
      for (int i = 0; i < chidren.size(); i++) {
        if (i > 0) {
          sb.append(", ");
        }
        sb.append(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_95bfd92_6c2d71c\rev_left_95bfd92\ql\src\java\org\apache\hadoop\hive\ql\plan\ExprNodeGenericFuncDesc.java
chidren.get(i).toString()
=======
chidren.get(i)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_95bfd92_6c2d71c\rev_right_6c2d71c\ql\src\java\org\apache\hadoop\hive\ql\plan\ExprNodeGenericFuncDesc.java
);
      }
    }
    sb.append(")");
    return sb.toString();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e683264_d3bccce\rev_left_e683264\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreMutex.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e683264_d3bccce\rev_base_125dc96\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreMutex.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e683264_d3bccce\rev_right_d3bccce\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreMutex.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
try {
      lease.close();
      watcherRemoveClient.removeWatchers();
    }
    finally {
      lease = null;
    }
=======
this.lease = null;
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void release() throws Exception {
    Lease lease = this.lease;
    Preconditions.checkState(lease != null, "Not acquired");
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e683264_d3bccce\rev_left_e683264\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreMutex.java
try {
      lease.close();
      watcherRemoveClient.removeWatchers();
    }
    finally {
      lease = null;
    }
=======
this.lease = null;
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e683264_d3bccce\rev_right_d3bccce\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreMutex.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\MockCluster.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_base_98cfd5d\ambry-server\src\test\java\com.github.ambry.server\MockCluster.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\MockCluster.java
CONCLUSAO: FP. JDIME INTEGROU MÉTODOS COM O MESMO NOME, MAS ASSINATURAS DIFERENTES. EXEMPLO
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
try {
      for (MockDataNodeId dataNodeId : dataNodes) {
        if (enableSSL) {
          String sslEnabledDatacenters = getSSLEnabledDatacenterValue(dataNodeId.getDatacenterName(), datacenterList);
          sslProps.setProperty("ssl.enabled.datacenters", sslEnabledDatacenters);
        }
        initializeServer(dataNodeId, sslProps, enableHardDeletes);
      }
    }
    catch (InstantiationException e) {
      cleanup();
      throw e;
    }
=======
for (MockDataNodeId dataNodeId : dataNodes) {
      if (dataNodeId.getDatacenterName() == "DC1") {
        startServer(dataNodeId, sslEnabledDatacentersForDC1, time);
      }
      else 
        if (dataNodeId.getDatacenterName() == "DC2") {
          startServer(dataNodeId, sslEnabledDatacentersForDC2, time);
        }
        else 
          if (dataNodeId.getDatacenterName() == "DC3") {
            startServer(dataNodeId, sslEnabledDatacentersForDC3, time);
          }
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public MockCluster(NotificationSystem notificationSystem, boolean enableSSL, String datacenters, Properties sslProps, boolean enableHardDeletes, Time time) throws IOException, InstantiationException, URISyntaxException, GeneralSecurityException {
    this.notificationSystem = notificationSystem;
    clusterMap = new MockClusterMap(enableSSL);
    serverList = new ArrayList<AmbryServer>();
    ArrayList<String> datacenterList = Utils.splitString(datacenters, ",");
    List<MockDataNodeId> dataNodes = clusterMap.getDataNodes();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\MockCluster.java
try {
      for (MockDataNodeId dataNodeId : dataNodes) {
        if (enableSSL) {
          String sslEnabledDatacenters = getSSLEnabledDatacenterValue(dataNodeId.getDatacenterName(), datacenterList);
          sslProps.setProperty("ssl.enabled.datacenters", sslEnabledDatacenters);
        }
        initializeServer(dataNodeId, sslProps, enableHardDeletes);
      }
    }
    catch (InstantiationException e) {
      cleanup();
      throw e;
    }
=======
for (MockDataNodeId dataNodeId : dataNodes) {
      if (dataNodeId.getDatacenterName() == "DC1") {
        startServer(dataNodeId, sslEnabledDatacentersForDC1, time);
      }
      else 
        if (dataNodeId.getDatacenterName() == "DC2") {
          startServer(dataNodeId, sslEnabledDatacentersForDC2, time);
        }
        else 
          if (dataNodeId.getDatacenterName() == "DC3") {
            startServer(dataNodeId, sslEnabledDatacentersForDC3, time);
          }
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\MockCluster.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_base_98cfd5d\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
sslCluster.startServers()
=======
cluster = new MockCluster(notificationSystem, false, "", "", "", SystemTime.getInstance())
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Test public void startStopTest() throws IOException, InstantiationException, URISyntaxException, GeneralSecurityException {
    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
sslCluster.startServers()
=======
cluster = new MockCluster(notificationSystem, false, "", "", "", SystemTime.getInstance())
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_base_98cfd5d\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
CONCLUSAO: FP. JDIME INTEGROU MÉTODOS COM O MESMO NOME, MAS ASSINATURAS DIFERENTES.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
try {
      MockClusterMap clusterMap = cluster.getClusterMap();
      byte[] usermetadata = new byte[1000];
      byte[] data = new byte[31870];
      BlobProperties properties = new BlobProperties(31870, "serviceid1");
      new Random().nextBytes(usermetadata);
      new Random().nextBytes(data);
      List<PartitionId> partitionIds = clusterMap.getWritablePartitionIds();
      BlobId blobId1 = new BlobId(partitionIds.get(0));
      BlobId blobId2 = new BlobId(partitionIds.get(0));
      BlobId blobId3 = new BlobId(partitionIds.get(0));
      BlobId blobId4 = new BlobId(partitionIds.get(0));
      PutRequest putRequest = new PutRequest(1, "client1", blobId1, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      BlockingChannel channel = getBlockingChannelBasedOnPortType(targetPort, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      channel.connect();
      channel.send(putRequest);
      InputStream putResponseStream = channel.receive().getInputStream();
      PutResponse response = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response.getError(), ServerErrorCode.No_Error);
      PutRequest putRequest2 = new PutRequest(1, "client1", blobId2, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel.send(putRequest2);
      putResponseStream = channel.receive().getInputStream();
      PutResponse response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      PutRequest putRequest3 = new PutRequest(1, "client1", blobId3, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel.send(putRequest3);
      putResponseStream = channel.receive().getInputStream();
      PutResponse response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      BlobProperties propertiesExpired = new BlobProperties(31870, "serviceid1", "ownerid", "jpeg", false, 0);
      PutRequest putRequest4 = new PutRequest(1, "client1", blobId4, propertiesExpired, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel.send(putRequest4);
      putResponseStream = channel.receive().getInputStream();
      PutResponse response4 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response4.getError(), ServerErrorCode.No_Error);
      ArrayList<BlobId> ids = new ArrayList<BlobId>();
      MockPartitionId partition = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(blobId1);
      ArrayList<PartitionRequestInfo> partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
      PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(partition, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest1 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
      channel.send(getRequest1);
      InputStream stream = channel.receive().getInputStream();
      GetResponse resp1 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      try {
        BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp1.getInputStream());
        Assert.assertEquals(propertyOutput.getBlobSize(), 31870);
        Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      ids = new ArrayList<BlobId>();
      partition = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(blobId1);
      partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
      partitionRequestInfo = new PartitionRequestInfo(partition, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      getRequest1 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.Include_Expired_Blobs);
      channel.send(getRequest1);
      stream = channel.receive().getInputStream();
      resp1 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      try {
        BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp1.getInputStream());
        Assert.assertEquals(propertyOutput.getBlobSize(), 31870);
        Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      ArrayList<BlobId> idsExpired = new ArrayList<BlobId>();
      MockPartitionId partitionExpired = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      idsExpired.add(blobId4);
      ArrayList<PartitionRequestInfo> partitionRequestInfoListExpired = new ArrayList<PartitionRequestInfo>();
      PartitionRequestInfo partitionRequestInfoExpired = new PartitionRequestInfo(partitionExpired, idsExpired);
      partitionRequestInfoListExpired.add(partitionRequestInfoExpired);
      GetRequest getRequestExpired = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoListExpired, GetOptions.None);
      channel.send(getRequestExpired);
      InputStream streamExpired = channel.receive().getInputStream();
      GetResponse respExpired = GetResponse.readFrom(new DataInputStream(streamExpired), clusterMap);
      Assert.assertEquals(respExpired.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Expired);
      idsExpired = new ArrayList<BlobId>();
      partitionExpired = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      idsExpired.add(blobId4);
      partitionRequestInfoListExpired = new ArrayList<PartitionRequestInfo>();
      partitionRequestInfoExpired = new PartitionRequestInfo(partitionExpired, idsExpired);
      partitionRequestInfoListExpired.add(partitionRequestInfoExpired);
      getRequestExpired = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoListExpired, GetOptions.Include_Expired_Blobs);
      channel.send(getRequestExpired);
      streamExpired = channel.receive().getInputStream();
      respExpired = GetResponse.readFrom(new DataInputStream(streamExpired), clusterMap);
      try {
        BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(respExpired.getInputStream());
        Assert.assertEquals(propertyOutput.getBlobSize(), 31870);
        Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
        Assert.assertEquals(propertyOutput.getOwnerId(), "ownerid");
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      GetRequest getRequest2 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
      channel.send(getRequest2);
      stream = channel.receive().getInputStream();
      GetResponse resp2 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      try {
        ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp2.getInputStream());
        Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      try {
        coordinatorProps.setProperty("ssl.enabled.datacenters", sslEnabledDatacenters);
        Properties coordinatorProperties = getCoordinatorProperties(coordinatorDatacenter);
        coordinatorProperties.putAll(coordinatorProps);
        Coordinator coordinator = new AmbryCoordinator(new VerifiableProperties(coordinatorProperties), clusterMap);
        BlobOutput output = coordinator.getBlob(blobId1.getID());
        Assert.assertEquals(output.getSize(), 31870);
        byte[] dataOutputStream = new byte[(int)output.getSize()];
        output.getStream().read(dataOutputStream);
        Assert.assertArrayEquals(dataOutputStream, data);
        coordinator.close();
      }
      catch (CoordinatorException e) {
        e.printStackTrace();
        Assert.assertEquals(false, true);
      }
      ids = new ArrayList<BlobId>();
      partition = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(new BlobId(partition));
      partitionRequestInfoList.clear();
      partitionRequestInfo = new PartitionRequestInfo(partition, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest4 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
      channel.send(getRequest4);
      stream = channel.receive().getInputStream();
      GetResponse resp4 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp4.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Not_Found);
      channel.disconnect();
    }
    catch (Exception e) {
      e.printStackTrace();
      Assert.assertEquals(true, false);
    }
=======
cluster = new MockCluster(notificationSystem, enableSSLPorts, sslEnabledDatacentersForDC1, sslEnabledDatacentersForDC2, sslEnabledDatacentersForDC3, SystemTime.getInstance());
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void endToEndTest(Port targetPort, String coordinatorDatacenter, String sslEnabledDatacenters, MockCluster cluster) throws InterruptedException, IOException, InstantiationException {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
try {
      MockClusterMap clusterMap = cluster.getClusterMap();
      byte[] usermetadata = new byte[1000];
      byte[] data = new byte[31870];
      BlobProperties properties = new BlobProperties(31870, "serviceid1");
      new Random().nextBytes(usermetadata);
      new Random().nextBytes(data);
      List<PartitionId> partitionIds = clusterMap.getWritablePartitionIds();
      BlobId blobId1 = new BlobId(partitionIds.get(0));
      BlobId blobId2 = new BlobId(partitionIds.get(0));
      BlobId blobId3 = new BlobId(partitionIds.get(0));
      BlobId blobId4 = new BlobId(partitionIds.get(0));
      PutRequest putRequest = new PutRequest(1, "client1", blobId1, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      BlockingChannel channel = getBlockingChannelBasedOnPortType(targetPort, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      channel.connect();
      channel.send(putRequest);
      InputStream putResponseStream = channel.receive().getInputStream();
      PutResponse response = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response.getError(), ServerErrorCode.No_Error);
      PutRequest putRequest2 = new PutRequest(1, "client1", blobId2, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel.send(putRequest2);
      putResponseStream = channel.receive().getInputStream();
      PutResponse response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      PutRequest putRequest3 = new PutRequest(1, "client1", blobId3, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel.send(putRequest3);
      putResponseStream = channel.receive().getInputStream();
      PutResponse response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      BlobProperties propertiesExpired = new BlobProperties(31870, "serviceid1", "ownerid", "jpeg", false, 0);
      PutRequest putRequest4 = new PutRequest(1, "client1", blobId4, propertiesExpired, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel.send(putRequest4);
      putResponseStream = channel.receive().getInputStream();
      PutResponse response4 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response4.getError(), ServerErrorCode.No_Error);
      ArrayList<BlobId> ids = new ArrayList<BlobId>();
      MockPartitionId partition = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(blobId1);
      ArrayList<PartitionRequestInfo> partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
      PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(partition, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest1 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
      channel.send(getRequest1);
      InputStream stream = channel.receive().getInputStream();
      GetResponse resp1 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      try {
        BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp1.getInputStream());
        Assert.assertEquals(propertyOutput.getBlobSize(), 31870);
        Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      ids = new ArrayList<BlobId>();
      partition = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(blobId1);
      partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
      partitionRequestInfo = new PartitionRequestInfo(partition, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      getRequest1 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.Include_Expired_Blobs);
      channel.send(getRequest1);
      stream = channel.receive().getInputStream();
      resp1 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      try {
        BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp1.getInputStream());
        Assert.assertEquals(propertyOutput.getBlobSize(), 31870);
        Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      ArrayList<BlobId> idsExpired = new ArrayList<BlobId>();
      MockPartitionId partitionExpired = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      idsExpired.add(blobId4);
      ArrayList<PartitionRequestInfo> partitionRequestInfoListExpired = new ArrayList<PartitionRequestInfo>();
      PartitionRequestInfo partitionRequestInfoExpired = new PartitionRequestInfo(partitionExpired, idsExpired);
      partitionRequestInfoListExpired.add(partitionRequestInfoExpired);
      GetRequest getRequestExpired = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoListExpired, GetOptions.None);
      channel.send(getRequestExpired);
      InputStream streamExpired = channel.receive().getInputStream();
      GetResponse respExpired = GetResponse.readFrom(new DataInputStream(streamExpired), clusterMap);
      Assert.assertEquals(respExpired.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Expired);
      idsExpired = new ArrayList<BlobId>();
      partitionExpired = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      idsExpired.add(blobId4);
      partitionRequestInfoListExpired = new ArrayList<PartitionRequestInfo>();
      partitionRequestInfoExpired = new PartitionRequestInfo(partitionExpired, idsExpired);
      partitionRequestInfoListExpired.add(partitionRequestInfoExpired);
      getRequestExpired = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoListExpired, GetOptions.Include_Expired_Blobs);
      channel.send(getRequestExpired);
      streamExpired = channel.receive().getInputStream();
      respExpired = GetResponse.readFrom(new DataInputStream(streamExpired), clusterMap);
      try {
        BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(respExpired.getInputStream());
        Assert.assertEquals(propertyOutput.getBlobSize(), 31870);
        Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
        Assert.assertEquals(propertyOutput.getOwnerId(), "ownerid");
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      GetRequest getRequest2 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
      channel.send(getRequest2);
      stream = channel.receive().getInputStream();
      GetResponse resp2 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      try {
        ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp2.getInputStream());
        Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      try {
        coordinatorProps.setProperty("ssl.enabled.datacenters", sslEnabledDatacenters);
        Properties coordinatorProperties = getCoordinatorProperties(coordinatorDatacenter);
        coordinatorProperties.putAll(coordinatorProps);
        Coordinator coordinator = new AmbryCoordinator(new VerifiableProperties(coordinatorProperties), clusterMap);
        BlobOutput output = coordinator.getBlob(blobId1.getID());
        Assert.assertEquals(output.getSize(), 31870);
        byte[] dataOutputStream = new byte[(int)output.getSize()];
        output.getStream().read(dataOutputStream);
        Assert.assertArrayEquals(dataOutputStream, data);
        coordinator.close();
      }
      catch (CoordinatorException e) {
        e.printStackTrace();
        Assert.assertEquals(false, true);
      }
      ids = new ArrayList<BlobId>();
      partition = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(new BlobId(partition));
      partitionRequestInfoList.clear();
      partitionRequestInfo = new PartitionRequestInfo(partition, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest4 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
      channel.send(getRequest4);
      stream = channel.receive().getInputStream();
      GetResponse resp4 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp4.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Not_Found);
      channel.disconnect();
    }
    catch (Exception e) {
      e.printStackTrace();
      Assert.assertEquals(true, false);
    }
=======
cluster = new MockCluster(notificationSystem, enableSSLPorts, sslEnabledDatacentersForDC1, sslEnabledDatacentersForDC2, sslEnabledDatacentersForDC3, SystemTime.getInstance());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_base_98cfd5d\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
try {
      MockClusterMap clusterMap = cluster.getClusterMap();
      byte[] usermetadata = new byte[1000];
      byte[] data = new byte[1000];
      BlobProperties properties = new BlobProperties(1000, "serviceid1");
      new Random().nextBytes(usermetadata);
      new Random().nextBytes(data);
      PartitionId partition = clusterMap.getWritablePartitionIds().get(0);
      BlobId blobId1 = new BlobId(partition);
      BlobId blobId2 = new BlobId(partition);
      BlobId blobId3 = new BlobId(partition);
      BlobId blobId4 = new BlobId(partition);
      BlobId blobId5 = new BlobId(partition);
      BlobId blobId6 = new BlobId(partition);
      BlobId blobId7 = new BlobId(partition);
      BlobId blobId8 = new BlobId(partition);
      BlobId blobId9 = new BlobId(partition);
      BlobId blobId10 = new BlobId(partition);
      BlobId blobId11 = new BlobId(partition);
      PutRequest putRequest = new PutRequest(1, "client1", blobId1, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      BlockingChannel channel1 = getBlockingChannelBasedOnPortType(dataNode1Port, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      BlockingChannel channel2 = getBlockingChannelBasedOnPortType(dataNode2Port, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      BlockingChannel channel3 = getBlockingChannelBasedOnPortType(dataNode3Port, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      channel1.connect();
      channel2.connect();
      channel3.connect();
      channel1.send(putRequest);
      InputStream putResponseStream = channel1.receive().getInputStream();
      PutResponse response = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response.getError(), ServerErrorCode.No_Error);
      PutRequest putRequest2 = new PutRequest(1, "client1", blobId2, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      PutResponse response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      PutRequest putRequest3 = new PutRequest(1, "client1", blobId3, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel3.send(putRequest3);
      putResponseStream = channel3.receive().getInputStream();
      PutResponse response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      putRequest = new PutRequest(1, "client1", blobId4, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel1.send(putRequest);
      putResponseStream = channel1.receive().getInputStream();
      response = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response.getError(), ServerErrorCode.No_Error);
      putRequest2 = new PutRequest(1, "client1", blobId5, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      putRequest3 = new PutRequest(1, "client1", blobId6, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel3.send(putRequest3);
      putResponseStream = channel3.receive().getInputStream();
      response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      notificationSystem.awaitBlobCreations(blobId1.getID());
      notificationSystem.awaitBlobCreations(blobId2.getID());
      notificationSystem.awaitBlobCreations(blobId3.getID());
      notificationSystem.awaitBlobCreations(blobId4.getID());
      notificationSystem.awaitBlobCreations(blobId5.getID());
      notificationSystem.awaitBlobCreations(blobId6.getID());
      ArrayList<BlobId> ids = new ArrayList<BlobId>();
      MockPartitionId mockPartitionId = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(blobId3);
      ArrayList<PartitionRequestInfo> partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
      PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(mockPartitionId, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest1 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
      channel2.send(getRequest1);
      InputStream stream = channel2.receive().getInputStream();
      GetResponse resp1 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp1.getError(), ServerErrorCode.No_Error);
      Assert.assertEquals(resp1.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.No_Error);
      try {
        BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp1.getInputStream());
        Assert.assertEquals(propertyOutput.getBlobSize(), 1000);
        Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      ids.clear();
      ids.add(blobId2);
      GetRequest getRequest2 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
      channel1.send(getRequest2);
      stream = channel1.receive().getInputStream();
      GetResponse resp2 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp2.getError(), ServerErrorCode.No_Error);
      Assert.assertEquals(resp2.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.No_Error);
      try {
        ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp2.getInputStream());
        Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      ids.clear();
      ids.add(blobId1);
      GetRequest getRequest3 = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
      channel3.send(getRequest3);
      stream = channel3.receive().getInputStream();
      GetResponse resp3 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      try {
        BlobOutput blobOutput = MessageFormatRecord.deserializeBlob(resp3.getInputStream());
        byte[] blobout = new byte[(int)blobOutput.getSize()];
        int readsize = 0;
        while (readsize < blobOutput.getSize()){
          readsize += blobOutput.getStream().read(blobout, readsize, (int)blobOutput.getSize() - readsize);
        }
        Assert.assertArrayEquals(blobout, data);
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      try {
        coordinatorProps.setProperty("ssl.enabled.datacenters", sslEnabledDatacenters);
        Properties coordinatorProperties = getCoordinatorProperties(coordinatorDatacenter);
        coordinatorProperties.putAll(coordinatorProps);
        Coordinator coordinator = new AmbryCoordinator(new VerifiableProperties(coordinatorProperties), clusterMap);
        checkBlobId(coordinator, blobId1, data);
        checkBlobId(coordinator, blobId2, data);
        checkBlobId(coordinator, blobId3, data);
        checkBlobId(coordinator, blobId4, data);
        checkBlobId(coordinator, blobId5, data);
        checkBlobId(coordinator, blobId6, data);
        coordinator.close();
      }
      catch (CoordinatorException e) {
        e.printStackTrace();
        Assert.assertEquals(false, true);
      }
      ids = new ArrayList<BlobId>();
      mockPartitionId = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(new BlobId(mockPartitionId));
      partitionRequestInfoList.clear();
      partitionRequestInfo = new PartitionRequestInfo(mockPartitionId, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest4 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
      channel3.send(getRequest4);
      stream = channel3.receive().getInputStream();
      GetResponse resp4 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp4.getError(), ServerErrorCode.No_Error);
      Assert.assertEquals(resp4.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Not_Found);
      DeleteRequest deleteRequest = new DeleteRequest(1, "reptest", blobId1);
      channel1.send(deleteRequest);
      InputStream deleteResponseStream = channel1.receive().getInputStream();
      DeleteResponse deleteResponse = DeleteResponse.readFrom(new DataInputStream(deleteResponseStream));
      Assert.assertEquals(deleteResponse.getError(), ServerErrorCode.No_Error);
      notificationSystem.awaitBlobDeletions(blobId1.getID());
      ids = new ArrayList<BlobId>();
      ids.add(blobId1);
      partitionRequestInfoList.clear();
      partitionRequestInfo = new PartitionRequestInfo(partition, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest5 = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
      channel3.send(getRequest5);
      stream = channel3.receive().getInputStream();
      GetResponse resp5 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp5.getError(), ServerErrorCode.No_Error);
      Assert.assertEquals(resp5.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Deleted);
      cluster.getServers().get(0).shutdown();
      cluster.getServers().get(0).awaitShutdown();
      DataNodeId dataNodeId = clusterMap.getDataNodeId("localhost", interestedDataNodePortNumber);
      List<String> mountPaths = ((MockDataNodeId)dataNodeId).getMountPaths();
      Set<String> setToCheck = new HashSet<String>();
      List<ReplicaId> replicaIds = clusterMap.getReplicaIds(dataNodeId);
      for (ReplicaId replicaId : replicaIds) {
        List<ReplicaId> peerReplicas = replicaId.getPeerReplicaIds();
        for (ReplicaId peerReplica : peerReplicas) {
          setToCheck.add(replicaId.getPartitionId().toString() + peerReplica.getDataNodeId().getHostname() + peerReplica.getDataNodeId().getPort());
        }
      }
      for (String mountPath : mountPaths) {
        File replicaTokenFile = new File(mountPath, "replicaTokens");
        if (replicaTokenFile.exists()) {
          CrcInputStream crcStream = new CrcInputStream(new FileInputStream(replicaTokenFile));
          DataInputStream dataInputStream = new DataInputStream(crcStream);
          try {
            short version = dataInputStream.readShort();
            Assert.assertEquals(version, 0);
            StoreKeyFactory storeKeyFactory = Utils.getObj("com.github.ambry.commons.BlobIdFactory", clusterMap);
            FindTokenFactory factory = Utils.getObj("com.github.ambry.store.StoreFindTokenFactory", storeKeyFactory);
            System.out.println("setToCheck" + setToCheck.size());
            while (dataInputStream.available() > 8){
              PartitionId partitionId = clusterMap.getPartitionIdFromStream(dataInputStream);
              String hostname = Utils.readIntString(dataInputStream);
              Utils.readIntString(dataInputStream);
              int port = dataInputStream.readInt();
              Assert.assertTrue(setToCheck.contains(partitionId.toString() + hostname + port));
              setToCheck.remove(partitionId.toString() + hostname + port);
              dataInputStream.readLong();
              FindToken token = factory.getFindToken(dataInputStream);
              System.out.println("partitionId " + partitionId + " hostname " + hostname + " port " + port + " token " + token);
              ByteBuffer bytebufferToken = ByteBuffer.wrap(token.toBytes());
              Assert.assertEquals(bytebufferToken.getShort(), 0);
              int size = bytebufferToken.getInt();
              bytebufferToken.position(bytebufferToken.position() + size);
              long parsedToken = bytebufferToken.getLong();
              System.out.println("The parsed token is " + parsedToken);
              Assert.assertTrue(parsedToken == -1 || parsedToken == 13062);
            }
            long crc = crcStream.getValue();
            Assert.assertEquals(crc, dataInputStream.readLong());
          }
          catch (IOException e) {
            Assert.assertTrue(false);
          }
          finally {
            dataInputStream.close();
          }
        }
        else {
          Assert.assertTrue(false);
        }
      }
      putRequest2 = new PutRequest(1, "client1", blobId7, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      putRequest3 = new PutRequest(1, "client1", blobId8, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel3.send(putRequest3);
      putResponseStream = channel3.receive().getInputStream();
      response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      putRequest2 = new PutRequest(1, "client1", blobId9, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      putRequest3 = new PutRequest(1, "client1", blobId10, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel3.send(putRequest3);
      putResponseStream = channel3.receive().getInputStream();
      response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      putRequest2 = new PutRequest(1, "client1", blobId11, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      cluster.getServers().get(0).startup();
      notificationSystem.awaitBlobCreations(blobId7.getID());
      notificationSystem.awaitBlobCreations(blobId8.getID());
      notificationSystem.awaitBlobCreations(blobId9.getID());
      notificationSystem.awaitBlobCreations(blobId10.getID());
      notificationSystem.awaitBlobCreations(blobId11.getID());
      channel1.disconnect();
      channel1.connect();
      try {
        checkBlobContent(clusterMap, blobId2, channel1, data);
        checkBlobContent(clusterMap, blobId3, channel1, data);
        checkBlobContent(clusterMap, blobId4, channel1, data);
        checkBlobContent(clusterMap, blobId5, channel1, data);
        checkBlobContent(clusterMap, blobId6, channel1, data);
        checkBlobContent(clusterMap, blobId7, channel1, data);
        checkBlobContent(clusterMap, blobId8, channel1, data);
        checkBlobContent(clusterMap, blobId9, channel1, data);
        checkBlobContent(clusterMap, blobId10, channel1, data);
        checkBlobContent(clusterMap, blobId11, channel1, data);
      }
      catch (MessageFormatException e) {
        Assert.assertFalse(true);
      }
      cluster.getServers().get(0).shutdown();
      cluster.getServers().get(0).awaitShutdown();
      File mountFile = new File(clusterMap.getReplicaIds(dataNodeId).get(0).getMountPath());
      for (File toDelete : mountFile.listFiles()) {
        deleteFolderContent(toDelete, true);
      }
      notificationSystem.decrementCreatedReplica(blobId2.getID());
      notificationSystem.decrementCreatedReplica(blobId3.getID());
      notificationSystem.decrementCreatedReplica(blobId4.getID());
      notificationSystem.decrementCreatedReplica(blobId5.getID());
      notificationSystem.decrementCreatedReplica(blobId6.getID());
      notificationSystem.decrementCreatedReplica(blobId7.getID());
      notificationSystem.decrementCreatedReplica(blobId8.getID());
      notificationSystem.decrementCreatedReplica(blobId9.getID());
      notificationSystem.decrementCreatedReplica(blobId10.getID());
      notificationSystem.decrementCreatedReplica(blobId11.getID());
      cluster.getServers().get(0).startup();
      notificationSystem.awaitBlobCreations(blobId2.getID());
      notificationSystem.awaitBlobCreations(blobId3.getID());
      notificationSystem.awaitBlobCreations(blobId4.getID());
      notificationSystem.awaitBlobCreations(blobId5.getID());
      notificationSystem.awaitBlobCreations(blobId6.getID());
      notificationSystem.awaitBlobCreations(blobId7.getID());
      notificationSystem.awaitBlobCreations(blobId8.getID());
      notificationSystem.awaitBlobCreations(blobId9.getID());
      notificationSystem.awaitBlobCreations(blobId10.getID());
      notificationSystem.awaitBlobCreations(blobId11.getID());
      channel1.disconnect();
      channel1.connect();
      try {
        checkBlobContent(clusterMap, blobId2, channel1, data);
        checkBlobContent(clusterMap, blobId3, channel1, data);
        checkBlobContent(clusterMap, blobId4, channel1, data);
        checkBlobContent(clusterMap, blobId5, channel1, data);
        checkBlobContent(clusterMap, blobId6, channel1, data);
        checkBlobContent(clusterMap, blobId7, channel1, data);
        checkBlobContent(clusterMap, blobId8, channel1, data);
        checkBlobContent(clusterMap, blobId9, channel1, data);
        checkBlobContent(clusterMap, blobId10, channel1, data);
        checkBlobContent(clusterMap, blobId11, channel1, data);
      }
      catch (MessageFormatException e) {
        Assert.assertFalse(true);
      }
      channel1.disconnect();
      channel2.disconnect();
      channel3.disconnect();
    }
    catch (Exception e) {
      e.printStackTrace();
      Assert.assertTrue(false);
    }
=======
cluster = new MockCluster(notificationSystem, enableSSLPorts, sslEnabledDatacentersForDC1, sslEnabledDatacentersForDC2, sslEnabledDatacentersForDC3, SystemTime.getInstance());
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void endToEndReplicationWithMultiNodeSinglePartitionTest(String coordinatorDatacenter, String sslEnabledDatacenters, int interestedDataNodePortNumber, Port dataNode1Port, Port dataNode2Port, Port dataNode3Port, MockCluster cluster) throws InterruptedException, IOException, InstantiationException {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
try {
      MockClusterMap clusterMap = cluster.getClusterMap();
      byte[] usermetadata = new byte[1000];
      byte[] data = new byte[1000];
      BlobProperties properties = new BlobProperties(1000, "serviceid1");
      new Random().nextBytes(usermetadata);
      new Random().nextBytes(data);
      PartitionId partition = clusterMap.getWritablePartitionIds().get(0);
      BlobId blobId1 = new BlobId(partition);
      BlobId blobId2 = new BlobId(partition);
      BlobId blobId3 = new BlobId(partition);
      BlobId blobId4 = new BlobId(partition);
      BlobId blobId5 = new BlobId(partition);
      BlobId blobId6 = new BlobId(partition);
      BlobId blobId7 = new BlobId(partition);
      BlobId blobId8 = new BlobId(partition);
      BlobId blobId9 = new BlobId(partition);
      BlobId blobId10 = new BlobId(partition);
      BlobId blobId11 = new BlobId(partition);
      PutRequest putRequest = new PutRequest(1, "client1", blobId1, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      BlockingChannel channel1 = getBlockingChannelBasedOnPortType(dataNode1Port, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      BlockingChannel channel2 = getBlockingChannelBasedOnPortType(dataNode2Port, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      BlockingChannel channel3 = getBlockingChannelBasedOnPortType(dataNode3Port, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      channel1.connect();
      channel2.connect();
      channel3.connect();
      channel1.send(putRequest);
      InputStream putResponseStream = channel1.receive().getInputStream();
      PutResponse response = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response.getError(), ServerErrorCode.No_Error);
      PutRequest putRequest2 = new PutRequest(1, "client1", blobId2, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      PutResponse response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      PutRequest putRequest3 = new PutRequest(1, "client1", blobId3, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel3.send(putRequest3);
      putResponseStream = channel3.receive().getInputStream();
      PutResponse response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      putRequest = new PutRequest(1, "client1", blobId4, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel1.send(putRequest);
      putResponseStream = channel1.receive().getInputStream();
      response = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response.getError(), ServerErrorCode.No_Error);
      putRequest2 = new PutRequest(1, "client1", blobId5, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      putRequest3 = new PutRequest(1, "client1", blobId6, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel3.send(putRequest3);
      putResponseStream = channel3.receive().getInputStream();
      response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      notificationSystem.awaitBlobCreations(blobId1.getID());
      notificationSystem.awaitBlobCreations(blobId2.getID());
      notificationSystem.awaitBlobCreations(blobId3.getID());
      notificationSystem.awaitBlobCreations(blobId4.getID());
      notificationSystem.awaitBlobCreations(blobId5.getID());
      notificationSystem.awaitBlobCreations(blobId6.getID());
      ArrayList<BlobId> ids = new ArrayList<BlobId>();
      MockPartitionId mockPartitionId = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(blobId3);
      ArrayList<PartitionRequestInfo> partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
      PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(mockPartitionId, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest1 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
      channel2.send(getRequest1);
      InputStream stream = channel2.receive().getInputStream();
      GetResponse resp1 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp1.getError(), ServerErrorCode.No_Error);
      Assert.assertEquals(resp1.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.No_Error);
      try {
        BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp1.getInputStream());
        Assert.assertEquals(propertyOutput.getBlobSize(), 1000);
        Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      ids.clear();
      ids.add(blobId2);
      GetRequest getRequest2 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
      channel1.send(getRequest2);
      stream = channel1.receive().getInputStream();
      GetResponse resp2 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp2.getError(), ServerErrorCode.No_Error);
      Assert.assertEquals(resp2.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.No_Error);
      try {
        ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp2.getInputStream());
        Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      ids.clear();
      ids.add(blobId1);
      GetRequest getRequest3 = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
      channel3.send(getRequest3);
      stream = channel3.receive().getInputStream();
      GetResponse resp3 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      try {
        BlobOutput blobOutput = MessageFormatRecord.deserializeBlob(resp3.getInputStream());
        byte[] blobout = new byte[(int)blobOutput.getSize()];
        int readsize = 0;
        while (readsize < blobOutput.getSize()){
          readsize += blobOutput.getStream().read(blobout, readsize, (int)blobOutput.getSize() - readsize);
        }
        Assert.assertArrayEquals(blobout, data);
      }
      catch (MessageFormatException e) {
        Assert.assertEquals(false, true);
      }
      try {
        coordinatorProps.setProperty("ssl.enabled.datacenters", sslEnabledDatacenters);
        Properties coordinatorProperties = getCoordinatorProperties(coordinatorDatacenter);
        coordinatorProperties.putAll(coordinatorProps);
        Coordinator coordinator = new AmbryCoordinator(new VerifiableProperties(coordinatorProperties), clusterMap);
        checkBlobId(coordinator, blobId1, data);
        checkBlobId(coordinator, blobId2, data);
        checkBlobId(coordinator, blobId3, data);
        checkBlobId(coordinator, blobId4, data);
        checkBlobId(coordinator, blobId5, data);
        checkBlobId(coordinator, blobId6, data);
        coordinator.close();
      }
      catch (CoordinatorException e) {
        e.printStackTrace();
        Assert.assertEquals(false, true);
      }
      ids = new ArrayList<BlobId>();
      mockPartitionId = (MockPartitionId)clusterMap.getWritablePartitionIds().get(0);
      ids.add(new BlobId(mockPartitionId));
      partitionRequestInfoList.clear();
      partitionRequestInfo = new PartitionRequestInfo(mockPartitionId, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest4 = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
      channel3.send(getRequest4);
      stream = channel3.receive().getInputStream();
      GetResponse resp4 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp4.getError(), ServerErrorCode.No_Error);
      Assert.assertEquals(resp4.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Not_Found);
      DeleteRequest deleteRequest = new DeleteRequest(1, "reptest", blobId1);
      channel1.send(deleteRequest);
      InputStream deleteResponseStream = channel1.receive().getInputStream();
      DeleteResponse deleteResponse = DeleteResponse.readFrom(new DataInputStream(deleteResponseStream));
      Assert.assertEquals(deleteResponse.getError(), ServerErrorCode.No_Error);
      notificationSystem.awaitBlobDeletions(blobId1.getID());
      ids = new ArrayList<BlobId>();
      ids.add(blobId1);
      partitionRequestInfoList.clear();
      partitionRequestInfo = new PartitionRequestInfo(partition, ids);
      partitionRequestInfoList.add(partitionRequestInfo);
      GetRequest getRequest5 = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
      channel3.send(getRequest5);
      stream = channel3.receive().getInputStream();
      GetResponse resp5 = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
      Assert.assertEquals(resp5.getError(), ServerErrorCode.No_Error);
      Assert.assertEquals(resp5.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Deleted);
      cluster.getServers().get(0).shutdown();
      cluster.getServers().get(0).awaitShutdown();
      DataNodeId dataNodeId = clusterMap.getDataNodeId("localhost", interestedDataNodePortNumber);
      List<String> mountPaths = ((MockDataNodeId)dataNodeId).getMountPaths();
      Set<String> setToCheck = new HashSet<String>();
      List<ReplicaId> replicaIds = clusterMap.getReplicaIds(dataNodeId);
      for (ReplicaId replicaId : replicaIds) {
        List<ReplicaId> peerReplicas = replicaId.getPeerReplicaIds();
        for (ReplicaId peerReplica : peerReplicas) {
          setToCheck.add(replicaId.getPartitionId().toString() + peerReplica.getDataNodeId().getHostname() + peerReplica.getDataNodeId().getPort());
        }
      }
      for (String mountPath : mountPaths) {
        File replicaTokenFile = new File(mountPath, "replicaTokens");
        if (replicaTokenFile.exists()) {
          CrcInputStream crcStream = new CrcInputStream(new FileInputStream(replicaTokenFile));
          DataInputStream dataInputStream = new DataInputStream(crcStream);
          try {
            short version = dataInputStream.readShort();
            Assert.assertEquals(version, 0);
            StoreKeyFactory storeKeyFactory = Utils.getObj("com.github.ambry.commons.BlobIdFactory", clusterMap);
            FindTokenFactory factory = Utils.getObj("com.github.ambry.store.StoreFindTokenFactory", storeKeyFactory);
            System.out.println("setToCheck" + setToCheck.size());
            while (dataInputStream.available() > 8){
              PartitionId partitionId = clusterMap.getPartitionIdFromStream(dataInputStream);
              String hostname = Utils.readIntString(dataInputStream);
              Utils.readIntString(dataInputStream);
              int port = dataInputStream.readInt();
              Assert.assertTrue(setToCheck.contains(partitionId.toString() + hostname + port));
              setToCheck.remove(partitionId.toString() + hostname + port);
              dataInputStream.readLong();
              FindToken token = factory.getFindToken(dataInputStream);
              System.out.println("partitionId " + partitionId + " hostname " + hostname + " port " + port + " token " + token);
              ByteBuffer bytebufferToken = ByteBuffer.wrap(token.toBytes());
              Assert.assertEquals(bytebufferToken.getShort(), 0);
              int size = bytebufferToken.getInt();
              bytebufferToken.position(bytebufferToken.position() + size);
              long parsedToken = bytebufferToken.getLong();
              System.out.println("The parsed token is " + parsedToken);
              Assert.assertTrue(parsedToken == -1 || parsedToken == 13062);
            }
            long crc = crcStream.getValue();
            Assert.assertEquals(crc, dataInputStream.readLong());
          }
          catch (IOException e) {
            Assert.assertTrue(false);
          }
          finally {
            dataInputStream.close();
          }
        }
        else {
          Assert.assertTrue(false);
        }
      }
      putRequest2 = new PutRequest(1, "client1", blobId7, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      putRequest3 = new PutRequest(1, "client1", blobId8, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel3.send(putRequest3);
      putResponseStream = channel3.receive().getInputStream();
      response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      putRequest2 = new PutRequest(1, "client1", blobId9, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      putRequest3 = new PutRequest(1, "client1", blobId10, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel3.send(putRequest3);
      putResponseStream = channel3.receive().getInputStream();
      response3 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response3.getError(), ServerErrorCode.No_Error);
      putRequest2 = new PutRequest(1, "client1", blobId11, properties, ByteBuffer.wrap(usermetadata), new ByteBufferInputStream(ByteBuffer.wrap(data)));
      channel2.send(putRequest2);
      putResponseStream = channel2.receive().getInputStream();
      response2 = PutResponse.readFrom(new DataInputStream(putResponseStream));
      Assert.assertEquals(response2.getError(), ServerErrorCode.No_Error);
      cluster.getServers().get(0).startup();
      notificationSystem.awaitBlobCreations(blobId7.getID());
      notificationSystem.awaitBlobCreations(blobId8.getID());
      notificationSystem.awaitBlobCreations(blobId9.getID());
      notificationSystem.awaitBlobCreations(blobId10.getID());
      notificationSystem.awaitBlobCreations(blobId11.getID());
      channel1.disconnect();
      channel1.connect();
      try {
        checkBlobContent(clusterMap, blobId2, channel1, data);
        checkBlobContent(clusterMap, blobId3, channel1, data);
        checkBlobContent(clusterMap, blobId4, channel1, data);
        checkBlobContent(clusterMap, blobId5, channel1, data);
        checkBlobContent(clusterMap, blobId6, channel1, data);
        checkBlobContent(clusterMap, blobId7, channel1, data);
        checkBlobContent(clusterMap, blobId8, channel1, data);
        checkBlobContent(clusterMap, blobId9, channel1, data);
        checkBlobContent(clusterMap, blobId10, channel1, data);
        checkBlobContent(clusterMap, blobId11, channel1, data);
      }
      catch (MessageFormatException e) {
        Assert.assertFalse(true);
      }
      cluster.getServers().get(0).shutdown();
      cluster.getServers().get(0).awaitShutdown();
      File mountFile = new File(clusterMap.getReplicaIds(dataNodeId).get(0).getMountPath());
      for (File toDelete : mountFile.listFiles()) {
        deleteFolderContent(toDelete, true);
      }
      notificationSystem.decrementCreatedReplica(blobId2.getID());
      notificationSystem.decrementCreatedReplica(blobId3.getID());
      notificationSystem.decrementCreatedReplica(blobId4.getID());
      notificationSystem.decrementCreatedReplica(blobId5.getID());
      notificationSystem.decrementCreatedReplica(blobId6.getID());
      notificationSystem.decrementCreatedReplica(blobId7.getID());
      notificationSystem.decrementCreatedReplica(blobId8.getID());
      notificationSystem.decrementCreatedReplica(blobId9.getID());
      notificationSystem.decrementCreatedReplica(blobId10.getID());
      notificationSystem.decrementCreatedReplica(blobId11.getID());
      cluster.getServers().get(0).startup();
      notificationSystem.awaitBlobCreations(blobId2.getID());
      notificationSystem.awaitBlobCreations(blobId3.getID());
      notificationSystem.awaitBlobCreations(blobId4.getID());
      notificationSystem.awaitBlobCreations(blobId5.getID());
      notificationSystem.awaitBlobCreations(blobId6.getID());
      notificationSystem.awaitBlobCreations(blobId7.getID());
      notificationSystem.awaitBlobCreations(blobId8.getID());
      notificationSystem.awaitBlobCreations(blobId9.getID());
      notificationSystem.awaitBlobCreations(blobId10.getID());
      notificationSystem.awaitBlobCreations(blobId11.getID());
      channel1.disconnect();
      channel1.connect();
      try {
        checkBlobContent(clusterMap, blobId2, channel1, data);
        checkBlobContent(clusterMap, blobId3, channel1, data);
        checkBlobContent(clusterMap, blobId4, channel1, data);
        checkBlobContent(clusterMap, blobId5, channel1, data);
        checkBlobContent(clusterMap, blobId6, channel1, data);
        checkBlobContent(clusterMap, blobId7, channel1, data);
        checkBlobContent(clusterMap, blobId8, channel1, data);
        checkBlobContent(clusterMap, blobId9, channel1, data);
        checkBlobContent(clusterMap, blobId10, channel1, data);
        checkBlobContent(clusterMap, blobId11, channel1, data);
      }
      catch (MessageFormatException e) {
        Assert.assertFalse(true);
      }
      channel1.disconnect();
      channel2.disconnect();
      channel3.disconnect();
    }
    catch (Exception e) {
      e.printStackTrace();
      Assert.assertTrue(false);
    }
=======
cluster = new MockCluster(notificationSystem, enableSSLPorts, sslEnabledDatacentersForDC1, sslEnabledDatacentersForDC2, sslEnabledDatacentersForDC3, SystemTime.getInstance());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_base_98cfd5d\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
try {
      MockClusterMap clusterMap = cluster.getClusterMap();
      List<AmbryServer> serverList = cluster.getServers();
      byte[] usermetadata = new byte[100];
      byte[] data = new byte[100];
      BlobProperties properties = new BlobProperties(100, "serviceid1");
      new Random().nextBytes(usermetadata);
      new Random().nextBytes(data);
      BlockingChannel channel1 = getBlockingChannelBasedOnPortType(dataNode1Port, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      BlockingChannel channel2 = getBlockingChannelBasedOnPortType(dataNode2Port, "localhost", clientSSLSocketFactory2, clientSSLConfig2);
      BlockingChannel channel3 = getBlockingChannelBasedOnPortType(dataNode3Port, "localhost", clientSSLSocketFactory3, clientSSLConfig3);
      channel1.connect();
      channel2.connect();
      channel3.connect();
      int noOfParallelThreads = 3;
      CountDownLatch latch = new CountDownLatch(noOfParallelThreads);
      List<PutRequestRunnable> runnables = new ArrayList<PutRequestRunnable>(noOfParallelThreads);
      BlockingChannel channel = null;
      for (int i = 0; i < noOfParallelThreads; i++) {
        if (i % noOfParallelThreads == 0) {
          channel = channel1;
        }
        else 
          if (i % noOfParallelThreads == 1) {
            channel = channel2;
          }
          else 
            if (i % noOfParallelThreads == 2) {
              channel = channel3;
            }
        PutRequestRunnable runnable = new PutRequestRunnable(cluster, channel, 50, data, usermetadata, properties, latch);
        runnables.add(runnable);
        Thread threadToRun = new Thread(runnable);
        threadToRun.start();
      }
      latch.await();
      List<BlobId> blobIds = new ArrayList<BlobId>();
      for (int i = 0; i < runnables.size(); i++) {
        blobIds.addAll(runnables.get(i).getBlobIds());
      }
      for (BlobId blobId : blobIds) {
        notificationSystem.awaitBlobCreations(blobId.getID());
      }
      for (int i = 0; i < 3; i++) {
        channel = null;
        if (i == 0) {
          channel = channel1;
        }
        else 
          if (i == 1) {
            channel = channel2;
          }
          else 
            if (i == 2) {
              channel = channel3;
            }
        ArrayList<PartitionRequestInfo> partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
        for (int j = 0; j < blobIds.size(); j++) {
          ArrayList<BlobId> ids = new ArrayList<BlobId>();
          ids.add(blobIds.get(j));
          partitionRequestInfoList.clear();
          PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
          partitionRequestInfoList.add(partitionRequestInfo);
          GetRequest getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
          channel.send(getRequest);
          InputStream stream = channel.receive().getInputStream();
          GetResponse resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
          try {
            BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp.getInputStream());
            Assert.assertEquals(propertyOutput.getBlobSize(), 100);
            Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
          ids.clear();
          ids.add(blobIds.get(j));
          partitionRequestInfoList.clear();
          partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
          partitionRequestInfoList.add(partitionRequestInfo);
          getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
          channel.send(getRequest);
          stream = channel.receive().getInputStream();
          resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
          try {
            ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp.getInputStream());
            Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
          }
          catch (MessageFormatException e) {
            e.printStackTrace();
            Assert.assertEquals(false, true);
          }
          ids.clear();
          ids.add(blobIds.get(j));
          partitionRequestInfoList.clear();
          partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
          partitionRequestInfoList.add(partitionRequestInfo);
          getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
          channel.send(getRequest);
          stream = channel.receive().getInputStream();
          resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
          try {
            BlobOutput blobOutput = MessageFormatRecord.deserializeBlob(resp.getInputStream());
            byte[] blobout = new byte[(int)blobOutput.getSize()];
            int readsize = 0;
            while (readsize < blobOutput.getSize()){
              readsize += blobOutput.getStream().read(blobout, readsize, (int)blobOutput.getSize() - readsize);
            }
            Assert.assertArrayEquals(blobout, data);
          }
          catch (MessageFormatException e) {
            e.printStackTrace();
            Assert.assertEquals(false, true);
          }
        }
      }
      Set<BlobId> blobsDeleted = new HashSet<BlobId>();
      Set<BlobId> blobsChecked = new HashSet<BlobId>();
      for (int i = 0; i < blobIds.size(); i++) {
        int j = new Random().nextInt(3);
        if (j == 0) {
          j = new Random().nextInt(3);
          if (j == 0) {
            channel = channel1;
          }
          else 
            if (j == 1) {
              channel = channel2;
            }
            else 
              if (j == 2) {
                channel = channel3;
              }
          DeleteRequest deleteRequest = new DeleteRequest(1, "reptest", blobIds.get(i));
          channel.send(deleteRequest);
          InputStream deleteResponseStream = channel.receive().getInputStream();
          DeleteResponse deleteResponse = DeleteResponse.readFrom(new DataInputStream(deleteResponseStream));
          Assert.assertEquals(deleteResponse.getError(), ServerErrorCode.No_Error);
          blobsDeleted.add(blobIds.get(i));
        }
      }
      Iterator<BlobId> iterator = blobsDeleted.iterator();
      ArrayList<PartitionRequestInfo> partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
      while (iterator.hasNext()){
        BlobId deletedId = iterator.next();
        notificationSystem.awaitBlobDeletions(deletedId.getID());
        for (int j = 0; j < 3; j++) {
          if (j == 0) {
            channel = channel1;
          }
          else 
            if (j == 1) {
              channel = channel2;
            }
            else 
              if (j == 2) {
                channel = channel3;
              }
          ArrayList<BlobId> ids = new ArrayList<BlobId>();
          ids.add(deletedId);
          partitionRequestInfoList.clear();
          PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(deletedId.getPartition(), ids);
          partitionRequestInfoList.add(partitionRequestInfo);
          GetRequest getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
          channel.send(getRequest);
          InputStream stream = channel.receive().getInputStream();
          GetResponse resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
          Assert.assertEquals(resp.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Deleted);
        }
      }
      serverList.get(0).shutdown();
      serverList.get(0).awaitShutdown();
      MockDataNodeId dataNode = (MockDataNodeId)clusterMap.getDataNodeId("localhost", interestedDataNodePortNumber);
      System.out.println("Cleaning mount path " + dataNode.getMountPaths().get(0));
      for (ReplicaId replicaId : clusterMap.getReplicaIds(dataNode)) {
        if (replicaId.getMountPath().compareToIgnoreCase(dataNode.getMountPaths().get(0)) == 0) {
          System.out.println("Cleaning partition " + replicaId.getPartitionId());
        }
      }
      deleteFolderContent(new File(dataNode.getMountPaths().get(0)), false);
      int totalblobs = 0;
      for (int i = 0; i < blobIds.size(); i++) {
        for (ReplicaId replicaId : blobIds.get(i).getPartition().getReplicaIds()) {
          if (replicaId.getMountPath().compareToIgnoreCase(dataNode.getMountPaths().get(0)) == 0) {
            if (blobsDeleted.contains(blobIds.get(i))) {
              notificationSystem.decrementDeletedReplica(blobIds.get(i).getID());
            }
            else {
              totalblobs++;
              notificationSystem.decrementCreatedReplica(blobIds.get(i).getID());
            }
          }
        }
      }
      serverList.get(0).startup();
      channel1.disconnect();
      channel1.connect();
      for (int j = 0; j < blobIds.size(); j++) {
        if (blobsDeleted.contains(blobIds.get(j))) {
          notificationSystem.awaitBlobDeletions(blobIds.get(j).getID());
        }
        else {
          notificationSystem.awaitBlobCreations(blobIds.get(j).getID());
        }
        ArrayList<BlobId> ids = new ArrayList<BlobId>();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        GetRequest getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        InputStream stream = channel1.receive().getInputStream();
        GetResponse resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsDeleted.contains(blobIds.get(j)));
        }
        else {
          try {
            BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp.getInputStream());
            Assert.assertEquals(propertyOutput.getBlobSize(), 100);
            Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
        ids.clear();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        stream = channel1.receive().getInputStream();
        resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsDeleted.contains(blobIds.get(j)));
        }
        else {
          try {
            ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp.getInputStream());
            Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
        ids.clear();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        stream = channel1.receive().getInputStream();
        resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsDeleted.contains(blobIds.get(j)));
          blobsDeleted.remove(blobIds.get(j));
          blobsChecked.add(blobIds.get(j));
        }
        else {
          try {
            BlobOutput blobOutput = MessageFormatRecord.deserializeBlob(resp.getInputStream());
            byte[] blobout = new byte[(int)blobOutput.getSize()];
            int readsize = 0;
            while (readsize < blobOutput.getSize()){
              readsize += blobOutput.getStream().read(blobout, readsize, (int)blobOutput.getSize() - readsize);
            }
            Assert.assertArrayEquals(blobout, data);
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
      }
      Assert.assertEquals(blobsDeleted.size(), 0);
      serverList.get(0).shutdown();
      serverList.get(0).awaitShutdown();
      dataNode = (MockDataNodeId)clusterMap.getDataNodeId("localhost", interestedDataNodePortNumber);
      for (int i = 0; i < dataNode.getMountPaths().size(); i++) {
        System.out.println("Cleaning mount path " + dataNode.getMountPaths().get(i));
        for (ReplicaId replicaId : clusterMap.getReplicaIds(dataNode)) {
          if (replicaId.getMountPath().compareToIgnoreCase(dataNode.getMountPaths().get(i)) == 0) {
            System.out.println("Cleaning partition " + replicaId.getPartitionId());
          }
        }
        deleteFolderContent(new File(dataNode.getMountPaths().get(i)), false);
      }
      for (int i = 0; i < blobIds.size(); i++) {
        if (blobsChecked.contains(blobIds.get(i))) {
          notificationSystem.decrementDeletedReplica(blobIds.get(i).getID());
        }
        else {
          notificationSystem.decrementCreatedReplica(blobIds.get(i).getID());
        }
      }
      serverList.get(0).startup();
      channel1.disconnect();
      channel1.connect();
      for (int j = 0; j < blobIds.size(); j++) {
        if (blobsChecked.contains(blobIds.get(j))) {
          notificationSystem.awaitBlobDeletions(blobIds.get(j).getID());
        }
        else {
          notificationSystem.awaitBlobCreations(blobIds.get(j).getID());
        }
        ArrayList<BlobId> ids = new ArrayList<BlobId>();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        GetRequest getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        InputStream stream = channel1.receive().getInputStream();
        GetResponse resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsChecked.contains(blobIds.get(j)));
        }
        else {
          try {
            BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp.getInputStream());
            Assert.assertEquals(propertyOutput.getBlobSize(), 100);
            Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
        ids.clear();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        stream = channel1.receive().getInputStream();
        resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsChecked.contains(blobIds.get(j)));
        }
        else {
          try {
            ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp.getInputStream());
            Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
        ids.clear();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        stream = channel1.receive().getInputStream();
        resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsChecked.contains(blobIds.get(j)));
          blobsChecked.remove(blobIds.get(j));
        }
        else {
          try {
            BlobOutput blobOutput = MessageFormatRecord.deserializeBlob(resp.getInputStream());
            byte[] blobout = new byte[(int)blobOutput.getSize()];
            int readsize = 0;
            while (readsize < blobOutput.getSize()){
              readsize += blobOutput.getStream().read(blobout, readsize, (int)blobOutput.getSize() - readsize);
            }
            Assert.assertArrayEquals(blobout, data);
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
      }
      Assert.assertEquals(blobsChecked.size(), 0);
      channel1.disconnect();
      channel2.disconnect();
      channel3.disconnect();
    }
    catch (Exception e) {
      e.printStackTrace();
      Assert.assertTrue(false);
    }
=======
cluster = new MockCluster(notificationSystem, enableSSLPorts, sslEnabledDatacentersForDC1, sslEnabledDatacentersForDC2, sslEnabledDatacentersForDC3, SystemTime.getInstance());
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void endToEndReplicationWithMultiNodeMultiPartitionTest(int interestedDataNodePortNumber, Port dataNode1Port, Port dataNode2Port, Port dataNode3Port, MockCluster cluster) throws InterruptedException, IOException, InstantiationException {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
try {
      MockClusterMap clusterMap = cluster.getClusterMap();
      List<AmbryServer> serverList = cluster.getServers();
      byte[] usermetadata = new byte[100];
      byte[] data = new byte[100];
      BlobProperties properties = new BlobProperties(100, "serviceid1");
      new Random().nextBytes(usermetadata);
      new Random().nextBytes(data);
      BlockingChannel channel1 = getBlockingChannelBasedOnPortType(dataNode1Port, "localhost", clientSSLSocketFactory1, clientSSLConfig1);
      BlockingChannel channel2 = getBlockingChannelBasedOnPortType(dataNode2Port, "localhost", clientSSLSocketFactory2, clientSSLConfig2);
      BlockingChannel channel3 = getBlockingChannelBasedOnPortType(dataNode3Port, "localhost", clientSSLSocketFactory3, clientSSLConfig3);
      channel1.connect();
      channel2.connect();
      channel3.connect();
      int noOfParallelThreads = 3;
      CountDownLatch latch = new CountDownLatch(noOfParallelThreads);
      List<PutRequestRunnable> runnables = new ArrayList<PutRequestRunnable>(noOfParallelThreads);
      BlockingChannel channel = null;
      for (int i = 0; i < noOfParallelThreads; i++) {
        if (i % noOfParallelThreads == 0) {
          channel = channel1;
        }
        else 
          if (i % noOfParallelThreads == 1) {
            channel = channel2;
          }
          else 
            if (i % noOfParallelThreads == 2) {
              channel = channel3;
            }
        PutRequestRunnable runnable = new PutRequestRunnable(cluster, channel, 50, data, usermetadata, properties, latch);
        runnables.add(runnable);
        Thread threadToRun = new Thread(runnable);
        threadToRun.start();
      }
      latch.await();
      List<BlobId> blobIds = new ArrayList<BlobId>();
      for (int i = 0; i < runnables.size(); i++) {
        blobIds.addAll(runnables.get(i).getBlobIds());
      }
      for (BlobId blobId : blobIds) {
        notificationSystem.awaitBlobCreations(blobId.getID());
      }
      for (int i = 0; i < 3; i++) {
        channel = null;
        if (i == 0) {
          channel = channel1;
        }
        else 
          if (i == 1) {
            channel = channel2;
          }
          else 
            if (i == 2) {
              channel = channel3;
            }
        ArrayList<PartitionRequestInfo> partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
        for (int j = 0; j < blobIds.size(); j++) {
          ArrayList<BlobId> ids = new ArrayList<BlobId>();
          ids.add(blobIds.get(j));
          partitionRequestInfoList.clear();
          PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
          partitionRequestInfoList.add(partitionRequestInfo);
          GetRequest getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
          channel.send(getRequest);
          InputStream stream = channel.receive().getInputStream();
          GetResponse resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
          try {
            BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp.getInputStream());
            Assert.assertEquals(propertyOutput.getBlobSize(), 100);
            Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
          ids.clear();
          ids.add(blobIds.get(j));
          partitionRequestInfoList.clear();
          partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
          partitionRequestInfoList.add(partitionRequestInfo);
          getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
          channel.send(getRequest);
          stream = channel.receive().getInputStream();
          resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
          try {
            ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp.getInputStream());
            Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
          }
          catch (MessageFormatException e) {
            e.printStackTrace();
            Assert.assertEquals(false, true);
          }
          ids.clear();
          ids.add(blobIds.get(j));
          partitionRequestInfoList.clear();
          partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
          partitionRequestInfoList.add(partitionRequestInfo);
          getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
          channel.send(getRequest);
          stream = channel.receive().getInputStream();
          resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
          try {
            BlobOutput blobOutput = MessageFormatRecord.deserializeBlob(resp.getInputStream());
            byte[] blobout = new byte[(int)blobOutput.getSize()];
            int readsize = 0;
            while (readsize < blobOutput.getSize()){
              readsize += blobOutput.getStream().read(blobout, readsize, (int)blobOutput.getSize() - readsize);
            }
            Assert.assertArrayEquals(blobout, data);
          }
          catch (MessageFormatException e) {
            e.printStackTrace();
            Assert.assertEquals(false, true);
          }
        }
      }
      Set<BlobId> blobsDeleted = new HashSet<BlobId>();
      Set<BlobId> blobsChecked = new HashSet<BlobId>();
      for (int i = 0; i < blobIds.size(); i++) {
        int j = new Random().nextInt(3);
        if (j == 0) {
          j = new Random().nextInt(3);
          if (j == 0) {
            channel = channel1;
          }
          else 
            if (j == 1) {
              channel = channel2;
            }
            else 
              if (j == 2) {
                channel = channel3;
              }
          DeleteRequest deleteRequest = new DeleteRequest(1, "reptest", blobIds.get(i));
          channel.send(deleteRequest);
          InputStream deleteResponseStream = channel.receive().getInputStream();
          DeleteResponse deleteResponse = DeleteResponse.readFrom(new DataInputStream(deleteResponseStream));
          Assert.assertEquals(deleteResponse.getError(), ServerErrorCode.No_Error);
          blobsDeleted.add(blobIds.get(i));
        }
      }
      Iterator<BlobId> iterator = blobsDeleted.iterator();
      ArrayList<PartitionRequestInfo> partitionRequestInfoList = new ArrayList<PartitionRequestInfo>();
      while (iterator.hasNext()){
        BlobId deletedId = iterator.next();
        notificationSystem.awaitBlobDeletions(deletedId.getID());
        for (int j = 0; j < 3; j++) {
          if (j == 0) {
            channel = channel1;
          }
          else 
            if (j == 1) {
              channel = channel2;
            }
            else 
              if (j == 2) {
                channel = channel3;
              }
          ArrayList<BlobId> ids = new ArrayList<BlobId>();
          ids.add(deletedId);
          partitionRequestInfoList.clear();
          PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(deletedId.getPartition(), ids);
          partitionRequestInfoList.add(partitionRequestInfo);
          GetRequest getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
          channel.send(getRequest);
          InputStream stream = channel.receive().getInputStream();
          GetResponse resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
          Assert.assertEquals(resp.getPartitionResponseInfoList().get(0).getErrorCode(), ServerErrorCode.Blob_Deleted);
        }
      }
      serverList.get(0).shutdown();
      serverList.get(0).awaitShutdown();
      MockDataNodeId dataNode = (MockDataNodeId)clusterMap.getDataNodeId("localhost", interestedDataNodePortNumber);
      System.out.println("Cleaning mount path " + dataNode.getMountPaths().get(0));
      for (ReplicaId replicaId : clusterMap.getReplicaIds(dataNode)) {
        if (replicaId.getMountPath().compareToIgnoreCase(dataNode.getMountPaths().get(0)) == 0) {
          System.out.println("Cleaning partition " + replicaId.getPartitionId());
        }
      }
      deleteFolderContent(new File(dataNode.getMountPaths().get(0)), false);
      int totalblobs = 0;
      for (int i = 0; i < blobIds.size(); i++) {
        for (ReplicaId replicaId : blobIds.get(i).getPartition().getReplicaIds()) {
          if (replicaId.getMountPath().compareToIgnoreCase(dataNode.getMountPaths().get(0)) == 0) {
            if (blobsDeleted.contains(blobIds.get(i))) {
              notificationSystem.decrementDeletedReplica(blobIds.get(i).getID());
            }
            else {
              totalblobs++;
              notificationSystem.decrementCreatedReplica(blobIds.get(i).getID());
            }
          }
        }
      }
      serverList.get(0).startup();
      channel1.disconnect();
      channel1.connect();
      for (int j = 0; j < blobIds.size(); j++) {
        if (blobsDeleted.contains(blobIds.get(j))) {
          notificationSystem.awaitBlobDeletions(blobIds.get(j).getID());
        }
        else {
          notificationSystem.awaitBlobCreations(blobIds.get(j).getID());
        }
        ArrayList<BlobId> ids = new ArrayList<BlobId>();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        GetRequest getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        InputStream stream = channel1.receive().getInputStream();
        GetResponse resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsDeleted.contains(blobIds.get(j)));
        }
        else {
          try {
            BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp.getInputStream());
            Assert.assertEquals(propertyOutput.getBlobSize(), 100);
            Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
        ids.clear();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        stream = channel1.receive().getInputStream();
        resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsDeleted.contains(blobIds.get(j)));
        }
        else {
          try {
            ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp.getInputStream());
            Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
        ids.clear();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        stream = channel1.receive().getInputStream();
        resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsDeleted.contains(blobIds.get(j)));
          blobsDeleted.remove(blobIds.get(j));
          blobsChecked.add(blobIds.get(j));
        }
        else {
          try {
            BlobOutput blobOutput = MessageFormatRecord.deserializeBlob(resp.getInputStream());
            byte[] blobout = new byte[(int)blobOutput.getSize()];
            int readsize = 0;
            while (readsize < blobOutput.getSize()){
              readsize += blobOutput.getStream().read(blobout, readsize, (int)blobOutput.getSize() - readsize);
            }
            Assert.assertArrayEquals(blobout, data);
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
      }
      Assert.assertEquals(blobsDeleted.size(), 0);
      serverList.get(0).shutdown();
      serverList.get(0).awaitShutdown();
      dataNode = (MockDataNodeId)clusterMap.getDataNodeId("localhost", interestedDataNodePortNumber);
      for (int i = 0; i < dataNode.getMountPaths().size(); i++) {
        System.out.println("Cleaning mount path " + dataNode.getMountPaths().get(i));
        for (ReplicaId replicaId : clusterMap.getReplicaIds(dataNode)) {
          if (replicaId.getMountPath().compareToIgnoreCase(dataNode.getMountPaths().get(i)) == 0) {
            System.out.println("Cleaning partition " + replicaId.getPartitionId());
          }
        }
        deleteFolderContent(new File(dataNode.getMountPaths().get(i)), false);
      }
      for (int i = 0; i < blobIds.size(); i++) {
        if (blobsChecked.contains(blobIds.get(i))) {
          notificationSystem.decrementDeletedReplica(blobIds.get(i).getID());
        }
        else {
          notificationSystem.decrementCreatedReplica(blobIds.get(i).getID());
        }
      }
      serverList.get(0).startup();
      channel1.disconnect();
      channel1.connect();
      for (int j = 0; j < blobIds.size(); j++) {
        if (blobsChecked.contains(blobIds.get(j))) {
          notificationSystem.awaitBlobDeletions(blobIds.get(j).getID());
        }
        else {
          notificationSystem.awaitBlobCreations(blobIds.get(j).getID());
        }
        ArrayList<BlobId> ids = new ArrayList<BlobId>();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        PartitionRequestInfo partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        GetRequest getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobProperties, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        InputStream stream = channel1.receive().getInputStream();
        GetResponse resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsChecked.contains(blobIds.get(j)));
        }
        else {
          try {
            BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(resp.getInputStream());
            Assert.assertEquals(propertyOutput.getBlobSize(), 100);
            Assert.assertEquals(propertyOutput.getServiceId(), "serviceid1");
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
        ids.clear();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.BlobUserMetadata, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        stream = channel1.receive().getInputStream();
        resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsChecked.contains(blobIds.get(j)));
        }
        else {
          try {
            ByteBuffer userMetadataOutput = MessageFormatRecord.deserializeUserMetadata(resp.getInputStream());
            Assert.assertArrayEquals(userMetadataOutput.array(), usermetadata);
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
        ids.clear();
        ids.add(blobIds.get(j));
        partitionRequestInfoList.clear();
        partitionRequestInfo = new PartitionRequestInfo(blobIds.get(j).getPartition(), ids);
        partitionRequestInfoList.add(partitionRequestInfo);
        getRequest = new GetRequest(1, "clientid2", MessageFormatFlags.Blob, partitionRequestInfoList, GetOptions.None);
        channel1.send(getRequest);
        stream = channel1.receive().getInputStream();
        resp = GetResponse.readFrom(new DataInputStream(stream), clusterMap);
        if (resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Deleted || resp.getPartitionResponseInfoList().get(0).getErrorCode() == ServerErrorCode.Blob_Not_Found) {
          Assert.assertTrue(blobsChecked.contains(blobIds.get(j)));
          blobsChecked.remove(blobIds.get(j));
        }
        else {
          try {
            BlobOutput blobOutput = MessageFormatRecord.deserializeBlob(resp.getInputStream());
            byte[] blobout = new byte[(int)blobOutput.getSize()];
            int readsize = 0;
            while (readsize < blobOutput.getSize()){
              readsize += blobOutput.getStream().read(blobout, readsize, (int)blobOutput.getSize() - readsize);
            }
            Assert.assertArrayEquals(blobout, data);
          }
          catch (MessageFormatException e) {
            Assert.assertEquals(false, true);
          }
        }
      }
      Assert.assertEquals(blobsChecked.size(), 0);
      channel1.disconnect();
      channel2.disconnect();
      channel3.disconnect();
    }
    catch (Exception e) {
      e.printStackTrace();
      Assert.assertTrue(false);
    }
=======
cluster = new MockCluster(notificationSystem, enableSSLPorts, sslEnabledDatacentersForDC1, sslEnabledDatacentersForDC2, sslEnabledDatacentersForDC3, SystemTime.getInstance());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_base_98cfd5d\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
CONCLUSAO: MESMO CONFLITO. RENAMING NO SSMERGE.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Properties props = new Properties();
=======
cluster = new MockCluster(notificationSystem, enableSSLPorts, sslEnabledDatacenter1, sslEnabledDatacenter2, sslEnabledDatacenter3, SystemTime.getInstance());
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void endToEndReplicationWithMultiNodeMultiPartitionMultiDCTest(String sourceDatacenter, PortType portType, MockCluster cluster) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_left_1f41948\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java
Properties props = new Properties();
=======
cluster = new MockCluster(notificationSystem, enableSSLPorts, sslEnabledDatacenter1, sslEnabledDatacenter2, sslEnabledDatacenter3, SystemTime.getInstance());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_1f41948_4a4a3e3\rev_right_4a4a3e3\ambry-server\src\test\java\com.github.ambry.server\ServerTest.java

    props.setProperty("coordinator.hostname", "localhost");
    props.setProperty("coordinator.datacenter.name", sourceDatacenter);
    props.putAll(coordinatorProps);
    VerifiableProperties verifiableProperties = new VerifiableProperties(props);
    Coordinator coordinator = new AmbryCoordinator(verifiableProperties, cluster.getClusterMap());
    Thread[] senderThreads = new Thread[3];
    LinkedBlockingQueue<Payload> blockingQueue = new LinkedBlockingQueue<Payload>();
    int numberOfSenderThreads = 3;
    int numberOfVerifierThreads = 3;
    CountDownLatch senderLatch = new CountDownLatch(numberOfSenderThreads);
    int numberOfRequestsToSendPerThread = 5;
    for (int i = 0; i < numberOfSenderThreads; i++) {
      senderThreads[i] = new Thread(new Sender(blockingQueue, senderLatch, numberOfRequestsToSendPerThread, coordinator));
      senderThreads[i].start();
    }
    senderLatch.await();
    if (blockingQueue.size() != numberOfRequestsToSendPerThread * numberOfSenderThreads) {
      throw new IllegalStateException();
    }
    Properties sslProps = new Properties();
    sslProps.putAll(coordinatorProps);
    sslProps.setProperty("ssl.enabled.datacenters", "DC1,DC2,DC3");
    ConnectionPool connectionPool = new BlockingChannelConnectionPool(new ConnectionPoolConfig(new VerifiableProperties(new Properties())), new SSLConfig(new VerifiableProperties(sslProps)), new MetricRegistry());
    CountDownLatch verifierLatch = new CountDownLatch(numberOfVerifierThreads);
    AtomicInteger totalRequests = new AtomicInteger(numberOfRequestsToSendPerThread * numberOfSenderThreads);
    AtomicInteger verifiedRequests = new AtomicInteger(0);
    AtomicBoolean cancelTest = new AtomicBoolean(false);
    for (int i = 0; i < numberOfVerifierThreads; i++) {
      Thread thread = new Thread(new Verifier(blockingQueue, verifierLatch, totalRequests, verifiedRequests, cluster.getClusterMap(), cancelTest, portType, connectionPool));
      thread.start();
    }
    verifierLatch.await();
    Assert.assertEquals(totalRequests.get(), verifiedRequests.get());
    coordinator.close();
    connectionPool.shutdown();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_left_16b59fa\driver-compat\src\main\com\mongodb\DBCollection.java,C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_base_b004820\driver-compat\src\main\com\mongodb\DBCollection.java,C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_right_7c9c613\driver-compat\src\main\com\mongodb\DBCollection.java
CONCLUSAO: MESMO CONFLIT, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
final Codec<DBObject> codec;
=======
final Serializer<DBObject> serializer = toDBObjectSerializer(encoder);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public WriteResult insert(final List<DBObject> documents, final WriteConcern aWriteConcern, final DBEncoder encoder) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_left_16b59fa\driver-compat\src\main\com\mongodb\DBCollection.java
final Codec<DBObject> codec;
=======
final Serializer<DBObject> serializer = toDBObjectSerializer(encoder);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_right_7c9c613\driver-compat\src\main\com\mongodb\DBCollection.java

    final MongoInsert<DBObject> mongoInsert = new MongoInsert<DBObject>(documents).writeConcern(this.writeConcern.toNew());
    return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_left_16b59fa\driver-compat\src\main\com\mongodb\DBCollection.java
insert(mongoInsert, codec)
=======
new WriteResult(insertInternal(mongoInsert, serializer), aWriteConcern)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_right_7c9c613\driver-compat\src\main\com\mongodb\DBCollection.java
;
    return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_left_16b59fa\driver-compat\src\main\com\mongodb\DBCollection.java
insert(mongoInsert, codec)
=======
new WriteResult(insertInternal(mongoInsert, serializer), aWriteConcern)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_right_7c9c613\driver-compat\src\main\com\mongodb\DBCollection.java
;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_left_16b59fa\driver-compat\src\main\com\mongodb\DBCollection.java,C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_base_b004820\driver-compat\src\main\com\mongodb\DBCollection.java,C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_right_7c9c613\driver-compat\src\main\com\mongodb\DBCollection.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
insert(mongoInsert, codec)
=======
new WriteResult(insertInternal(mongoInsert, serializer), aWriteConcern)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public WriteResult insert(final List<DBObject> documents, final WriteConcern aWriteConcern, final DBEncoder encoder) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_left_16b59fa\driver-compat\src\main\com\mongodb\DBCollection.java
final Codec<DBObject> codec;
=======
final Serializer<DBObject> serializer = toDBObjectSerializer(encoder);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_right_7c9c613\driver-compat\src\main\com\mongodb\DBCollection.java

    final MongoInsert<DBObject> mongoInsert = new MongoInsert<DBObject>(documents).writeConcern(this.writeConcern.toNew());
    return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_left_16b59fa\driver-compat\src\main\com\mongodb\DBCollection.java
insert(mongoInsert, codec)
=======
new WriteResult(insertInternal(mongoInsert, serializer), aWriteConcern)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_right_7c9c613\driver-compat\src\main\com\mongodb\DBCollection.java
;
    return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_left_16b59fa\driver-compat\src\main\com\mongodb\DBCollection.java
insert(mongoInsert, codec)
=======
new WriteResult(insertInternal(mongoInsert, serializer), aWriteConcern)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\mongo-java-driver\revisions\rev_16b59fa_7c9c613\rev_right_7c9c613\driver-compat\src\main\com\mongodb\DBCollection.java
;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_707fe30_1c9f597\rev_left_707fe30\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_707fe30_1c9f597\rev_base_a3acb29\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_707fe30_1c9f597\rev_right_1c9f597\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
int bytesRead = read(key);
=======
read(key);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void run() {
    try {
      startupComplete();
      while (isRunning()){
        configureNewConnections();
        processNewResponses();
        long startSelectTime = SystemTime.getInstance().milliseconds();
        int ready = selector.select(300);
        logger.trace("Processor id {} selection time = {} ms", id, (SystemTime.getInstance().milliseconds() - startSelectTime));
        if (ready > 0) {
          Set<SelectionKey> keys = selector.selectedKeys();
          Iterator<SelectionKey> iter = keys.iterator();
          while (iter.hasNext() && isRunning()){
            SelectionKey key = null;
            try {
              key = iter.next();
              iter.remove();
              if (key.isReadable()) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_707fe30_1c9f597\rev_left_707fe30\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java
int bytesRead = read(key);
=======
read(key);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_707fe30_1c9f597\rev_right_1c9f597\ambry-network\src\main\java\com.github.ambry.network\SocketServer.java

                if (bytesRead == -1) 
                  close(key);
              }
            }
          }
        }
      }
      logger.debug("Closing server socket and selector.");
      closeAll();
      selector.close();
      shutdownComplete();
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\CreateBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\CreateBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\CreateBuilderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (storingStat == null) {
      client.getZooKeeper().create(operationAndData.getData().getPath(), operationAndData.getData().getData(), acling.getAclList(operationAndData.getData().getPath()), createMode, new AsyncCallback.StringCallback() {
          @Override public void processResult(int rc, String path, Object ctx, String name) {
            trace.commit();
            if ((rc == KeeperException.Code.NONODE.intValue()) && createParentsIfNeeded) {
              backgroundCreateParentsThenNode(client, operationAndData, operationAndData.getData().getPath(), backgrounding, createParentsAsContainers);
            }
            else 
              if ((rc == KeeperException.Code.NODEEXISTS.intValue()) && setDataIfExists) {
                backgroundSetData(client, operationAndData, operationAndData.getData().getPath(), backgrounding);
              }
              else {
                sendBackgroundResponse(rc, path, ctx, name, null, operationAndData);
              }
          }
      }, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().create(operationAndData.getData().getPath(), operationAndData.getData().getData(), acling.getAclList(operationAndData.getData().getPath()), createMode, new AsyncCallback.Create2Callback() {
          @Override public void processResult(int rc, String path, Object ctx, String name, Stat stat) {
            trace.commit();
            if (stat != null) {
              storingStat.setAversion(stat.getAversion());
              storingStat.setCtime(stat.getCtime());
              storingStat.setCversion(stat.getCversion());
              storingStat.setCzxid(stat.getCzxid());
              storingStat.setDataLength(stat.getDataLength());
              storingStat.setEphemeralOwner(stat.getEphemeralOwner());
              storingStat.setMtime(stat.getMtime());
              storingStat.setMzxid(stat.getMzxid());
              storingStat.setNumChildren(stat.getNumChildren());
              storingStat.setPzxid(stat.getPzxid());
              storingStat.setVersion(stat.getVersion());
            }
            if ((rc == KeeperException.Code.NONODE.intValue()) && createParentsIfNeeded) {
              backgroundCreateParentsThenNode(client, operationAndData, operationAndData.getData().getPath(), backgrounding, createParentsAsContainers);
            }
            else {
              sendBackgroundResponse(rc, path, ctx, name, stat, operationAndData);
            }
          }
      }, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("CreateBuilderImpl-Background");
      client.getZooKeeper().create(operationAndData.getData().getPath(), operationAndData.getData().getData(), acling.getAclList(operationAndData.getData().getPath()), createMode, new AsyncCallback.StringCallback() {
          @Override public void processResult(int rc, String path, Object ctx, String name) {
            trace.commit();
            if ((rc == KeeperException.Code.NONODE.intValue()) && createParentsIfNeeded) {
              backgroundCreateParentsThenNode(client, operationAndData, operationAndData.getData().getPath(), backgrounding, createParentsAsContainers);
            }
            else {
              sendBackgroundResponse(rc, path, ctx, name, operationAndData);
            }
          }
      }, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<PathAndBytes> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\CreateBuilderImpl.java
if (storingStat == null) {
      client.getZooKeeper().create(operationAndData.getData().getPath(), operationAndData.getData().getData(), acling.getAclList(operationAndData.getData().getPath()), createMode, new AsyncCallback.StringCallback() {
          @Override public void processResult(int rc, String path, Object ctx, String name) {
            trace.commit();
            if ((rc == KeeperException.Code.NONODE.intValue()) && createParentsIfNeeded) {
              backgroundCreateParentsThenNode(client, operationAndData, operationAndData.getData().getPath(), backgrounding, createParentsAsContainers);
            }
            else 
              if ((rc == KeeperException.Code.NODEEXISTS.intValue()) && setDataIfExists) {
                backgroundSetData(client, operationAndData, operationAndData.getData().getPath(), backgrounding);
              }
              else {
                sendBackgroundResponse(rc, path, ctx, name, null, operationAndData);
              }
          }
      }, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().create(operationAndData.getData().getPath(), operationAndData.getData().getData(), acling.getAclList(operationAndData.getData().getPath()), createMode, new AsyncCallback.Create2Callback() {
          @Override public void processResult(int rc, String path, Object ctx, String name, Stat stat) {
            trace.commit();
            if (stat != null) {
              storingStat.setAversion(stat.getAversion());
              storingStat.setCtime(stat.getCtime());
              storingStat.setCversion(stat.getCversion());
              storingStat.setCzxid(stat.getCzxid());
              storingStat.setDataLength(stat.getDataLength());
              storingStat.setEphemeralOwner(stat.getEphemeralOwner());
              storingStat.setMtime(stat.getMtime());
              storingStat.setMzxid(stat.getMzxid());
              storingStat.setNumChildren(stat.getNumChildren());
              storingStat.setPzxid(stat.getPzxid());
              storingStat.setVersion(stat.getVersion());
            }
            if ((rc == KeeperException.Code.NONODE.intValue()) && createParentsIfNeeded) {
              backgroundCreateParentsThenNode(client, operationAndData, operationAndData.getData().getPath(), backgrounding, createParentsAsContainers);
            }
            else {
              sendBackgroundResponse(rc, path, ctx, name, stat, operationAndData);
            }
          }
      }, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("CreateBuilderImpl-Background");
      client.getZooKeeper().create(operationAndData.getData().getPath(), operationAndData.getData().getData(), acling.getAclList(operationAndData.getData().getPath()), createMode, new AsyncCallback.StringCallback() {
          @Override public void processResult(int rc, String path, Object ctx, String name) {
            trace.commit();
            if ((rc == KeeperException.Code.NONODE.intValue()) && createParentsIfNeeded) {
              backgroundCreateParentsThenNode(client, operationAndData, operationAndData.getData().getPath(), backgrounding, createParentsAsContainers);
            }
            else {
              sendBackgroundResponse(rc, path, ctx, name, operationAndData);
            }
          }
      }, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\CreateBuilderImpl.java

    if (storingStat == null) {
      client.getZooKeeper().create(operationAndData.getData().getPath(), operationAndData.getData().getData(), acling.getAclList(operationAndData.getData().getPath()), createMode, new AsyncCallback.StringCallback() {
          @Override public void processResult(int rc, String path, Object ctx, String name) {
            trace.commit();
            if ((rc == KeeperException.Code.NONODE.intValue()) && createParentsIfNeeded) {
              backgroundCreateParentsThenNode(client, operationAndData, operationAndData.getData().getPath(), backgrounding, createParentsAsContainers);
            }
            else 
              if ((rc == KeeperException.Code.NODEEXISTS.intValue()) && setDataIfExists) {
                backgroundSetData(client, operationAndData, operationAndData.getData().getPath(), backgrounding);
              }
              else {
                sendBackgroundResponse(rc, path, ctx, name, null, operationAndData);
              }
          }
      }, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().create(operationAndData.getData().getPath(), operationAndData.getData().getData(), acling.getAclList(operationAndData.getData().getPath()), createMode, new AsyncCallback.Create2Callback() {
          @Override public void processResult(int rc, String path, Object ctx, String name, Stat stat) {
            trace.commit();
            if (stat != null) {
              storingStat.setAversion(stat.getAversion());
              storingStat.setCtime(stat.getCtime());
              storingStat.setCversion(stat.getCversion());
              storingStat.setCzxid(stat.getCzxid());
              storingStat.setDataLength(stat.getDataLength());
              storingStat.setEphemeralOwner(stat.getEphemeralOwner());
              storingStat.setMtime(stat.getMtime());
              storingStat.setMzxid(stat.getMzxid());
              storingStat.setNumChildren(stat.getNumChildren());
              storingStat.setPzxid(stat.getPzxid());
              storingStat.setVersion(stat.getVersion());
            }
            if ((rc == KeeperException.Code.NONODE.intValue()) && createParentsIfNeeded) {
              backgroundCreateParentsThenNode(client, operationAndData, operationAndData.getData().getPath(), backgrounding, createParentsAsContainers);
            }
            else {
              sendBackgroundResponse(rc, path, ctx, name, stat, operationAndData);
            }
          }
      }, backgrounding.getContext());
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\DeleteBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\DeleteBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\DeleteBuilderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
client.getZooKeeper().delete(operationAndData.getData(), version, new AsyncCallback.VoidCallback() {
        @Override public void processResult(int rc, String path, Object ctx) {
          trace.commit();
          if ((rc == KeeperException.Code.NOTEMPTY.intValue()) && deletingChildrenIfNeeded) {
            backgroundDeleteChildrenThenNode(operationAndData);
          }
          else {
            if ((rc == KeeperException.Code.NONODE.intValue()) && quietly) {
              rc = KeeperException.Code.OK.intValue();
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.DELETE, rc, path, null, ctx, null, null, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
        }
    }, backgrounding.getContext());
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("DeleteBuilderImpl-Background");
      client.getZooKeeper().delete(operationAndData.getData(), version, new AsyncCallback.VoidCallback() {
          @Override public void processResult(int rc, String path, Object ctx) {
            trace.commit();
            if ((rc == KeeperException.Code.NOTEMPTY.intValue()) && deletingChildrenIfNeeded) {
              backgroundDeleteChildrenThenNode(operationAndData);
            }
            else {
              CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.DELETE, rc, path, null, ctx, null, null, null, null, null);
              client.processBackgroundOperation(operationAndData, event);
            }
          }
      }, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\DeleteBuilderImpl.java
client.getZooKeeper().delete(operationAndData.getData(), version, new AsyncCallback.VoidCallback() {
        @Override public void processResult(int rc, String path, Object ctx) {
          trace.commit();
          if ((rc == KeeperException.Code.NOTEMPTY.intValue()) && deletingChildrenIfNeeded) {
            backgroundDeleteChildrenThenNode(operationAndData);
          }
          else {
            if ((rc == KeeperException.Code.NONODE.intValue()) && quietly) {
              rc = KeeperException.Code.OK.intValue();
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.DELETE, rc, path, null, ctx, null, null, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
        }
    }, backgrounding.getContext());
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("DeleteBuilderImpl-Background");
      client.getZooKeeper().delete(operationAndData.getData(), version, new AsyncCallback.VoidCallback() {
          @Override public void processResult(int rc, String path, Object ctx) {
            trace.commit();
            if ((rc == KeeperException.Code.NOTEMPTY.intValue()) && deletingChildrenIfNeeded) {
              backgroundDeleteChildrenThenNode(operationAndData);
            }
            else {
              CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.DELETE, rc, path, null, ctx, null, null, null, null, null);
              client.processBackgroundOperation(operationAndData, event);
            }
          }
      }, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\DeleteBuilderImpl.java

    client.getZooKeeper().delete(operationAndData.getData(), version, new AsyncCallback.VoidCallback() {
        @Override public void processResult(int rc, String path, Object ctx) {
          trace.commit();
          if ((rc == KeeperException.Code.NOTEMPTY.intValue()) && deletingChildrenIfNeeded) {
            backgroundDeleteChildrenThenNode(operationAndData);
          }
          else {
            if ((rc == KeeperException.Code.NONODE.intValue()) && quietly) {
              rc = KeeperException.Code.OK.intValue();
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.DELETE, rc, path, null, ctx, null, null, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
        }
    }, backgrounding.getContext());
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java
CONCLUSAO: FP. DEVS EDITAM/ADICIONAM COMANDOS QUE NÃO APARENTAM TER RELAÇÃO ENTRE SI
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
        @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
          trace.commit();
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("ExistsBuilderImpl-Background");
      AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
          @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java
AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
        @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
          trace.commit();
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("ExistsBuilderImpl-Background");
      AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
          @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java
if (watching.isWatched()) {
      client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("ExistsBuilderImpl-Background");
      AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
          @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java

    if (watching.isWatched()) {
      client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (watching.isWatched()) {
      client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("ExistsBuilderImpl-Background");
      AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
          @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java
AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
        @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
          trace.commit();
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("ExistsBuilderImpl-Background");
      AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
          @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java
if (watching.isWatched()) {
      client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("ExistsBuilderImpl-Background");
      AsyncCallback.StatCallback callback = new AsyncCallback.StatCallback() {
          @Override public void processResult(int rc, String path, Object ctx, Stat stat) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.EXISTS, rc, path, null, ctx, stat, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\ExistsBuilderImpl.java

    if (watching.isWatched()) {
      client.getZooKeeper().exists(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().exists(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetACLBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\GetACLBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetACLBuilderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
AsyncCallback.ACLCallback callback = new AsyncCallback.ACLCallback() {
        @Override public void processResult(int rc, String path, Object ctx, List<ACL> acl, Stat stat) {
          trace.commit();
          CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.GET_ACL, rc, path, null, ctx, stat, null, null, null, acl, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetACLBuilderImpl-Background");
      AsyncCallback.ACLCallback callback = new AsyncCallback.ACLCallback() {
          @Override public void processResult(int rc, String path, Object ctx, List<ACL> acl, Stat stat) {
            trace.commit();
            CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.GET_ACL, rc, path, null, ctx, stat, null, null, null, acl);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      client.getZooKeeper().getACL(operationAndData.getData(), responseStat, callback, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetACLBuilderImpl.java
AsyncCallback.ACLCallback callback = new AsyncCallback.ACLCallback() {
        @Override public void processResult(int rc, String path, Object ctx, List<ACL> acl, Stat stat) {
          trace.commit();
          CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.GET_ACL, rc, path, null, ctx, stat, null, null, null, acl, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetACLBuilderImpl-Background");
      AsyncCallback.ACLCallback callback = new AsyncCallback.ACLCallback() {
          @Override public void processResult(int rc, String path, Object ctx, List<ACL> acl, Stat stat) {
            trace.commit();
            CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.GET_ACL, rc, path, null, ctx, stat, null, null, null, acl);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      client.getZooKeeper().getACL(operationAndData.getData(), responseStat, callback, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetACLBuilderImpl.java

    AsyncCallback.ACLCallback callback = new AsyncCallback.ACLCallback() {
        @Override public void processResult(int rc, String path, Object ctx, List<ACL> acl, Stat stat) {
          trace.commit();
          CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.GET_ACL, rc, path, null, ctx, stat, null, null, null, acl, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
    client.getZooKeeper().getACL(operationAndData.getData(), responseStat, callback, backgrounding.getContext());
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java
CONCLUSAO: FP. DEVS EDITAM/ADICIONAM COMANDOS QUE NÃO APARENTAM TER RELAÇÃO ENTRE SI
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
        @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
          trace.commit();
          if (strings == null) {
            strings = Lists.newArrayList();
          }
          CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetChildrenBuilderImpl-Background");
      AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
          @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
            trace.commit();
            if (strings == null) {
              strings = Lists.newArrayList();
            }
            CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java
AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
        @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
          trace.commit();
          if (strings == null) {
            strings = Lists.newArrayList();
          }
          CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetChildrenBuilderImpl-Background");
      AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
          @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
            trace.commit();
            if (strings == null) {
              strings = Lists.newArrayList();
            }
            CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java
if (watching.isWatched()) {
      client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetChildrenBuilderImpl-Background");
      AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
          @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
            trace.commit();
            if (strings == null) {
              strings = Lists.newArrayList();
            }
            CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java

    if (watching.isWatched()) {
      client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (watching.isWatched()) {
      client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetChildrenBuilderImpl-Background");
      AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
          @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
            trace.commit();
            if (strings == null) {
              strings = Lists.newArrayList();
            }
            CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java
AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
        @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
          trace.commit();
          if (strings == null) {
            strings = Lists.newArrayList();
          }
          CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetChildrenBuilderImpl-Background");
      AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
          @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
            trace.commit();
            if (strings == null) {
              strings = Lists.newArrayList();
            }
            CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java
if (watching.isWatched()) {
      client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetChildrenBuilderImpl-Background");
      AsyncCallback.Children2Callback callback = new AsyncCallback.Children2Callback() {
          @Override public void processResult(int rc, String path, Object o, List<String> strings, Stat stat) {
            trace.commit();
            if (strings == null) {
              strings = Lists.newArrayList();
            }
            CuratorEventImpl event = new CuratorEventImpl(client, CuratorEventType.CHILDREN, rc, path, null, o, stat, null, strings, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetChildrenBuilderImpl.java

    if (watching.isWatched()) {
      client.getZooKeeper().getChildren(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getChildren(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java
CONCLUSAO: FP. DEVS EDITAM/ADICIONAM COMANDOS QUE NÃO APARENTAM TER RELAÇÃO ENTRE SI
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
        @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
          trace.commit();
          if (decompress && (data != null)) {
            try {
              data = client.getCompressionProvider().decompress(path, data);
            }
            catch (Exception e) {
              ThreadUtils.checkInterrupted(e);
              log.error("Decompressing for path: " + path, e);
              rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
            }
          }
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetDataBuilderImpl-Background");
      AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
          @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            trace.commit();
            if (decompress && (data != null)) {
              try {
                data = client.getCompressionProvider().decompress(path, data);
              }
              catch (Exception e) {
                ThreadUtils.checkInterrupted(e);
                log.error("Decompressing for path: " + path, e);
                rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
              }
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java
AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
        @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
          trace.commit();
          if (decompress && (data != null)) {
            try {
              data = client.getCompressionProvider().decompress(path, data);
            }
            catch (Exception e) {
              ThreadUtils.checkInterrupted(e);
              log.error("Decompressing for path: " + path, e);
              rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
            }
          }
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetDataBuilderImpl-Background");
      AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
          @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            trace.commit();
            if (decompress && (data != null)) {
              try {
                data = client.getCompressionProvider().decompress(path, data);
              }
              catch (Exception e) {
                ThreadUtils.checkInterrupted(e);
                log.error("Decompressing for path: " + path, e);
                rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
              }
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java
if (watching.isWatched()) {
      client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetDataBuilderImpl-Background");
      AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
          @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            trace.commit();
            if (decompress && (data != null)) {
              try {
                data = client.getCompressionProvider().decompress(path, data);
              }
              catch (Exception e) {
                ThreadUtils.checkInterrupted(e);
                log.error("Decompressing for path: " + path, e);
                rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
              }
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java

    if (watching.isWatched()) {
      client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (watching.isWatched()) {
      client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetDataBuilderImpl-Background");
      AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
          @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            trace.commit();
            if (decompress && (data != null)) {
              try {
                data = client.getCompressionProvider().decompress(path, data);
              }
              catch (Exception e) {
                ThreadUtils.checkInterrupted(e);
                log.error("Decompressing for path: " + path, e);
                rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
              }
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java
AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
        @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
          trace.commit();
          if (decompress && (data != null)) {
            try {
              data = client.getCompressionProvider().decompress(path, data);
            }
            catch (Exception e) {
              ThreadUtils.checkInterrupted(e);
              log.error("Decompressing for path: " + path, e);
              rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
            }
          }
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetDataBuilderImpl-Background");
      AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
          @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            trace.commit();
            if (decompress && (data != null)) {
              try {
                data = client.getCompressionProvider().decompress(path, data);
              }
              catch (Exception e) {
                ThreadUtils.checkInterrupted(e);
                log.error("Decompressing for path: " + path, e);
                rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
              }
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java
if (watching.isWatched()) {
      client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("GetDataBuilderImpl-Background");
      AsyncCallback.DataCallback callback = new AsyncCallback.DataCallback() {
          @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            trace.commit();
            if (decompress && (data != null)) {
              try {
                data = client.getCompressionProvider().decompress(path, data);
              }
              catch (Exception e) {
                ThreadUtils.checkInterrupted(e);
                log.error("Decompressing for path: " + path, e);
                rc = KeeperException.Code.DATAINCONSISTENCY.intValue();
              }
            }
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.GET_DATA, rc, path, null, ctx, stat, data, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      if (watching.isWatched()) {
        client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
      }
      else {
        client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(), callback, backgrounding.getContext());
      }
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\GetDataBuilderImpl.java

    if (watching.isWatched()) {
      client.getZooKeeper().getData(operationAndData.getData(), true, callback, backgrounding.getContext());
    }
    else {
      client.getZooKeeper().getData(operationAndData.getData(), watching.getWatcher(client, operationAndData.getData()), callback, backgrounding.getContext());
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\SyncBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_base_33c19d6\curator-framework\src\main\java\org\apache\curator\framework\imps\SyncBuilderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\SyncBuilderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
AsyncCallback.VoidCallback voidCallback = new AsyncCallback.VoidCallback() {
        @Override public void processResult(int rc, String path, Object ctx) {
          trace.commit();
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.SYNC, rc, path, path, ctx, null, null, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("SyncBuilderImpl-Background");
      final String path = operationAndData.getData();
      String adjustedPath = client.fixForNamespace(path);
      AsyncCallback.VoidCallback voidCallback = new AsyncCallback.VoidCallback() {
          @Override public void processResult(int rc, String path, Object ctx) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.SYNC, rc, path, path, ctx, null, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      client.getZooKeeper().sync(adjustedPath, voidCallback, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void performBackgroundOperation(final OperationAndData<String> operationAndData) throws Exception {
    try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("SyncBuilderImpl-Background");
      final String path = operationAndData.getData();
      String adjustedPath = client.fixForNamespace(path);
      AsyncCallback.VoidCallback voidCallback = new AsyncCallback.VoidCallback() {
          @Override public void processResult(int rc, String path, Object ctx) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.SYNC, rc, path, path, ctx, null, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      client.getZooKeeper().sync(adjustedPath, voidCallback, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_left_8ef32cc\curator-framework\src\main\java\org\apache\curator\framework\imps\SyncBuilderImpl.java
AsyncCallback.VoidCallback voidCallback = new AsyncCallback.VoidCallback() {
        @Override public void processResult(int rc, String path, Object ctx) {
          trace.commit();
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.SYNC, rc, path, path, ctx, null, null, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
=======
try {
      final TimeTrace trace = client.getZookeeperClient().startTracer("SyncBuilderImpl-Background");
      final String path = operationAndData.getData();
      String adjustedPath = client.fixForNamespace(path);
      AsyncCallback.VoidCallback voidCallback = new AsyncCallback.VoidCallback() {
          @Override public void processResult(int rc, String path, Object ctx) {
            trace.commit();
            CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.SYNC, rc, path, path, ctx, null, null, null, null, null);
            client.processBackgroundOperation(operationAndData, event);
          }
      };
      client.getZooKeeper().sync(adjustedPath, voidCallback, backgrounding.getContext());
    }
    catch (Throwable e) {
      backgrounding.checkError(e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_8ef32cc_8499680\rev_right_8499680\curator-framework\src\main\java\org\apache\curator\framework\imps\SyncBuilderImpl.java

    String adjustedPath = client.fixForNamespace(path);
    AsyncCallback.VoidCallback voidCallback = new AsyncCallback.VoidCallback() {
        @Override public void processResult(int rc, String path, Object ctx) {
          trace.commit();
          CuratorEvent event = new CuratorEventImpl(client, CuratorEventType.SYNC, rc, path, path, ctx, null, null, null, null, null, null);
          client.processBackgroundOperation(operationAndData, event);
        }
    };
    client.getZooKeeper().sync(adjustedPath, voidCallback, backgrounding.getContext());
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_58400ef_8c800df\rev_left_58400ef\flyway-core\src\main\java\org\flywaydb\core\Flyway.java,C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_58400ef_8c800df\rev_base_24f1874\flyway-core\src\main\java\org\flywaydb\core\Flyway.java,C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_58400ef_8c800df\rev_right_8c800df\flyway-core\src\main\java\org\flywaydb\core\Flyway.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
for (FlywayCallback callback : getCallbacks()) {
            callback.beforeRepair(connectionUserObjects);
          }
=======
MetaDataTable metaDataTable = new MetaDataTableImpl(dbSupport, schemas[0].getTable(table), classLoader);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
        public Void execute(Connection connectionMetaDataTable, Connection connectionUserObjects, DbSupport dbSupport, Schema[] schemas) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_58400ef_8c800df\rev_left_58400ef\flyway-core\src\main\java\org\flywaydb\core\Flyway.java
for (FlywayCallback callback : getCallbacks()) {
            callback.beforeRepair(connectionUserObjects);
          }
=======
MetaDataTable metaDataTable = new MetaDataTableImpl(dbSupport, schemas[0].getTable(table), classLoader);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_58400ef_8c800df\rev_right_8c800df\flyway-core\src\main\java\org\flywaydb\core\Flyway.java

          new MetaDataTableImpl(dbSupport, schemas[0].getTable(table)).repair();
          for (FlywayCallback callback : getCallbacks()) {
            callback.afterRepair(connectionUserObjects);
          }
          return null;
        }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_left_b46877e\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_base_709f3db\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_right_b0c21eb\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
BlobId blobId = getBlobIdFromString(blobIdString);
=======
try {
      BlobId id = new BlobId(blobId, map);
      DataNodeId node = id.getPartition().getReplicaIds().get(0).getDataNodeId();
      ConnectionPool resource = pool.get(node.getHostname() + node.getPort());
      if (resource == null) {
        resource = new ConnectionPool(node.getHostname(), node.getPort());
        pool.put(node.getHostname() + node.getPort(), resource);
      }
      BlockingChannel channel = resource.getConnection();
      GetResponse response = doGetResponse(id, MessageFormatFlags.Blob, channel);
      BlobOutput output = MessageFormatRecord.deserializeBlob(response.getInputStream());
      resource.returnConnection(channel);
      return output;
    }
    catch (Exception e) {
      System.out.println("error " + e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public BlobOutput getBlob(String blobIdString) throws CoordinatorException {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_left_b46877e\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java
BlobId blobId = getBlobIdFromString(blobIdString);
=======
try {
      BlobId id = new BlobId(blobId, map);
      DataNodeId node = id.getPartition().getReplicaIds().get(0).getDataNodeId();
      ConnectionPool resource = pool.get(node.getHostname() + node.getPort());
      if (resource == null) {
        resource = new ConnectionPool(node.getHostname(), node.getPort());
        pool.put(node.getHostname() + node.getPort(), resource);
      }
      BlockingChannel channel = resource.getConnection();
      GetResponse response = doGetResponse(id, MessageFormatFlags.Blob, channel);
      BlobOutput output = MessageFormatRecord.deserializeBlob(response.getInputStream());
      resource.returnConnection(channel);
      return output;
    }
    catch (Exception e) {
      System.out.println("error " + e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_right_b0c21eb\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java

    GetBlobOperation gbdo = new GetBlobOperation(datacenterName, connectionPool, requesterPool, getOperationContext(), blobId, operationTimeoutMs, clusterMap);
    gbdo.execute();
    return gbdo.getBlobOutput();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_left_b46877e\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_base_709f3db\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_right_b0c21eb\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
BlobId blobId = getBlobIdFromString(blobIdString);
=======
try {
      BlobId id = new BlobId(blobId, map);
      DataNodeId node = id.getPartition().getReplicaIds().get(0).getDataNodeId();
      ConnectionPool resource = pool.get(node.getHostname() + node.getPort());
      if (resource == null) {
        resource = new ConnectionPool(node.getHostname(), node.getPort());
        pool.put(node.getHostname() + node.getPort(), resource);
      }
      BlockingChannel channel = resource.getConnection();
      GetResponse response = doGetResponse(id, MessageFormatFlags.BlobProperties, channel);
      BlobProperties properties = MessageFormatRecord.deserializeBlobProperties(response.getInputStream());
      resource.returnConnection(channel);
      return properties;
    }
    catch (Exception e) {
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public BlobProperties getBlobProperties(String blobIdString) throws CoordinatorException {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_left_b46877e\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java
BlobId blobId = getBlobIdFromString(blobIdString);
=======
try {
      BlobId id = new BlobId(blobId, map);
      DataNodeId node = id.getPartition().getReplicaIds().get(0).getDataNodeId();
      ConnectionPool resource = pool.get(node.getHostname() + node.getPort());
      if (resource == null) {
        resource = new ConnectionPool(node.getHostname(), node.getPort());
        pool.put(node.getHostname() + node.getPort(), resource);
      }
      BlockingChannel channel = resource.getConnection();
      GetResponse response = doGetResponse(id, MessageFormatFlags.BlobProperties, channel);
      BlobProperties properties = MessageFormatRecord.deserializeBlobProperties(response.getInputStream());
      resource.returnConnection(channel);
      return properties;
    }
    catch (Exception e) {
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_b46877e_b0c21eb\rev_right_b0c21eb\ambry-coordinator\src\main\java\com.github.ambry.coordinator\AmbryCoordinator.java

    GetBlobPropertiesOperation gbpo = new GetBlobPropertiesOperation(datacenterName, connectionPool, requesterPool, getOperationContext(), blobId, operationTimeoutMs, clusterMap);
    gbpo.execute();
    return gbpo.getBlobProperties();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_base_2b1d351\src\org\nutz\lang\Encoding.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
String str
=======
String postStr
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static String encodeURIComponent(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java
String str
=======
String postStr
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_base_2b1d351\src\org\nutz\lang\Encoding.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
str
=======
postStr
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static String encodeURIComponent(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java
String str
=======
String postStr
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
) {
    try {
      return URLEncoder.encode(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java
str
=======
postStr
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java
"UTF-8"
=======
defaultEncoding()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
);
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_base_2b1d351\src\org\nutz\lang\Encoding.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
"UTF-8"
=======
defaultEncoding()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static String encodeURIComponent(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java
String str
=======
String postStr
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
) {
    try {
      return URLEncoder.encode(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java
str
=======
postStr
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_left_6b80c32\src\org\nutz\lang\Encoding.java
"UTF-8"
=======
defaultEncoding()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_6b80c32_b447a8a\rev_right_b447a8a\src\org\nutz\lang\Encoding.java
);
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_left_55ce489\extra\src\org\droidparts\util\io\ImageAttacher.java,C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_base_4c522fb\extra\src\org\droidparts\util\io\ImageAttacher.java,C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_right_25554aa\extra\src\org\droidparts\util\io\ImageAttacher.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
addAndExecute(view, new Pair<String, View>(imgUrl, null))
=======
attachImageCrossFaded(view, imgUrl, null)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void attachImage(ImageView view, String imgUrl) {
    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_left_55ce489\extra\src\org\droidparts\util\io\ImageAttacher.java
addAndExecute(view, new Pair<String, View>(imgUrl, null))
=======
attachImageCrossFaded(view, imgUrl, null)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_right_25554aa\extra\src\org\droidparts\util\io\ImageAttacher.java
;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_left_55ce489\extra\src\org\droidparts\util\io\ImageAttacher.java,C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_base_4c522fb\extra\src\org\droidparts\util\io\ImageAttacher.java,C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_right_25554aa\extra\src\org\droidparts\util\io\ImageAttacher.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
addAndExecute(view, new Pair<String, View>(imgUrl, placeholderView));
=======
exec.execute(fetchAndAttachRunnable);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void attachImageCrossFaded(ImageView view, String imgUrl, View placeholderView) {
    placeholderView.setVisibility(VISIBLE);
    view.setVisibility(INVISIBLE);
    map.put(view, new Pair<String, View>(imgUrl, placeholderView));
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_left_55ce489\extra\src\org\droidparts\util\io\ImageAttacher.java
addAndExecute(view, new Pair<String, View>(imgUrl, placeholderView));
=======
exec.execute(fetchAndAttachRunnable);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\droidparts\revisions\rev_55ce489_25554aa\rev_right_25554aa\extra\src\org\droidparts\util\io\ImageAttacher.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_7d44bae_337b9d9\rev_left_7d44bae\curator-client\src\main\java\org\apache\curator\ensemble\fixed\FixedEnsembleProvider.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_7d44bae_337b9d9\rev_base_1571588\curator-client\src\main\java\org\apache\curator\ensemble\fixed\FixedEnsembleProvider.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_7d44bae_337b9d9\rev_right_337b9d9\curator-client\src\main\java\org\apache\curator\ensemble\fixed\FixedEnsembleProvider.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
updateServerListEnabled
=======
connectionString
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public FixedEnsembleProvider(String connectionString, boolean updateServerListEnabled) {
    Preconditions.checkArgument(!Strings.isNullOrEmpty(connectionString), "connectionString cannot be null or empty");
    this.updateServerListEnabled = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_7d44bae_337b9d9\rev_left_7d44bae\curator-client\src\main\java\org\apache\curator\ensemble\fixed\FixedEnsembleProvider.java
updateServerListEnabled
=======
connectionString
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_7d44bae_337b9d9\rev_right_337b9d9\curator-client\src\main\java\org\apache\curator\ensemble\fixed\FixedEnsembleProvider.java
;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_base_7bb3f9d\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
configuration.get(BASIC_METRICS)
=======
GraphDatabaseConfiguration.isMetricsEnabled(storageConfig, metricsConfig)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Backend(Configuration configuration, Configuration metricsConfig) {
    this.configuration = configuration;
    storeManager = getStorageManager(configuration);
    indexes = getIndexes(configuration);
    storeFeatures = storeManager.getFeatures();
    if (null == metricsConfig) {
      metricsConfig = new BaseConfiguration();
    }
    basicMetrics = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
configuration.get(BASIC_METRICS)
=======
GraphDatabaseConfiguration.isMetricsEnabled(storageConfig, metricsConfig)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
;
    mergeBasicMetrics = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
configuration.get(MERGE_BASIC_METRICS)
=======
GraphDatabaseConfiguration.isMetricsMergingEnabled(storageConfig, metricsConfig)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
;
    Preconditions.checkArgument(bufferSizeTmp >= 0, "Buffer size must be non-negative (use 0 to disable)");
    if (!storeFeatures.supportsBatchMutation()) {
      bufferSize = 0;
      log.debug("Buffering disabled because backend does not support batch mutations");
    }
    else 
      bufferSize = bufferSizeTmp;
    writeAttempts = configuration.get(WRITE_ATTEMPTS);
    readAttempts = configuration.get(READ_ATTEMPTS);
    persistAttemptWaittime = configuration.get(STORAGE_ATTEMPT_WAITTIME);
    if (configuration.get(PARALLEL_BACKEND_OPS)) {
      int poolsize = Math.min(1, Runtime.getRuntime().availableProcessors()) * THREAD_POOL_SIZE_SCALE_FACTOR;
      threadPool = Executors.newFixedThreadPool(poolsize);
      log.info("Initiated backend operations thread pool of size {}", poolsize);
    }
    else {
      threadPool = null;
    }
    final String lockBackendName = configuration.get(LOCK_BACKEND);
    if (REGISTERED_LOCKERS.containsKey(lockBackendName)) {
      lockerCreator = REGISTERED_LOCKERS.get(lockBackendName);
    }
    else {
      throw new TitanConfigurationException("Unknown lock backend \"" + lockBackendName + "\".  Known lock backends: " + Joiner.on(", ").join(REGISTERED_LOCKERS.keySet()) + ".");
    }
    Preconditions.checkNotNull(lockerCreator);
    if (storeFeatures.isDistributed() && storeFeatures.isKeyOrdered()) {
      log.debug("Wrapping index store with HashPrefix");
      hashPrefixIndex = true;
    }
    else {
      hashPrefixIndex = false;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_base_7bb3f9d\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
configuration.get(MERGE_BASIC_METRICS)
=======
GraphDatabaseConfiguration.isMetricsMergingEnabled(storageConfig, metricsConfig)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Backend(Configuration configuration, Configuration metricsConfig) {
    this.configuration = configuration;
    storeManager = getStorageManager(configuration);
    indexes = getIndexes(configuration);
    storeFeatures = storeManager.getFeatures();
    if (null == metricsConfig) {
      metricsConfig = new BaseConfiguration();
    }
    basicMetrics = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
configuration.get(BASIC_METRICS)
=======
GraphDatabaseConfiguration.isMetricsEnabled(storageConfig, metricsConfig)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
;
    mergeBasicMetrics = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
configuration.get(MERGE_BASIC_METRICS)
=======
GraphDatabaseConfiguration.isMetricsMergingEnabled(storageConfig, metricsConfig)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\Backend.java
;
    Preconditions.checkArgument(bufferSizeTmp >= 0, "Buffer size must be non-negative (use 0 to disable)");
    if (!storeFeatures.supportsBatchMutation()) {
      bufferSize = 0;
      log.debug("Buffering disabled because backend does not support batch mutations");
    }
    else 
      bufferSize = bufferSizeTmp;
    writeAttempts = configuration.get(WRITE_ATTEMPTS);
    readAttempts = configuration.get(READ_ATTEMPTS);
    persistAttemptWaittime = configuration.get(STORAGE_ATTEMPT_WAITTIME);
    if (configuration.get(PARALLEL_BACKEND_OPS)) {
      int poolsize = Math.min(1, Runtime.getRuntime().availableProcessors()) * THREAD_POOL_SIZE_SCALE_FACTOR;
      threadPool = Executors.newFixedThreadPool(poolsize);
      log.info("Initiated backend operations thread pool of size {}", poolsize);
    }
    else {
      threadPool = null;
    }
    final String lockBackendName = configuration.get(LOCK_BACKEND);
    if (REGISTERED_LOCKERS.containsKey(lockBackendName)) {
      lockerCreator = REGISTERED_LOCKERS.get(lockBackendName);
    }
    else {
      throw new TitanConfigurationException("Unknown lock backend \"" + lockBackendName + "\".  Known lock backends: " + Joiner.on(", ").join(REGISTERED_LOCKERS.keySet()) + ".");
    }
    Preconditions.checkNotNull(lockerCreator);
    if (storeFeatures.isDistributed() && storeFeatures.isKeyOrdered()) {
      log.debug("Wrapping index store with HashPrefix");
      hashPrefixIndex = true;
    }
    else {
      hashPrefixIndex = false;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\configuration\GraphDatabaseConfiguration.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_base_7bb3f9d\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\configuration\GraphDatabaseConfiguration.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\configuration\GraphDatabaseConfiguration.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (!configuration.get(BASIC_METRICS)) {
      metricsPrefix = null;
    }
    else {
      Preconditions.checkNotNull(metricsPrefix);
    }
=======
if (enableMetrics) {
      Configuration metricsConf = configuration.subset(METRICS_NAMESPACE);
      metricsPrefix = metricsConf.getString(METRICS_PREFIX_KEY, METRICS_PREFIX_DEFAULT);
      Preconditions.checkNotNull(metricsPrefix);
      configureMetricsConsoleReporter(metricsConf);
      configureMetricsCsvReporter(metricsConf);
      configureMetricsJmxReporter(metricsConf);
      configureMetricsSlf4jReporter(metricsConf);
      configureMetricsGangliaReporter(metricsConf);
      configureMetricsGraphiteReporter(metricsConf);
    }
    else {
      metricsPrefix = null;
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void configureMetrics() {
    Preconditions.checkNotNull(configuration);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\configuration\GraphDatabaseConfiguration.java
metricsPrefix = configuration.get(METRICS_PREFIX);
=======
final boolean enableMetrics = isMetricsEnabledInGraphConfig(configuration);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\configuration\GraphDatabaseConfiguration.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_left_b7abc2e\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\configuration\GraphDatabaseConfiguration.java
if (!configuration.get(BASIC_METRICS)) {
      metricsPrefix = null;
    }
    else {
      Preconditions.checkNotNull(metricsPrefix);
    }
=======
if (enableMetrics) {
      Configuration metricsConf = configuration.subset(METRICS_NAMESPACE);
      metricsPrefix = metricsConf.getString(METRICS_PREFIX_KEY, METRICS_PREFIX_DEFAULT);
      Preconditions.checkNotNull(metricsPrefix);
      configureMetricsConsoleReporter(metricsConf);
      configureMetricsCsvReporter(metricsConf);
      configureMetricsJmxReporter(metricsConf);
      configureMetricsSlf4jReporter(metricsConf);
      configureMetricsGangliaReporter(metricsConf);
      configureMetricsGraphiteReporter(metricsConf);
    }
    else {
      metricsPrefix = null;
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_b7abc2e_902237a\rev_right_902237a\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\configuration\GraphDatabaseConfiguration.java

    configureMetricsConsoleReporter();
    configureMetricsCsvReporter();
    configureMetricsJmxReporter();
    configureMetricsSlf4jReporter();
    configureMetricsGangliaReporter();
    configureMetricsGraphiteReporter();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_4c0b2d3_0559a45\rev_left_4c0b2d3\flyway-core\src\main\java\com\googlecode\flyway\core\migration\sql\SqlScript.java,C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_4c0b2d3_0559a45\rev_base_3002c8c\flyway-core\src\main\java\com\googlecode\flyway\core\migration\sql\SqlScript.java,C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_4c0b2d3_0559a45\rev_right_0559a45\flyway-core\src\main\java\com\googlecode\flyway\core\migration\sql\SqlScript.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (LOG.isDebugEnabled()) {
          LOG.debug("Found statement at line " + statementLineNumber + ": " + statementSql);
        }
=======
if (!isDelimiterChangeExplicit()) {
          delimiter = DEFAULT_STATEMENT_DELIMITER;
        }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  List<SqlStatement> linesToStatements(List<String> lines) {
    List<SqlStatement> statements = new ArrayList<SqlStatement>();
    int statementLineNumber = 0;
    String statementSql = "";
    String delimiter = DEFAULT_STATEMENT_DELIMITER;
    for (int lineNumber = 1; lineNumber <= lines.size(); lineNumber++) {
      String line = lines.get(lineNumber - 1);
      if (line.isEmpty()) {
        continue ;
      }
      if (statementSql.isEmpty()) {
        statementLineNumber = lineNumber;
      }
      else {
        statementSql += " ";
      }
      statementSql += line;
      String newDelimiter = checkForNewDelimiter(line);
      if (newDelimiter != null) {
        delimiter = newDelimiter;
        if (isDelimiterChangeExplicit()) {
          statementSql = "";
          continue ;
        }
      }
      if (line.endsWith(delimiter)) {
        String noDelimiterStatementSql = stripDelimiter(statementSql, delimiter);
        statements.add(new SqlStatement(statementLineNumber, noDelimiterStatementSql));
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_4c0b2d3_0559a45\rev_left_4c0b2d3\flyway-core\src\main\java\com\googlecode\flyway\core\migration\sql\SqlScript.java
if (LOG.isDebugEnabled()) {
          LOG.debug("Found statement at line " + statementLineNumber + ": " + statementSql);
        }
=======
if (!isDelimiterChangeExplicit()) {
          delimiter = DEFAULT_STATEMENT_DELIMITER;
        }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\flyway\revisions\rev_4c0b2d3_0559a45\rev_right_0559a45\flyway-core\src\main\java\com\googlecode\flyway\core\migration\sql\SqlScript.java

        delimiter = DEFAULT_STATEMENT_DELIMITER;
        statementSql = "";
      }
    }
    if (!statementSql.isEmpty()) {
      statements.add(new SqlStatement(statementLineNumber, statementSql));
    }
    return statements;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e7d57ec_b3939ac\rev_left_e7d57ec\curator-recipes\src\main\java\org\apache\curator\framework\recipes\nodes\PersistentNode.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e7d57ec_b3939ac\rev_base_d034aea\curator-recipes\src\main\java\org\apache\curator\framework\recipes\nodes\PersistentNode.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e7d57ec_b3939ac\rev_right_b3939ac\curator-recipes\src\main\java\org\apache\curator\framework\recipes\nodes\PersistentNode.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
createMethod = useProtection ? createBuilder.creatingParentContainersIfNeeded().withProtection() : createBuilder.creatingParentContainersIfNeeded();
=======
this.data.set(Arrays.copyOf(data, data.length));
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public PersistentNode(CuratorFramework givenClient, final CreateMode mode, boolean useProtection, final String basePath, byte[] initData, long ttl) {
    this.useProtection = useProtection;
    this.client = Preconditions.checkNotNull(givenClient, "client cannot be null").newWatcherRemoveCuratorFramework();
    this.basePath = PathUtils.validatePath(basePath);
    this.mode = Preconditions.checkNotNull(mode, "mode cannot be null");
    final byte[] data = Preconditions.checkNotNull(initData, "data cannot be null");
    backgroundCallback = new BackgroundCallback() {
        @Override public void processResult(CuratorFramework dummy, CuratorEvent event) throws Exception {
          if (isActive()) {
            processBackgroundCallback(event);
          }
          else {
            processBackgroundCallbackClosedState(event);
          }
        }
    };
    CreateBuilderMain createBuilder = mode.isTTL() ? client.create().withTtl(ttl) : client.create();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e7d57ec_b3939ac\rev_left_e7d57ec\curator-recipes\src\main\java\org\apache\curator\framework\recipes\nodes\PersistentNode.java
createMethod = useProtection ? createBuilder.creatingParentContainersIfNeeded().withProtection() : createBuilder.creatingParentContainersIfNeeded();
=======
this.data.set(Arrays.copyOf(data, data.length));
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_e7d57ec_b3939ac\rev_right_b3939ac\curator-recipes\src\main\java\org\apache\curator\framework\recipes\nodes\PersistentNode.java

    this.data.set(Arrays.copyOf(data, data.length));
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_left_44abe2f\app\src\processing\app\contrib\ContributionListPanel.java,C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_base_02b13ab\app\src\processing\app\contrib\ContributionListPanel.java,C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_right_1c1d660\app\src\processing\app\contrib\ContributionListPanel.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
dtm.getDataVector().removeAllElements();
=======
if (contributionTab.contributionType != null) {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
    }
    else {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
      GridBagConstraints c = new GridBagConstraints();
      c.fill = GridBagConstraints.BOTH;
      c.weightx = 1;
      c.weighty = 1;
      c.gridx = 0;
      c.gridy = row++;
      c.anchor = GridBagConstraints.NORTH;
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void updatePanelOrdering() {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_left_44abe2f\app\src\processing\app\contrib\ContributionListPanel.java
dtm.getDataVector().removeAllElements();
=======
if (contributionTab.contributionType != null) {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
    }
    else {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
      GridBagConstraints c = new GridBagConstraints();
      c.fill = GridBagConstraints.BOTH;
      c.weightx = 1;
      c.weighty = 1;
      c.gridx = 0;
      c.gridy = row++;
      c.anchor = GridBagConstraints.NORTH;
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_right_1c1d660\app\src\processing\app\contrib\ContributionListPanel.java

    dtm.fireTableDataChanged();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_left_44abe2f\app\src\processing\app\contrib\ContributionListPanel.java
for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
      ((DefaultTableModel)table.getModel()).addRow(new Object[]{ entry.getKey(), entry.getKey(), entry.getKey() } );
    }
=======
if (contributionTab.contributionType != null) {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
    }
    else {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
      GridBagConstraints c = new GridBagConstraints();
      c.fill = GridBagConstraints.BOTH;
      c.weightx = 1;
      c.weighty = 1;
      c.gridx = 0;
      c.gridy = row++;
      c.anchor = GridBagConstraints.NORTH;
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_right_1c1d660\app\src\processing\app\contrib\ContributionListPanel.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_left_44abe2f\app\src\processing\app\contrib\ContributionListPanel.java,C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_base_02b13ab\app\src\processing\app\contrib\ContributionListPanel.java,C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_right_1c1d660\app\src\processing\app\contrib\ContributionListPanel.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
      ((DefaultTableModel)table.getModel()).addRow(new Object[]{ entry.getKey(), entry.getKey(), entry.getKey() } );
    }
=======
if (contributionTab.contributionType != null) {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
    }
    else {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
      GridBagConstraints c = new GridBagConstraints();
      c.fill = GridBagConstraints.BOTH;
      c.weightx = 1;
      c.weighty = 1;
      c.gridx = 0;
      c.gridy = row++;
      c.anchor = GridBagConstraints.NORTH;
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void updatePanelOrdering() {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_left_44abe2f\app\src\processing\app\contrib\ContributionListPanel.java
dtm.getDataVector().removeAllElements();
=======
if (contributionTab.contributionType != null) {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
    }
    else {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
      GridBagConstraints c = new GridBagConstraints();
      c.fill = GridBagConstraints.BOTH;
      c.weightx = 1;
      c.weighty = 1;
      c.gridx = 0;
      c.gridy = row++;
      c.anchor = GridBagConstraints.NORTH;
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_right_1c1d660\app\src\processing\app\contrib\ContributionListPanel.java

    dtm.fireTableDataChanged();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_left_44abe2f\app\src\processing\app\contrib\ContributionListPanel.java
for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
      ((DefaultTableModel)table.getModel()).addRow(new Object[]{ entry.getKey(), entry.getKey(), entry.getKey() } );
    }
=======
if (contributionTab.contributionType != null) {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
    }
    else {
      int row = 0;
      for (Entry<Contribution, ContributionPanel> entry : panelByContribution.entrySet()) {
        GridBagConstraints c = new GridBagConstraints();
        c.fill = GridBagConstraints.HORIZONTAL;
        c.weightx = 1;
        c.gridx = 0;
        c.gridy = row++;
        c.anchor = GridBagConstraints.NORTH;
        add(entry.getValue(), c);
      }
      GridBagConstraints c = new GridBagConstraints();
      c.fill = GridBagConstraints.BOTH;
      c.weightx = 1;
      c.weighty = 1;
      c.gridx = 0;
      c.gridy = row++;
      c.anchor = GridBagConstraints.NORTH;
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_44abe2f_1c1d660\rev_right_1c1d660\app\src\processing\app\contrib\ContributionListPanel.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_644f632_f9821d6\rev_left_644f632\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_644f632_f9821d6\rev_base_9a6a886\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_644f632_f9821d6\rev_right_f9821d6\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
return handleAssociation(entity, relationsMap, m, pd);
=======
for (Relation relation : m.getRelations()) {
      FetchType fetchType = relation.getFetchType();
      if (fetchType.equals(FetchType.LAZY)) {
        associationBuilder.setProxyRelationObject(entity, relationsMap, m, pd, entityId, relation);
        continue ;
      }
      associationBuilder.setConcreteRelationObject(entity, relationsMap, m, pd, entityId, relation);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Object recursivelyFindEntities(Object entity, Map<String, Object> relationsMap, EntityMetadata m, PersistenceDelegator pd) {
    associationBuilder = new AssociationBuilder();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_644f632_f9821d6\rev_left_644f632\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java
return handleAssociation(entity, relationsMap, m, pd);
=======
for (Relation relation : m.getRelations()) {
      FetchType fetchType = relation.getFetchType();
      if (fetchType.equals(FetchType.LAZY)) {
        associationBuilder.setProxyRelationObject(entity, relationsMap, m, pd, entityId, relation);
        continue ;
      }
      associationBuilder.setConcreteRelationObject(entity, relationsMap, m, pd, entityId, relation);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_644f632_f9821d6\rev_right_f9821d6\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_left_d4aa650\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java,C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_base_7515683\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java,C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_right_fe8d343\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Configuration tsoClientHbaseConf = HBaseConfiguration.create();
=======
Runtime.getRuntime().addShutdownHook(new Thread() {
        public void run() {
          try {
            registrationService.close();
            logger.info("ooo Omid ooo - Omid\'s Notification Example App Stopped (CTRL+C) - ooo Omid ooo");
          }
          catch (IOException e) {
          }
        }
    });
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @SuppressWarnings(value = {"static-access", }) public static void main(String[] args) throws Exception {
    final OmidDelta registrationService = new OmidDelta("ExampleApp");
    CommandLineParser cmdLineParser = new ExtendedPosixParser(true);
    Options options = new Options();
    options.addOption(OptionBuilder.withLongOpt("txs").withDescription("Number of transactions to execute").withType(Number.class).hasArg().withArgName("argname").create());
    options.addOption(OptionBuilder.withLongOpt("rows-per-tx").withDescription("Number of rows that each transaction inserts").withType(Number.class).hasArg().withArgName("argname").create());
    int txsToExecute = 1;
    int rowsPerTx = 1;
    try {
      CommandLine cmdLine = cmdLineParser.parse(options, args);
      if (cmdLine.hasOption("txs")) {
        txsToExecute = ((Number)cmdLine.getParsedOptionValue("txs")).intValue();
      }
      if (cmdLine.hasOption("rows-per-tx")) {
        rowsPerTx = ((Number)cmdLine.getParsedOptionValue("rows-per-tx")).intValue();
      }
      cdl = new CountDownLatch(txsToExecute * rowsPerTx * 2);
    }
    catch (ParseException e) {
      e.printStackTrace();
      System.exit(1);
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_left_d4aa650\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java
Configuration tsoClientHbaseConf = HBaseConfiguration.create();
=======
Runtime.getRuntime().addShutdownHook(new Thread() {
        public void run() {
          try {
            registrationService.close();
            logger.info("ooo Omid ooo - Omid\'s Notification Example App Stopped (CTRL+C) - ooo Omid ooo");
          }
          catch (IOException e) {
          }
        }
    });
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_right_fe8d343\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java

    tsoClientHbaseConf.set("tso.host", "localhost");
    tsoClientHbaseConf.setInt("tso.port", 1234);
    logger.info("ooo Omid ooo - STARTING OMID\'S EXAMPLE NOTIFICATION APP. - ooo Omid ooo");
    logger.info("ooo Omid ooo -" + " A table called " + Constants.TABLE_1 + " with a column Family " + Constants.COLUMN_FAMILY_1 + " has been already created by the Omid Infrastructure " + "- ooo Omid ooo");
    Observer obs1 = new Observer() {
        Interest interestObs1 = new Interest(Constants.TABLE_1, Constants.COLUMN_FAMILY_1, Constants.COLUMN_1);
        public void onColumnChanged(byte[] column, byte[] columnFamily, byte[] table, byte[] rowKey, TransactionState tx) {
          logger.info("ooo Omid ooo -" + "I\'M OBSERVER o1." + " An update has occurred on Table: " + Bytes.toString(table) + " RowKey: " + Bytes.toString(rowKey) + " ColumnFamily: " + Bytes.toString(columnFamily) + " Column: " + Bytes.toString(column) + " !!! - ooo Omid ooo");
          logger.info("ooo Omid ooo - OBSERVER o1 INSERTING A NEW ROW ON COLUMN " + Constants.COLUMN_2 + " UNDER TRANSACTIONAL CONTEXT " + tx + " - ooo Omid ooo");
          Configuration tsoClientConf = HBaseConfiguration.create();
          tsoClientConf.set("tso.host", "localhost");
          tsoClientConf.setInt("tso.port", 1234);
          try {
            TransactionalTable tt = new TransactionalTable(tsoClientConf, Constants.TABLE_1);
            doTransactionalPut(tx, tt, rowKey, Bytes.toBytes(Constants.COLUMN_FAMILY_1), Bytes.toBytes(Constants.COLUMN_2), Bytes.toBytes("Data written by OBSERVER o1"));
          }
          catch (IOException e) {
            e.printStackTrace();
          }
          cdl.countDown();
        }
        @Override public String getName() {
          return "o1";
        }
        @Override public List<Interest> getInterests() {
          return Collections.singletonList(interestObs1);
        }
    };
    Observer obs2 = new Observer() {
        Interest interestObs2 = new Interest(Constants.TABLE_1, Constants.COLUMN_FAMILY_1, Constants.COLUMN_2);
        public void onColumnChanged(byte[] column, byte[] columnFamily, byte[] table, byte[] rowKey, TransactionState tx) {
          logger.info("ooo Omid ooo - " + "I\'M OBSERVER o2." + " An update has occurred on Table: " + Bytes.toString(table) + " RowKey: " + Bytes.toString(rowKey) + " ColumnFamily: " + Bytes.toString(columnFamily) + " Column: " + Bytes.toString(column) + " !!! I\'M NOT GONNA DO ANYTHING ELSE - ooo Omid ooo");
          cdl.countDown();
        }
        @Override public String getName() {
          return "o2";
        }
        @Override public List<Interest> getInterests() {
          return Collections.singletonList(interestObs2);
        }
    };
    final IncrementalApplication app = new DeltaOmid.AppBuilder("ExampleApp").addObserver(obs1).addObserver(obs2).build();
    Runtime.getRuntime().addShutdownHook(new Thread() {
        public void run() {
          try {
            app.close();
            logger.info("ooo Omid ooo - Omid\'s Notification Example App Stopped (CTRL+C) - ooo Omid ooo");
          }
          catch (IOException e) {
          }
        }
    });
    logger.info("ooo Omid ooo - WAITING 5 SECONDS TO ALLOW OBSERVER REGISTRATION - ooo Omid ooo");
    Thread.currentThread().sleep(5000);
    TransactionManager tm = new TransactionManager(tsoClientHbaseConf);
    TransactionalTable tt = new TransactionalTable(tsoClientHbaseConf, Constants.TABLE_1);
    logger.info("ooo Omid ooo - STARTING " + txsToExecute + " TRIGGER TXS INSERTING " + rowsPerTx + " ROWS EACH IN COLUMN " + Constants.COLUMN_1 + " - ooo Omid ooo");
    for (int i = 0; i < txsToExecute; i++) {
      TransactionState tx = tm.beginTransaction();
      for (int j = 0; j < rowsPerTx; j++) {
        Put row = new Put(Bytes.toBytes("row-" + Integer.toString(i + (j * 10000))));
        row.add(Bytes.toBytes(Constants.COLUMN_FAMILY_1), Bytes.toBytes(Constants.COLUMN_1), Bytes.toBytes("testWrite-" + Integer.toString(i + (j * 10000))));
        tt.put(tx, row);
      }
      tm.tryCommit(tx);
    }
    logger.info("ooo Omid ooo - TRIGGER TXS COMMITTED - ooo Omid ooo");
    tt.close();
    logger.info("ooo Omid ooo - WAITING TO ALLOW THE 2 OBSERVERS RECEIVING ALL THE NOTIFICATIONS - ooo Omid ooo");
    cdl.await();
    logger.info("ooo Omid ooo - OBSERVERS HAVE RECEIVED ALL THE NOTIFICATIONS WAITING 30 SECONDS TO ALLOW FINISHING CLEARING STUFF - ooo Omid ooo");
    Thread.currentThread().sleep(30000);
    app.close();
    Thread.currentThread().sleep(10000);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_left_d4aa650\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java
logger.info("ooo Omid ooo - OMID\'S NOTIFICATION APP FINISHED - ooo Omid ooo");
=======
registrationService.close();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_right_fe8d343\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_left_d4aa650\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java,C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_base_7515683\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java,C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_right_fe8d343\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
logger.info("ooo Omid ooo - OMID\'S NOTIFICATION APP FINISHED - ooo Omid ooo");
=======
registrationService.close();
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @SuppressWarnings(value = {"static-access", }) public static void main(String[] args) throws Exception {
    final OmidDelta registrationService = new OmidDelta("ExampleApp");
    CommandLineParser cmdLineParser = new ExtendedPosixParser(true);
    Options options = new Options();
    options.addOption(OptionBuilder.withLongOpt("txs").withDescription("Number of transactions to execute").withType(Number.class).hasArg().withArgName("argname").create());
    options.addOption(OptionBuilder.withLongOpt("rows-per-tx").withDescription("Number of rows that each transaction inserts").withType(Number.class).hasArg().withArgName("argname").create());
    int txsToExecute = 1;
    int rowsPerTx = 1;
    try {
      CommandLine cmdLine = cmdLineParser.parse(options, args);
      if (cmdLine.hasOption("txs")) {
        txsToExecute = ((Number)cmdLine.getParsedOptionValue("txs")).intValue();
      }
      if (cmdLine.hasOption("rows-per-tx")) {
        rowsPerTx = ((Number)cmdLine.getParsedOptionValue("rows-per-tx")).intValue();
      }
      cdl = new CountDownLatch(txsToExecute * rowsPerTx * 2);
    }
    catch (ParseException e) {
      e.printStackTrace();
      System.exit(1);
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_left_d4aa650\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java
Configuration tsoClientHbaseConf = HBaseConfiguration.create();
=======
Runtime.getRuntime().addShutdownHook(new Thread() {
        public void run() {
          try {
            registrationService.close();
            logger.info("ooo Omid ooo - Omid\'s Notification Example App Stopped (CTRL+C) - ooo Omid ooo");
          }
          catch (IOException e) {
          }
        }
    });
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_right_fe8d343\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java

    tsoClientHbaseConf.set("tso.host", "localhost");
    tsoClientHbaseConf.setInt("tso.port", 1234);
    logger.info("ooo Omid ooo - STARTING OMID\'S EXAMPLE NOTIFICATION APP. - ooo Omid ooo");
    logger.info("ooo Omid ooo -" + " A table called " + Constants.TABLE_1 + " with a column Family " + Constants.COLUMN_FAMILY_1 + " has been already created by the Omid Infrastructure " + "- ooo Omid ooo");
    Observer obs1 = new Observer() {
        Interest interestObs1 = new Interest(Constants.TABLE_1, Constants.COLUMN_FAMILY_1, Constants.COLUMN_1);
        public void onColumnChanged(byte[] column, byte[] columnFamily, byte[] table, byte[] rowKey, TransactionState tx) {
          logger.info("ooo Omid ooo -" + "I\'M OBSERVER o1." + " An update has occurred on Table: " + Bytes.toString(table) + " RowKey: " + Bytes.toString(rowKey) + " ColumnFamily: " + Bytes.toString(columnFamily) + " Column: " + Bytes.toString(column) + " !!! - ooo Omid ooo");
          logger.info("ooo Omid ooo - OBSERVER o1 INSERTING A NEW ROW ON COLUMN " + Constants.COLUMN_2 + " UNDER TRANSACTIONAL CONTEXT " + tx + " - ooo Omid ooo");
          Configuration tsoClientConf = HBaseConfiguration.create();
          tsoClientConf.set("tso.host", "localhost");
          tsoClientConf.setInt("tso.port", 1234);
          try {
            TransactionalTable tt = new TransactionalTable(tsoClientConf, Constants.TABLE_1);
            doTransactionalPut(tx, tt, rowKey, Bytes.toBytes(Constants.COLUMN_FAMILY_1), Bytes.toBytes(Constants.COLUMN_2), Bytes.toBytes("Data written by OBSERVER o1"));
          }
          catch (IOException e) {
            e.printStackTrace();
          }
          cdl.countDown();
        }
        @Override public String getName() {
          return "o1";
        }
        @Override public List<Interest> getInterests() {
          return Collections.singletonList(interestObs1);
        }
    };
    Observer obs2 = new Observer() {
        Interest interestObs2 = new Interest(Constants.TABLE_1, Constants.COLUMN_FAMILY_1, Constants.COLUMN_2);
        public void onColumnChanged(byte[] column, byte[] columnFamily, byte[] table, byte[] rowKey, TransactionState tx) {
          logger.info("ooo Omid ooo - " + "I\'M OBSERVER o2." + " An update has occurred on Table: " + Bytes.toString(table) + " RowKey: " + Bytes.toString(rowKey) + " ColumnFamily: " + Bytes.toString(columnFamily) + " Column: " + Bytes.toString(column) + " !!! I\'M NOT GONNA DO ANYTHING ELSE - ooo Omid ooo");
          cdl.countDown();
        }
        @Override public String getName() {
          return "o2";
        }
        @Override public List<Interest> getInterests() {
          return Collections.singletonList(interestObs2);
        }
    };
    final IncrementalApplication app = new DeltaOmid.AppBuilder("ExampleApp").addObserver(obs1).addObserver(obs2).build();
    Runtime.getRuntime().addShutdownHook(new Thread() {
        public void run() {
          try {
            app.close();
            logger.info("ooo Omid ooo - Omid\'s Notification Example App Stopped (CTRL+C) - ooo Omid ooo");
          }
          catch (IOException e) {
          }
        }
    });
    logger.info("ooo Omid ooo - WAITING 5 SECONDS TO ALLOW OBSERVER REGISTRATION - ooo Omid ooo");
    Thread.currentThread().sleep(5000);
    TransactionManager tm = new TransactionManager(tsoClientHbaseConf);
    TransactionalTable tt = new TransactionalTable(tsoClientHbaseConf, Constants.TABLE_1);
    logger.info("ooo Omid ooo - STARTING " + txsToExecute + " TRIGGER TXS INSERTING " + rowsPerTx + " ROWS EACH IN COLUMN " + Constants.COLUMN_1 + " - ooo Omid ooo");
    for (int i = 0; i < txsToExecute; i++) {
      TransactionState tx = tm.beginTransaction();
      for (int j = 0; j < rowsPerTx; j++) {
        Put row = new Put(Bytes.toBytes("row-" + Integer.toString(i + (j * 10000))));
        row.add(Bytes.toBytes(Constants.COLUMN_FAMILY_1), Bytes.toBytes(Constants.COLUMN_1), Bytes.toBytes("testWrite-" + Integer.toString(i + (j * 10000))));
        tt.put(tx, row);
      }
      tm.tryCommit(tx);
    }
    logger.info("ooo Omid ooo - TRIGGER TXS COMMITTED - ooo Omid ooo");
    tt.close();
    logger.info("ooo Omid ooo - WAITING TO ALLOW THE 2 OBSERVERS RECEIVING ALL THE NOTIFICATIONS - ooo Omid ooo");
    cdl.await();
    logger.info("ooo Omid ooo - OBSERVERS HAVE RECEIVED ALL THE NOTIFICATIONS WAITING 30 SECONDS TO ALLOW FINISHING CLEARING STUFF - ooo Omid ooo");
    Thread.currentThread().sleep(30000);
    app.close();
    Thread.currentThread().sleep(10000);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_left_d4aa650\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java
logger.info("ooo Omid ooo - OMID\'S NOTIFICATION APP FINISHED - ooo Omid ooo");
=======
registrationService.close();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\omid\revisions\rev_d4aa650_fe8d343\rev_right_fe8d343\src\main\java\com\yahoo\omid\examples\notifications\ClientNotificationAppExample.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_base_135dcc4\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
getNextMemberInjectedAncestor(type)
=======
getApplicationSupertype(type)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void generateInjectAdapter(TypeElement type, ExecutableElement constructor, List<Element> fields) throws IOException {
    String packageName = getPackage(type).getQualifiedName().toString();
    String strippedTypeName = strippedTypeName(type.getQualifiedName().toString(), packageName);
    TypeMirror supertype = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
getNextMemberInjectedAncestor(type)
=======
getApplicationSupertype(type)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
;
    String adapterName = adapterName(type, INJECT_ADAPTER_SUFFIX);
    JavaFileObject sourceFile = processingEnv.getFiler().createSourceFile(adapterName, type);
    JavaWriter writer = new JavaWriter(sourceFile.openWriter());
    boolean isAbstract = type.getModifiers().contains(ABSTRACT);
    boolean injectMembers = !fields.isEmpty() || supertype != null;
    boolean disambiguateFields = !fields.isEmpty() && (constructor != null) && !constructor.getParameters().isEmpty();
    boolean dependent = injectMembers || ((constructor != null) && !constructor.getParameters().isEmpty());
    writer.emitSingleLineComment(AdapterJavadocs.GENERATED_BY_DAGGER);
    writer.emitPackage(packageName);
    writer.emitImports(findImports(dependent, injectMembers, constructor != null));
    writer.emitEmptyLine();
    writer.emitJavadoc(bindingTypeDocs(strippedTypeName, isAbstract, injectMembers, dependent));
    writer.beginType(adapterName, "class", EnumSet.of(PUBLIC, FINAL), JavaWriter.type(Binding.class, strippedTypeName), implementedInterfaces(strippedTypeName, injectMembers, constructor != null));
    writeMemberBindingsFields(writer, fields, disambiguateFields);
    if (constructor != null) {
      writeParameterBindingsFields(writer, constructor, disambiguateFields);
    }
    if (supertype != null) {
      writeSupertypeInjectorField(writer, type, supertype);
    }
    writer.emitEmptyLine();
    writeInjectAdapterConstructor(writer, constructor, type, strippedTypeName, adapterName);
    if (dependent) {
      writeAttachMethod(writer, constructor, fields, disambiguateFields, strippedTypeName, supertype, true);
      writeGetDependenciesMethod(writer, constructor, fields, disambiguateFields, supertype, true);
    }
    if (constructor != null) {
      writeGetMethod(writer, constructor, disambiguateFields, injectMembers, strippedTypeName);
    }
    if (injectMembers) {
      writeMembersInjectMethod(writer, fields, disambiguateFields, strippedTypeName, supertype);
    }
    writer.endType();
    writer.close();
    if (supertype != null) {
      generateParentBindings(type, ((TypeElement)processingEnv.getTypeUtils().asElement(supertype)));
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_base_135dcc4\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
CONCLUSAO: FP. OS DEVS ADICIONARAM METÓDOS COM MESMO NOME, MAS ASSINATURAS DIFERENTES.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
TypeElement type
=======
TypeMirror supertype
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void writeSupertypeInjectorField(JavaWriter writer, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
TypeElement type
=======
TypeMirror supertype
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
, TypeMirror nextAncestor);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_base_135dcc4\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
adapterName
=======
JavaWriter.type(Binding.class, rawTypeToString(supertype, '.'))
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void writeSupertypeInjectorField(JavaWriter writer, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
TypeElement type
=======
TypeMirror supertype
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
, TypeMirror nextAncestor) throws IOException {
    TypeElement supertypeElement = ((TypeElement)processingEnv.getTypeUtils().asElement(nextAncestor));
    String adapterName = parentAdapterName(type, supertypeElement);
    writer.emitField(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
adapterName
=======
JavaWriter.type(Binding.class, rawTypeToString(supertype, '.'))
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
"nextInjectableAncestor"
=======
"supertype"
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
, EnumSet.of(PRIVATE), "new " + adapterName + "()");
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_base_135dcc4\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
"nextInjectableAncestor"
=======
"supertype"
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void writeSupertypeInjectorField(JavaWriter writer, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
TypeElement type
=======
TypeMirror supertype
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
, TypeMirror nextAncestor) throws IOException {
    TypeElement supertypeElement = ((TypeElement)processingEnv.getTypeUtils().asElement(nextAncestor));
    String adapterName = parentAdapterName(type, supertypeElement);
    writer.emitField(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
adapterName
=======
JavaWriter.type(Binding.class, rawTypeToString(supertype, '.'))
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
"nextInjectableAncestor"
=======
"supertype"
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
, EnumSet.of(PRIVATE), "new " + adapterName + "()");
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_base_135dcc4\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
"nextInjectableAncestor.getDependencies(null, injectMembersBindings)"
=======
"injectMembersBindings.add(%s)"
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void writeGetDependenciesMethod(JavaWriter writer, ExecutableElement constructor, List<Element> fields, boolean disambiguateFields, TypeMirror supertype, boolean extendsBinding) throws IOException {
    writer.emitJavadoc(AdapterJavadocs.GET_DEPENDENCIES_METHOD);
    if (extendsBinding) {
      writer.emitAnnotation(Override.class);
    }
    String setOfBindings = JavaWriter.type(Set.class, "Binding<?>");
    writer.beginMethod("void", "getDependencies", EnumSet.of(PUBLIC), setOfBindings, "getBindings", setOfBindings, "injectMembersBindings");
    if (constructor != null) {
      for (Element parameter : constructor.getParameters()) {
        writer.emitStatement("getBindings.add(%s)", parameterName(disambiguateFields, parameter));
      }
    }
    for (Element field : fields) {
      writer.emitStatement("injectMembersBindings.add(%s)", fieldName(disambiguateFields, field));
    }
    if (supertype != null) {
      writer.emitStatement(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
"nextInjectableAncestor.getDependencies(null, injectMembersBindings)"
=======
"injectMembersBindings.add(%s)"
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
);
    }
    writer.endMethod();
    writer.emitEmptyLine();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_base_135dcc4\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
"nextInjectableAncestor.injectMembers(object)"
=======
"supertype.injectMembers(object)"
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void writeMembersInjectMethod(JavaWriter writer, List<Element> fields, boolean disambiguateFields, String strippedTypeName, TypeMirror supertype) throws IOException {
    writer.emitJavadoc(AdapterJavadocs.MEMBERS_INJECT_METHOD, strippedTypeName);
    writer.emitAnnotation(Override.class);
    writer.beginMethod("void", "injectMembers", EnumSet.of(PUBLIC), strippedTypeName, "object");
    for (Element field : fields) {
      writer.emitStatement("object.%s = %s.get()", field.getSimpleName(), fieldName(disambiguateFields, field));
    }
    if (supertype != null) {
      writer.emitStatement(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_left_1bc7c83\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
"nextInjectableAncestor.injectMembers(object)"
=======
"supertype.injectMembers(object)"
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\dagger\revisions\rev_1bc7c83_8f2e49e\rev_right_8f2e49e\compiler\src\main\java\dagger\internal\codegen\InjectAdapterProcessor.java
);
    }
    writer.endMethod();
    writer.emitEmptyLine();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_left_9d00b7f\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_base_221cd52\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_right_7202ca5\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Metamodel metamodel = KunderaMetadataManager.getMetamodel(kunderaMetadata, m.getPersistenceUnit());
=======
Client<?> client = pd.getClient(m);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Object generateAndSetId(Object e, EntityMetadata m, PersistenceDelegator pd, final KunderaMetadata kunderaMetadata) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_left_9d00b7f\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java
Metamodel metamodel = KunderaMetadataManager.getMetamodel(kunderaMetadata, m.getPersistenceUnit());
=======
Client<?> client = pd.getClient(m);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_right_7202ca5\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_left_9d00b7f\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java
if (keyValue != null) {
      Client<?> client = pd.getClient(m);
      String clientFactoryName = KunderaMetadataManager.getPersistenceUnitMetadata(kunderaMetadata, m.getPersistenceUnit()).getClient();
      if (clientFactoryName != null && !clientFactoryName.equalsIgnoreCase("com.impetus.client.rdbms.RDBMSClientFactory")) {
        if (client != null) {
          GenerationType type = keyValue.getStrategy();
          switch (type){
            case TABLE:
            return onTableGenerator(m, client, keyValue, e);
            case SEQUENCE:
            return onSequenceGenerator(m, client, keyValue, e);
            case AUTO:
            return onAutoGenerator(m, client, e);
            case IDENTITY:
            throw new UnsupportedOperationException(GenerationType.class.getSimpleName() + "." + type + " Strategy not supported by this client :" + client.getClass().getName());
          }
        }
      }
      else {
        int hashCode = e.hashCode();
        Object generatedId = PropertyAccessorHelper.fromSourceToTargetClass(m.getIdAttribute().getJavaType(), Integer.class, new Integer(hashCode));
        PropertyAccessorHelper.setId(e, m, generatedId);
        return generatedId;
      }
    }
=======
return generateId(e, m, client);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_right_7202ca5\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java

    if (keyValue != null) {
      Client<?> client = pd.getClient(m);
      String clientFactoryName = KunderaMetadataManager.getPersistenceUnitMetadata(kunderaMetadata, m.getPersistenceUnit()).getClient();
      if (clientFactoryName != null && !clientFactoryName.equalsIgnoreCase("com.impetus.client.rdbms.RDBMSClientFactory")) {
        if (client != null) {
          GenerationType type = keyValue.getStrategy();
          switch (type){
            case TABLE:
            return onTableGenerator(m, client, keyValue, e);
            case SEQUENCE:
            return onSequenceGenerator(m, client, keyValue, e);
            case AUTO:
            return onAutoGenerator(m, client, e);
            case IDENTITY:
            throw new UnsupportedOperationException(GenerationType.class.getSimpleName() + "." + type + " Strategy not supported by this client :" + client.getClass().getName());
          }
        }
      }
      else {
        int hashCode = e.hashCode();
        Object generatedId = PropertyAccessorHelper.fromSourceToTargetClass(m.getIdAttribute().getJavaType(), Integer.class, new Integer(hashCode));
        PropertyAccessorHelper.setId(e, m, generatedId);
        return generatedId;
      }
    }
    return null;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_left_9d00b7f\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_base_221cd52\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_right_7202ca5\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (keyValue != null) {
      Client<?> client = pd.getClient(m);
      String clientFactoryName = KunderaMetadataManager.getPersistenceUnitMetadata(kunderaMetadata, m.getPersistenceUnit()).getClient();
      if (clientFactoryName != null && !clientFactoryName.equalsIgnoreCase("com.impetus.client.rdbms.RDBMSClientFactory")) {
        if (client != null) {
          GenerationType type = keyValue.getStrategy();
          switch (type){
            case TABLE:
            return onTableGenerator(m, client, keyValue, e);
            case SEQUENCE:
            return onSequenceGenerator(m, client, keyValue, e);
            case AUTO:
            return onAutoGenerator(m, client, e);
            case IDENTITY:
            throw new UnsupportedOperationException(GenerationType.class.getSimpleName() + "." + type + " Strategy not supported by this client :" + client.getClass().getName());
          }
        }
      }
      else {
        int hashCode = e.hashCode();
        Object generatedId = PropertyAccessorHelper.fromSourceToTargetClass(m.getIdAttribute().getJavaType(), Integer.class, new Integer(hashCode));
        PropertyAccessorHelper.setId(e, m, generatedId);
        return generatedId;
      }
    }
=======
return generateId(e, m, client);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Object generateAndSetId(Object e, EntityMetadata m, PersistenceDelegator pd, final KunderaMetadata kunderaMetadata) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_left_9d00b7f\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java
Metamodel metamodel = KunderaMetadataManager.getMetamodel(kunderaMetadata, m.getPersistenceUnit());
=======
Client<?> client = pd.getClient(m);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_right_7202ca5\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_left_9d00b7f\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java
if (keyValue != null) {
      Client<?> client = pd.getClient(m);
      String clientFactoryName = KunderaMetadataManager.getPersistenceUnitMetadata(kunderaMetadata, m.getPersistenceUnit()).getClient();
      if (clientFactoryName != null && !clientFactoryName.equalsIgnoreCase("com.impetus.client.rdbms.RDBMSClientFactory")) {
        if (client != null) {
          GenerationType type = keyValue.getStrategy();
          switch (type){
            case TABLE:
            return onTableGenerator(m, client, keyValue, e);
            case SEQUENCE:
            return onSequenceGenerator(m, client, keyValue, e);
            case AUTO:
            return onAutoGenerator(m, client, e);
            case IDENTITY:
            throw new UnsupportedOperationException(GenerationType.class.getSimpleName() + "." + type + " Strategy not supported by this client :" + client.getClass().getName());
          }
        }
      }
      else {
        int hashCode = e.hashCode();
        Object generatedId = PropertyAccessorHelper.fromSourceToTargetClass(m.getIdAttribute().getJavaType(), Integer.class, new Integer(hashCode));
        PropertyAccessorHelper.setId(e, m, generatedId);
        return generatedId;
      }
    }
=======
return generateId(e, m, client);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_9d00b7f_7202ca5\rev_right_7202ca5\src\jpa-engine\core\src\main\java\com\impetus\kundera\persistence\IdGenerator.java

    if (keyValue != null) {
      Client<?> client = pd.getClient(m);
      String clientFactoryName = KunderaMetadataManager.getPersistenceUnitMetadata(kunderaMetadata, m.getPersistenceUnit()).getClient();
      if (clientFactoryName != null && !clientFactoryName.equalsIgnoreCase("com.impetus.client.rdbms.RDBMSClientFactory")) {
        if (client != null) {
          GenerationType type = keyValue.getStrategy();
          switch (type){
            case TABLE:
            return onTableGenerator(m, client, keyValue, e);
            case SEQUENCE:
            return onSequenceGenerator(m, client, keyValue, e);
            case AUTO:
            return onAutoGenerator(m, client, e);
            case IDENTITY:
            throw new UnsupportedOperationException(GenerationType.class.getSimpleName() + "." + type + " Strategy not supported by this client :" + client.getClass().getName());
          }
        }
      }
      else {
        int hashCode = e.hashCode();
        Object generatedId = PropertyAccessorHelper.fromSourceToTargetClass(m.getIdAttribute().getJavaType(), Integer.class, new Integer(hashCode));
        PropertyAccessorHelper.setId(e, m, generatedId);
        return generatedId;
      }
    }
    return null;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_left_0ef7278\src\org\nutz\ioc\impl\PropertiesProxy.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_base_5829f22\src\org\nutz\ioc\impl\PropertiesProxy.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_right_2efd2b8\src\org\nutz\ioc\impl\PropertiesProxy.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
boolean defaultValue
=======
boolean dfval
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public boolean getBoolean(String key, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_left_0ef7278\src\org\nutz\ioc\impl\PropertiesProxy.java
boolean defaultValue
=======
boolean dfval
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_right_2efd2b8\src\org\nutz\ioc\impl\PropertiesProxy.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_left_0ef7278\src\org\nutz\ioc\impl\PropertiesProxy.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_base_5829f22\src\org\nutz\ioc\impl\PropertiesProxy.java,C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_right_2efd2b8\src\org\nutz\ioc\impl\PropertiesProxy.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
try {
      return Boolean.parseBoolean(get(key));
    }
    catch (Exception e) {
      return defaultValue;
    }
=======
String val = get(key);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public boolean getBoolean(String key, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_left_0ef7278\src\org\nutz\ioc\impl\PropertiesProxy.java
boolean defaultValue
=======
boolean dfval
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_right_2efd2b8\src\org\nutz\ioc\impl\PropertiesProxy.java
) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_left_0ef7278\src\org\nutz\ioc\impl\PropertiesProxy.java
try {
      return Boolean.parseBoolean(get(key));
    }
    catch (Exception e) {
      return defaultValue;
    }
=======
String val = get(key);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\nutz\revisions\rev_0ef7278_2efd2b8\rev_right_2efd2b8\src\org\nutz\ioc\impl\PropertiesProxy.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_677b35d_bd6cca6\rev_left_677b35d\AttributesAPI\src\org\gephi\data\attributes\api\AttributeType.java,C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_677b35d_bd6cca6\rev_base_90e6e4b\AttributesAPI\src\org\gephi\data\attributes\api\AttributeType.java,C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_677b35d_bd6cca6\rev_right_bd6cca6\AttributesAPI\src\org\gephi\data\attributes\api\AttributeType.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
switch (this){
      case DYNAMIC_BYTE:
      case DYNAMIC_SHORT:
      case DYNAMIC_INT:
      case DYNAMIC_LONG:
      case DYNAMIC_FLOAT:
      case DYNAMIC_DOUBLE:
      case DYNAMIC_BOOLEAN:
      case DYNAMIC_CHAR:
      case DYNAMIC_STRING:
      case DYNAMIC_BIGINTEGER:
      case DYNAMIC_BIGDECIMAL:
      case TIME_INTERVAL:
      return true;
      default:
      return false;
    }
=======
if (this.equals(DYNAMIC_BYTE) || this.equals(DYNAMIC_SHORT) || this.equals(DYNAMIC_INT) || this.equals(DYNAMIC_LONG) || this.equals(DYNAMIC_FLOAT) || this.equals(DYNAMIC_DOUBLE) || this.equals(DYNAMIC_BOOLEAN) || this.equals(DYNAMIC_CHAR) || this.equals(DYNAMIC_STRING) || this.equals(DYNAMIC_BIGINTEGER) || this.equals(DYNAMIC_BIGDECIMAL) || this.equals(TIME_INTERVAL)) {
      return true;
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public boolean isDynamicType() {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_677b35d_bd6cca6\rev_left_677b35d\AttributesAPI\src\org\gephi\data\attributes\api\AttributeType.java
switch (this){
      case DYNAMIC_BYTE:
      case DYNAMIC_SHORT:
      case DYNAMIC_INT:
      case DYNAMIC_LONG:
      case DYNAMIC_FLOAT:
      case DYNAMIC_DOUBLE:
      case DYNAMIC_BOOLEAN:
      case DYNAMIC_CHAR:
      case DYNAMIC_STRING:
      case DYNAMIC_BIGINTEGER:
      case DYNAMIC_BIGDECIMAL:
      case TIME_INTERVAL:
      return true;
      default:
      return false;
    }
=======
if (this.equals(DYNAMIC_BYTE) || this.equals(DYNAMIC_SHORT) || this.equals(DYNAMIC_INT) || this.equals(DYNAMIC_LONG) || this.equals(DYNAMIC_FLOAT) || this.equals(DYNAMIC_DOUBLE) || this.equals(DYNAMIC_BOOLEAN) || this.equals(DYNAMIC_CHAR) || this.equals(DYNAMIC_STRING) || this.equals(DYNAMIC_BIGINTEGER) || this.equals(DYNAMIC_BIGDECIMAL) || this.equals(TIME_INTERVAL)) {
      return true;
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\gephi\revisions\rev_677b35d_bd6cca6\rev_right_bd6cca6\AttributesAPI\src\org\gephi\data\attributes\api\AttributeType.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\worldedit\revisions\rev_9343b3d_73a8646\rev_left_9343b3d\src\main\java\com\sk89q\worldedit\commands\SnapshotCommands.java,C:\Users\user\Desktop\gjcc\amostra\projects\worldedit\revisions\rev_9343b3d_73a8646\rev_base_1e9c5b2\src\main\java\com\sk89q\worldedit\commands\SnapshotCommands.java,C:\Users\user\Desktop\gjcc\amostra\projects\worldedit\revisions\rev_9343b3d_73a8646\rev_right_73a8646\src\main\java\com\sk89q\worldedit\commands\SnapshotCommands.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (snapshots.size() > 0) {
        for (byte i = 0; i < Math.min(num, snapshots.size()); ++i) {
          player.print((i + 1) + ". " + snapshots.get(i).getName());
        }
        player.print("Use /snap use [snapshot] or /snap use latest.");
      }
      else {
        player.printError("No snapshots are available. See console for details.");
        File dir = config.snapshotRepo.getDirectory();
        try {
          logger.info("WorldEdit found no snapshots: looked in: " + dir.getCanonicalPath());
        }
        catch (IOException e) {
          logger.info("WorldEdit found no snapshots: looked in " + "(NON-RESOLVABLE PATH - does it exist?): " + dir.getPath());
        }
      }
=======
for (byte i = 0; i < Math.min(num, snapshots.size()); i++) {
        player.print((i + 1) + ". " + snapshots.get(i).getName());
      }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Command(aliases = {"list", }, usage = "[num]", desc = "List snapshots", min = 0, max = 1) @CommandPermissions(value = {"worldedit.snapshots.list", }) public static void list(CommandContext args, WorldEdit we, LocalSession session, LocalPlayer player, EditSession editSession) throws WorldEditException {
    LocalConfiguration config = we.getConfiguration();
    int num = args.argsLength() > 0 ? Math.min(40, Math.max(5, args.getInteger(0))) : 5;
    String worldName = player.getWorld().getName();
    SnapshotRepository repo = config.snapshotRepositories.get(worldName);
    if (repo == null) {
      player.printError("Snapshot/backup restore is not configured for this world.");
      return ;
    }
    List<Snapshot> snapshots = repo.getSnapshots(true);
    if (snapshots.size() > 0) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\worldedit\revisions\rev_9343b3d_73a8646\rev_left_9343b3d\src\main\java\com\sk89q\worldedit\commands\SnapshotCommands.java
if (snapshots.size() > 0) {
        for (byte i = 0; i < Math.min(num, snapshots.size()); ++i) {
          player.print((i + 1) + ". " + snapshots.get(i).getName());
        }
        player.print("Use /snap use [snapshot] or /snap use latest.");
      }
      else {
        player.printError("No snapshots are available. See console for details.");
        File dir = config.snapshotRepo.getDirectory();
        try {
          logger.info("WorldEdit found no snapshots: looked in: " + dir.getCanonicalPath());
        }
        catch (IOException e) {
          logger.info("WorldEdit found no snapshots: looked in " + "(NON-RESOLVABLE PATH - does it exist?): " + dir.getPath());
        }
      }
=======
for (byte i = 0; i < Math.min(num, snapshots.size()); i++) {
        player.print((i + 1) + ". " + snapshots.get(i).getName());
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\worldedit\revisions\rev_9343b3d_73a8646\rev_right_73a8646\src\main\java\com\sk89q\worldedit\commands\SnapshotCommands.java

      if (snapshots.size() > 0) {
        for (byte i = 0; i < Math.min(num, snapshots.size()); ++i) {
          player.print((i + 1) + ". " + snapshots.get(i).getName());
        }
        player.print("Use /snap use [snapshot] or /snap use latest.");
      }
      else {
        player.printError("No snapshots are available. See console for details.");
        File dir = config.snapshotRepo.getDirectory();
        try {
          logger.info("WorldEdit found no snapshots: looked in: " + dir.getCanonicalPath());
        }
        catch (IOException e) {
          logger.info("WorldEdit found no snapshots: looked in " + "(NON-RESOLVABLE PATH - does it exist?): " + dir.getPath());
        }
      }
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_6520395_119e9ba\rev_left_6520395\core\src\main\java\org\elasticsearch\discovery\zen\ping\ZenPingService.java,C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_6520395_119e9ba\rev_base_32a0973\core\src\main\java\org\elasticsearch\discovery\zen\ping\ZenPingService.java,C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_6520395_119e9ba\rev_right_119e9ba\core\src\main\java\org\elasticsearch\discovery\zen\ping\ZenPingService.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
zenPingsBuilder
=======
new ArrayList<>(zenPings)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Inject public ZenPingService(Settings settings, Set<ZenPing> zenPings, TransportService transportService, ClusterName clusterName, NetworkService networkService, Version version, ElectMasterService electMasterService, @Nullable Set<UnicastHostsProvider> unicastHostsProviders) {
    super(settings);
    List<ZenPing> zenPingsBuilder = new ArrayList<>();
    this.zenPings = Collections.unmodifiableList(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_6520395_119e9ba\rev_left_6520395\core\src\main\java\org\elasticsearch\discovery\zen\ping\ZenPingService.java
zenPingsBuilder
=======
new ArrayList<>(zenPings)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_6520395_119e9ba\rev_right_119e9ba\core\src\main\java\org\elasticsearch\discovery\zen\ping\ZenPingService.java
);
    zenPingsBuilder.add(new UnicastZenPing(settings, threadPool, transportService, clusterName, version, electMasterService, unicastHostsProviders));
    this.zenPings = Collections.unmodifiableList(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_6520395_119e9ba\rev_left_6520395\core\src\main\java\org\elasticsearch\discovery\zen\ping\ZenPingService.java
zenPingsBuilder
=======
new ArrayList<>(zenPings)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_6520395_119e9ba\rev_right_119e9ba\core\src\main\java\org\elasticsearch\discovery\zen\ping\ZenPingService.java
);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_left_a0dd0c9\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_base_b4da5f5\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_right_8dc0283\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
try {
        synchronized(this) {
          for (; true; ) {
            List<String> children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
            if (!children.contains(nodeName)) {
              log.error("Sequential path not found: " + path);
              returnLease(lease);
              return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
            }
            if (children.size() <= maxLeases) {
              break ;
            }
            if (hasWait) {
              long thisWaitMs = getThisWaitMs(startMs, waitMs);
              if (thisWaitMs <= 0) {
                returnLease(lease);
                return InternalAcquireResult.RETURN_NULL;
              }
              wait(thisWaitMs);
            }
            else {
              wait();
            }
          }
        }
      }
      finally {
        client.removeWatchers();
      }
=======
if (debugAcquireLatch != null) {
        debugAcquireLatch.await();
      }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private InternalAcquireResult internalAcquire1Lease(ImmutableList.Builder<Lease> builder, long startMs, boolean hasWait, long waitMs) throws Exception {
    if (client.getState() != CuratorFrameworkState.STARTED) {
      return InternalAcquireResult.RETURN_NULL;
    }
    if (hasWait) {
      long thisWaitMs = getThisWaitMs(startMs, waitMs);
      if (!lock.acquire(thisWaitMs, TimeUnit.MILLISECONDS)) {
        return InternalAcquireResult.RETURN_NULL;
      }
    }
    else {
      lock.acquire();
    }
    Lease lease = null;
    try {
      PathAndBytesable<String> createBuilder = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL);
      String path = (nodeData != null) ? createBuilder.forPath(ZKPaths.makePath(leasesPath, LEASE_BASE_NAME), nodeData) : createBuilder.forPath(ZKPaths.makePath(leasesPath, LEASE_BASE_NAME));
      String nodeName = ZKPaths.getNodeFromPath(path);
      lease = makeLease(path);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_left_a0dd0c9\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java
try {
        synchronized(this) {
          for (; true; ) {
            List<String> children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
            if (!children.contains(nodeName)) {
              log.error("Sequential path not found: " + path);
              returnLease(lease);
              return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
            }
            if (children.size() <= maxLeases) {
              break ;
            }
            if (hasWait) {
              long thisWaitMs = getThisWaitMs(startMs, waitMs);
              if (thisWaitMs <= 0) {
                returnLease(lease);
                return InternalAcquireResult.RETURN_NULL;
              }
              wait(thisWaitMs);
            }
            else {
              wait();
            }
          }
        }
      }
      finally {
        client.removeWatchers();
      }
=======
if (debugAcquireLatch != null) {
        debugAcquireLatch.await();
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_right_8dc0283\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_left_a0dd0c9\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java
try {
        synchronized(this) {
          for (; true; ) {
            List<String> children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
            if (!children.contains(nodeName)) {
              log.error("Sequential path not found: " + path);
              returnLease(lease);
              return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
            }
            if (children.size() <= maxLeases) {
              break ;
            }
            if (hasWait) {
              long thisWaitMs = getThisWaitMs(startMs, waitMs);
              if (thisWaitMs <= 0) {
                returnLease(lease);
                return InternalAcquireResult.RETURN_NULL;
              }
              wait(thisWaitMs);
            }
            else {
              wait();
            }
          }
        }
      }
      finally {
        client.removeWatchers();
      }
=======
synchronized(this) {
        for (; true; ) {
          List<String> children;
          try {
            children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
          }
          catch (Exception e) {
            if (debugFailedGetChildrenLatch != null) {
              debugFailedGetChildrenLatch.countDown();
            }
            returnLease(lease);
            throw e;
          }
          if (!children.contains(nodeName)) {
            log.error("Sequential path not found: " + path);
            returnLease(lease);
            return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
          }
          if (children.size() <= maxLeases) {
            break ;
          }
          if (hasWait) {
            long thisWaitMs = getThisWaitMs(startMs, waitMs);
            if (thisWaitMs <= 0) {
              returnLease(lease);
              return InternalAcquireResult.RETURN_NULL;
            }
            wait(thisWaitMs);
          }
          else {
            wait();
          }
        }
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_right_8dc0283\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java

    }
    builder.add(Preconditions.checkNotNull(lease));
    return InternalAcquireResult.CONTINUE;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_left_a0dd0c9\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_base_b4da5f5\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_right_8dc0283\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
try {
        synchronized(this) {
          for (; true; ) {
            List<String> children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
            if (!children.contains(nodeName)) {
              log.error("Sequential path not found: " + path);
              returnLease(lease);
              return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
            }
            if (children.size() <= maxLeases) {
              break ;
            }
            if (hasWait) {
              long thisWaitMs = getThisWaitMs(startMs, waitMs);
              if (thisWaitMs <= 0) {
                returnLease(lease);
                return InternalAcquireResult.RETURN_NULL;
              }
              wait(thisWaitMs);
            }
            else {
              wait();
            }
          }
        }
      }
      finally {
        client.removeWatchers();
      }
=======
synchronized(this) {
        for (; true; ) {
          List<String> children;
          try {
            children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
          }
          catch (Exception e) {
            if (debugFailedGetChildrenLatch != null) {
              debugFailedGetChildrenLatch.countDown();
            }
            returnLease(lease);
            throw e;
          }
          if (!children.contains(nodeName)) {
            log.error("Sequential path not found: " + path);
            returnLease(lease);
            return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
          }
          if (children.size() <= maxLeases) {
            break ;
          }
          if (hasWait) {
            long thisWaitMs = getThisWaitMs(startMs, waitMs);
            if (thisWaitMs <= 0) {
              returnLease(lease);
              return InternalAcquireResult.RETURN_NULL;
            }
            wait(thisWaitMs);
          }
          else {
            wait();
          }
        }
      }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private InternalAcquireResult internalAcquire1Lease(ImmutableList.Builder<Lease> builder, long startMs, boolean hasWait, long waitMs) throws Exception {
    if (client.getState() != CuratorFrameworkState.STARTED) {
      return InternalAcquireResult.RETURN_NULL;
    }
    if (hasWait) {
      long thisWaitMs = getThisWaitMs(startMs, waitMs);
      if (!lock.acquire(thisWaitMs, TimeUnit.MILLISECONDS)) {
        return InternalAcquireResult.RETURN_NULL;
      }
    }
    else {
      lock.acquire();
    }
    Lease lease = null;
    try {
      PathAndBytesable<String> createBuilder = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL);
      String path = (nodeData != null) ? createBuilder.forPath(ZKPaths.makePath(leasesPath, LEASE_BASE_NAME), nodeData) : createBuilder.forPath(ZKPaths.makePath(leasesPath, LEASE_BASE_NAME));
      String nodeName = ZKPaths.getNodeFromPath(path);
      lease = makeLease(path);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_left_a0dd0c9\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java
try {
        synchronized(this) {
          for (; true; ) {
            List<String> children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
            if (!children.contains(nodeName)) {
              log.error("Sequential path not found: " + path);
              returnLease(lease);
              return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
            }
            if (children.size() <= maxLeases) {
              break ;
            }
            if (hasWait) {
              long thisWaitMs = getThisWaitMs(startMs, waitMs);
              if (thisWaitMs <= 0) {
                returnLease(lease);
                return InternalAcquireResult.RETURN_NULL;
              }
              wait(thisWaitMs);
            }
            else {
              wait();
            }
          }
        }
      }
      finally {
        client.removeWatchers();
      }
=======
if (debugAcquireLatch != null) {
        debugAcquireLatch.await();
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_right_8dc0283\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_left_a0dd0c9\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java
try {
        synchronized(this) {
          for (; true; ) {
            List<String> children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
            if (!children.contains(nodeName)) {
              log.error("Sequential path not found: " + path);
              returnLease(lease);
              return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
            }
            if (children.size() <= maxLeases) {
              break ;
            }
            if (hasWait) {
              long thisWaitMs = getThisWaitMs(startMs, waitMs);
              if (thisWaitMs <= 0) {
                returnLease(lease);
                return InternalAcquireResult.RETURN_NULL;
              }
              wait(thisWaitMs);
            }
            else {
              wait();
            }
          }
        }
      }
      finally {
        client.removeWatchers();
      }
=======
synchronized(this) {
        for (; true; ) {
          List<String> children;
          try {
            children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
          }
          catch (Exception e) {
            if (debugFailedGetChildrenLatch != null) {
              debugFailedGetChildrenLatch.countDown();
            }
            returnLease(lease);
            throw e;
          }
          if (!children.contains(nodeName)) {
            log.error("Sequential path not found: " + path);
            returnLease(lease);
            return InternalAcquireResult.RETRY_DUE_TO_MISSING_NODE;
          }
          if (children.size() <= maxLeases) {
            break ;
          }
          if (hasWait) {
            long thisWaitMs = getThisWaitMs(startMs, waitMs);
            if (thisWaitMs <= 0) {
              returnLease(lease);
              return InternalAcquireResult.RETURN_NULL;
            }
            wait(thisWaitMs);
          }
          else {
            wait();
          }
        }
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_a0dd0c9_8dc0283\rev_right_8dc0283\curator-recipes\src\main\java\org\apache\curator\framework\recipes\locks\InterProcessSemaphoreV2.java

    }
    builder.add(Preconditions.checkNotNull(lease));
    return InternalAcquireResult.CONTINUE;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_91ed291_ca19f8f\rev_left_91ed291\kundera-cassandra\src\main\java\com\impetus\client\cassandra\query\CassandraEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_91ed291_ca19f8f\rev_base_4950027\kundera-cassandra\src\main\java\com\impetus\client\cassandra\query\CassandraEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_91ed291_ca19f8f\rev_right_ca19f8f\kundera-cassandra\src\main\java\com\impetus\client\cassandra\query\CassandraEntityReader.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
ls = handleFindByRange(m, client, ls, conditions, isRowKeyQuery);
=======
if (MetadataUtils.useSecondryIndex(m.getPersistenceUnit())) {
        ls = ((PelopsClient)client).find(this.conditions, m, true, null);
      }
      else {
        ls = onAssociationUsingLucene(m, client, ls);
      }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public List<EnhanceEntity> populateRelation(EntityMetadata m, List<String> relationNames, boolean isParent, Client client) {
    List<EnhanceEntity> ls = null;
    boolean isRowKeyQuery = conditions.keySet().iterator().next();
    if (!isRowKeyQuery) {
      if (!isParent) {
        if (MetadataUtils.useSecondryIndex(m.getPersistenceUnit())) {
          ls = ((PelopsClient)client).find(m, relationNames, this.conditions.get(isRowKeyQuery));
        }
        else {
          Set<String> rSet = fetchDataFromLucene(client);
          try {
            ls = (List<EnhanceEntity>)((PelopsClient)client).find(m.getEntityClazz(), relationNames, true, m, rSet.toArray(new String[]{  } ));
          }
          catch (Exception e) {
            log.error("Error while executing handleAssociation for cassandra:" + e.getMessage());
            throw new QueryHandlerException(e.getMessage());
          }
        }
      }
      else {
        if (MetadataUtils.useSecondryIndex(m.getPersistenceUnit())) {
          ls = ((PelopsClient)client).find(this.conditions.get(isRowKeyQuery), m, true, null);
        }
        else {
          onAssociationUsingLucene(m, client, ls);
        }
      }
    }
    else {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_91ed291_ca19f8f\rev_left_91ed291\kundera-cassandra\src\main\java\com\impetus\client\cassandra\query\CassandraEntityReader.java
ls = handleFindByRange(m, client, ls, conditions, isRowKeyQuery);
=======
if (MetadataUtils.useSecondryIndex(m.getPersistenceUnit())) {
        ls = ((PelopsClient)client).find(this.conditions, m, true, null);
      }
      else {
        ls = onAssociationUsingLucene(m, client, ls);
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_91ed291_ca19f8f\rev_right_ca19f8f\kundera-cassandra\src\main\java\com\impetus\client\cassandra\query\CassandraEntityReader.java

    }
    return ls;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_8d2a2f8_c10f116\rev_left_8d2a2f8\core\src\main\java\org\elasticsearch\index\query\QueryFilterBuilder.java,C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_8d2a2f8_c10f116\rev_base_73d84e4\core\src\main\java\org\elasticsearch\index\query\QueryFilterBuilder.java,C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_8d2a2f8_c10f116\rev_right_c10f116\core\src\main\java\org\elasticsearch\index\query\QueryFilterBuilder.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
NAME
=======
QueryFilterParser.NAME
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {
    builder.field(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_8d2a2f8_c10f116\rev_left_8d2a2f8\core\src\main\java\org\elasticsearch\index\query\QueryFilterBuilder.java
NAME
=======
QueryFilterParser.NAME
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_8d2a2f8_c10f116\rev_right_c10f116\core\src\main\java\org\elasticsearch\index\query\QueryFilterBuilder.java
);
    queryBuilder.toXContent(builder, params);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_be2f153_adda148\rev_left_be2f153\client\src\main\java\com\metamx\druid\curator\announcement\Announcer.java,C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_be2f153_adda148\rev_base_fde874e\client\src\main\java\com\metamx\druid\curator\announcement\Announcer.java,C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_be2f153_adda148\rev_right_adda148\client\src\main\java\com\metamx\druid\curator\announcement\Announcer.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
final ZKPaths.PathAndNode pathAndNode = ZKPaths.getPathAndNode(path);
=======
synchronized(lock) {
      final ZKPaths.PathAndNode pathAndNode = ZKPaths.getPathAndNode(path);
      final String parentPath = pathAndNode.getPath();
      final String nodePath = pathAndNode.getNode();
      ConcurrentMap<String, byte[]> subPaths = announcements.get(parentPath);
      if (subPaths == null || subPaths.get(nodePath) == null) {
        announce(path, bytes);
        return ;
      }
      try {
        byte[] oldBytes = subPaths.get(nodePath);
        if (!Arrays.equals(oldBytes, bytes)) {
          subPaths.put(nodePath, bytes);
          updateAnnouncement(path, bytes);
        }
      }
      catch (Exception e) {
        throw Throwables.propagate(e);
      }
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void update(final String path, final byte[] bytes) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_be2f153_adda148\rev_left_be2f153\client\src\main\java\com\metamx\druid\curator\announcement\Announcer.java
final ZKPaths.PathAndNode pathAndNode = ZKPaths.getPathAndNode(path);
=======
synchronized(lock) {
      final ZKPaths.PathAndNode pathAndNode = ZKPaths.getPathAndNode(path);
      final String parentPath = pathAndNode.getPath();
      final String nodePath = pathAndNode.getNode();
      ConcurrentMap<String, byte[]> subPaths = announcements.get(parentPath);
      if (subPaths == null || subPaths.get(nodePath) == null) {
        announce(path, bytes);
        return ;
      }
      try {
        byte[] oldBytes = subPaths.get(nodePath);
        if (!Arrays.equals(oldBytes, bytes)) {
          subPaths.put(nodePath, bytes);
          updateAnnouncement(path, bytes);
        }
      }
      catch (Exception e) {
        throw Throwables.propagate(e);
      }
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_be2f153_adda148\rev_right_adda148\client\src\main\java\com\metamx\druid\curator\announcement\Announcer.java

    final String parentPath = pathAndNode.getPath();
    final String nodePath = pathAndNode.getNode();
    ConcurrentMap<String, byte[]> subPaths = announcements.get(parentPath);
    if (subPaths == null || subPaths.get(nodePath) == null) {
      announce(path, bytes);
      return ;
    }
    try {
      byte[] oldBytes = subPaths.get(nodePath);
      if (!Arrays.equals(oldBytes, bytes)) {
        subPaths.put(nodePath, bytes);
        updateAnnouncement(path, bytes);
      }
    }
    catch (Exception e) {
      throw Throwables.propagate(e);
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambrose\revisions\rev_8000215_8ad1e53\rev_left_8000215\pig\src\main\java\com\twitter\ambrose\service\DAGNode.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambrose\revisions\rev_8000215_8ad1e53\rev_base_bdb65ab\pig\src\main\java\com\twitter\ambrose\service\DAGNode.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambrose\revisions\rev_8000215_8ad1e53\rev_right_8ad1e53\pig\src\main\java\com\twitter\ambrose\service\DAGNode.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
DAGTransformer dagTransformer = new SugiyamaLayoutTransformer(true);
=======
for (DAGNode node : nodes) {
      node.setRuntime("pig");
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @SuppressWarnings(value = {"unchecked", }) public static void main(String[] args) throws IOException {
    String sourceFile = "pig/src/main/resources/web/data/large-dag.json";
    String json = JSONUtil.readFile(sourceFile);
    List<DAGNode> nodes = (List<DAGNode>)JSONUtil.readJson(json, new TypeReference<List<DAGNode>>() {
    });
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambrose\revisions\rev_8000215_8ad1e53\rev_left_8000215\pig\src\main\java\com\twitter\ambrose\service\DAGNode.java
DAGTransformer dagTransformer = new SugiyamaLayoutTransformer(true);
=======
for (DAGNode node : nodes) {
      node.setRuntime("pig");
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambrose\revisions\rev_8000215_8ad1e53\rev_right_8ad1e53\pig\src\main\java\com\twitter\ambrose\service\DAGNode.java

    dagTransformer.transform(nodes);
    JSONUtil.writeJson(sourceFile + "2", nodes);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\logback\revisions\rev_735d127_1911c7f\rev_left_735d127\logback-core\src\main\java\ch\qos\logback\core\ContextBase.java,C:\Users\user\Desktop\gjcc\amostra\projects\logback\revisions\rev_735d127_1911c7f\rev_base_10d4757\logback-core\src\main\java\ch\qos\logback\core\ContextBase.java,C:\Users\user\Desktop\gjcc\amostra\projects\logback\revisions\rev_735d127_1911c7f\rev_right_1911c7f\logback-core\src\main\java\ch\qos\logback\core\ContextBase.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
executorService = ExecutorServiceUtil.newExecutorService()
=======
executorService = newExecutorService()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public ExecutorService getExecutorService() {
    if (executorService == null) {
      synchronized(this) {
        if (executorService == null) {
          
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\logback\revisions\rev_735d127_1911c7f\rev_left_735d127\logback-core\src\main\java\ch\qos\logback\core\ContextBase.java
executorService = ExecutorServiceUtil.newExecutorService()
=======
executorService = newExecutorService()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\logback\revisions\rev_735d127_1911c7f\rev_right_1911c7f\logback-core\src\main\java\ch\qos\logback\core\ContextBase.java
;
        }
      }
    }
    return executorService;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_84557c9_5c6ec4a\rev_left_84557c9\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_84557c9_5c6ec4a\rev_base_1e02853\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_84557c9_5c6ec4a\rev_right_5c6ec4a\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
return isWrapperReq ? new EnhanceEntity(entity, thriftRow.getId(), relations) : entity;
=======
if (columns != null && (columns.size() == 1 ? columns.iterator().next() != null : true)) {
      for (Column c : thriftRow.getColumns()) {
        String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(c.getName());
        byte[] thriftColumnValue = c.getValue();
        if (null == thriftColumnValue) {
          continue ;
        }
        com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
        if (column != null) {
          try {
            PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
          }
          catch (PropertyAccessException pae) {
            log.warn(pae.getMessage());
          }
        }
        else {
          if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
            String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
            relations.put(thriftColumnName, value);
          }
        }
      }
    }
    else {
      for (SuperColumn c : thriftRow.getSuperColumns()) {
        for (Column cc : c.getColumns()) {
          String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(cc.getName());
          byte[] thriftColumnValue = cc.getValue();
          if (null == thriftColumnValue) {
            continue ;
          }
          com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
          if (column != null) {
            try {
              PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
            }
            catch (PropertyAccessException pae) {
              log.warn(pae.getMessage());
            }
          }
          else {
            if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
              String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
              relations.put(thriftColumnName, value);
            }
          }
        }
      }
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Object fromColumnThriftRow(Class<?> clazz, EntityMetadata m, ThriftRow thriftRow, List<String> relationNames, boolean isWrapperReq) throws Exception {
    Object entity = clazz.newInstance();
    Map<String, Object> relations = new HashMap<String, Object>();
    PropertyAccessorHelper.setId(entity, m, thriftRow.getId());
    for (Column c : thriftRow.getColumns()) {
      String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(c.getName());
      byte[] thriftColumnValue = c.getValue();
      if (null == thriftColumnValue) {
        continue ;
      }
      com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
      if (column != null) {
        try {
          PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
        }
        catch (PropertyAccessException pae) {
          log.warn(pae.getMessage());
        }
      }
      else {
        if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
          String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
          relations.put(thriftColumnName, value);
        }
      }
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_84557c9_5c6ec4a\rev_left_84557c9\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java
return isWrapperReq ? new EnhanceEntity(entity, thriftRow.getId(), relations) : entity;
=======
if (columns != null && (columns.size() == 1 ? columns.iterator().next() != null : true)) {
      for (Column c : thriftRow.getColumns()) {
        String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(c.getName());
        byte[] thriftColumnValue = c.getValue();
        if (null == thriftColumnValue) {
          continue ;
        }
        com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
        if (column != null) {
          try {
            PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
          }
          catch (PropertyAccessException pae) {
            log.warn(pae.getMessage());
          }
        }
        else {
          if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
            String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
            relations.put(thriftColumnName, value);
          }
        }
      }
    }
    else {
      for (SuperColumn c : thriftRow.getSuperColumns()) {
        for (Column cc : c.getColumns()) {
          String thriftColumnName = PropertyAccessorFactory.STRING.fromBytes(cc.getName());
          byte[] thriftColumnValue = cc.getValue();
          if (null == thriftColumnValue) {
            continue ;
          }
          com.impetus.kundera.metadata.model.Column column = m.getColumn(thriftColumnName);
          if (column != null) {
            try {
              PropertyAccessorHelper.set(entity, column.getField(), thriftColumnValue);
            }
            catch (PropertyAccessException pae) {
              log.warn(pae.getMessage());
            }
          }
          else {
            if (relationNames != null && !relationNames.isEmpty() && relationNames.contains(thriftColumnName)) {
              String value = PropertyAccessorFactory.STRING.fromBytes(thriftColumnValue);
              relations.put(thriftColumnName, value);
            }
          }
        }
      }
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_84557c9_5c6ec4a\rev_right_5c6ec4a\kundera-cassandra\src\main\java\com\impetus\client\cassandra\pelops\PelopsDataHandler.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_b60bbc2_8a6d818\rev_left_b60bbc2\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_b60bbc2_8a6d818\rev_base_19999da\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_b60bbc2_8a6d818\rev_right_8a6d818\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
dc = handleStaticParts(db, table, tbd, ti);
=======
if (work.getOutputs() != null) {
              DDLTask.addIfAbsentByName(new WriteEntity(partn, getWriteType(tbd, work.getLoadTableWork().getWriteType())), work.getOutputs());
            }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public int execute(DriverContext driverContext) {
    Utilities.LOG14535.info("Executing MoveWork " + System.identityHashCode(work) + " with " + work.getLoadFileWork() + "; " + work.getLoadTableWork() + "; " + work.getLoadMultiFilesWork());
    try {
      if (driverContext.getCtx().getExplainAnalyze() == AnalyzeState.RUNNING) {
        return 0;
      }
      Hive db = getHive();
      LoadFileDesc lfd = work.getLoadFileWork();
      if (lfd != null) {
        Path targetPath = lfd.getTargetDir();
        Path sourcePath = lfd.getSourcePath();
        Utilities.LOG14535.info("MoveTask moving LFD " + sourcePath + " to " + targetPath);
        moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
      }
      LoadMultiFilesDesc lmfd = work.getLoadMultiFilesWork();
      if (lmfd != null) {
        boolean isDfsDir = lmfd.getIsDfsDir();
        int i = 0;
        while (i < lmfd.getSourceDirs().size()){
          Path srcPath = lmfd.getSourceDirs().get(i);
          Path destPath = lmfd.getTargetDirs().get(i);
          FileSystem fs = destPath.getFileSystem(conf);
          if (!fs.exists(destPath.getParent())) {
            fs.mkdirs(destPath.getParent());
          }
          Utilities.LOG14535.info("MoveTask moving LMFD " + srcPath + " to " + destPath);
          moveFile(srcPath, destPath, isDfsDir);
          i++;
        }
      }
      LoadTableDesc tbd = work.getLoadTableWork();
      if (tbd != null) {
        StringBuilder mesg = new StringBuilder("Loading data to table ").append(tbd.getTable().getTableName());
        if (tbd.getPartitionSpec().size() > 0) {
          mesg.append(" partition (");
          Map<String, String> partSpec = tbd.getPartitionSpec();
          for (String key : partSpec.keySet()) {
            mesg.append(key).append('=').append(partSpec.get(key)).append(", ");
          }
          mesg.setLength(mesg.length() - 2);
          mesg.append(')');
        }
        String mesg_detail = " from " + tbd.getSourcePath();
        Utilities.LOG14535.info("" + mesg.toString() + " " + mesg_detail);
        console.printInfo(mesg.toString(), mesg_detail);
        Table table = db.getTable(tbd.getTable().getTableName());
        checkFileFormats(db, tbd, table);
        boolean isAcid = work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID;
        if (tbd.isMmTable() && isAcid) {
          throw new HiveException("ACID and MM are not supported");
        }
        DataContainer dc = null;
        if (tbd.getPartitionSpec().size() == 0) {
          dc = new DataContainer(table.getTTable());
          Utilities.LOG14535.info("loadTable called from " + tbd.getSourcePath() + " into " + tbd.getTable().getTableName());
          if (tbd.isMmTable() && !tbd.isCommitMmWrite()) {
            throw new HiveException("Only single-partition LoadTableDesc can skip commiting write ID");
          }
          db.loadTable(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getReplace(), work.isSrcLocal(), isSkewedStoredAsDirs(tbd), isAcid, hasFollowingStatsTask(), tbd.getMmWriteId());
          if (work.getOutputs() != null) {
            DDLTask.addIfAbsentByName(new WriteEntity(table, getWriteType(tbd, work.getLoadTableWork().getWriteType())), work.getOutputs());
          }
        }
        else {
          LOG.info("Partition is: " + tbd.getPartitionSpec().toString());
          TaskInformation ti = new TaskInformation(this, tbd.getSourcePath().toUri().toString());
          inferTaskInformation(ti);
          DynamicPartitionCtx dpCtx = tbd.getDPCtx();
          if (dpCtx != null && dpCtx.getNumDPCols() > 0) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_b60bbc2_8a6d818\rev_left_b60bbc2\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
dc = handleDynParts(db, table, tbd, ti, dpCtx);
=======
for (Map.Entry<Map<String, String>, Partition> entry : dp.entrySet()) {
              Partition partn = entry.getValue();
              if (bucketCols != null || sortCols != null) {
                updatePartitionBucketSortColumns(db, table, partn, bucketCols, numBuckets, sortCols);
              }
              WriteEntity enty = new WriteEntity(partn, getWriteType(tbd, work.getLoadTableWork().getWriteType()));
              if (work.getOutputs() != null) {
                DDLTask.addIfAbsentByName(enty, work.getOutputs());
              }
              if (queryPlan.getOutputs() == null) {
                queryPlan.setOutputs(new LinkedHashSet<WriteEntity>());
              }
              queryPlan.getOutputs().add(enty);
              dc = new DataContainer(table.getTTable(), partn.getTPartition());
              if (SessionState.get() != null && work.getLoadTableWork().getWriteType() != AcidUtils.Operation.DELETE && work.getLoadTableWork().getWriteType() != AcidUtils.Operation.UPDATE) {
                SessionState.get().getLineageState().setLineage(tbd.getSourcePath(), dc, table.getCols());
              }
              LOG.info("\tLoading partition " + entry.getKey());
            }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_b60bbc2_8a6d818\rev_right_8a6d818\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

            dc = handleDynParts(db, table, tbd, ti, dpCtx);
          }
          else {
            dc = handleStaticParts(db, table, tbd, ti);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_b60bbc2_8a6d818\rev_left_b60bbc2\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
dc = handleStaticParts(db, table, tbd, ti);
=======
if (work.getOutputs() != null) {
              DDLTask.addIfAbsentByName(new WriteEntity(partn, getWriteType(tbd, work.getLoadTableWork().getWriteType())), work.getOutputs());
            }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_b60bbc2_8a6d818\rev_right_8a6d818\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

          }
        }
        if (SessionState.get() != null && dc != null) {
          List<FieldSchema> tableCols = null;
          switch (work.getLoadTableWork().getWriteType()){
            case DELETE:
            case UPDATE:
            tableCols = new ArrayList<FieldSchema>();
            break ;
            default:
            tableCols = table.getCols();
            break ;
          }
          SessionState.get().getLineageState().setLineage(tbd.getSourcePath(), dc, tableCols);
        }
        releaseLocks(tbd);
      }
      return 0;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_left_393837b\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java,C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_base_9379c6c\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java,C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_right_d4ffedd\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
timeConverter = TimeConverter.getInstance(parameterType, locale)
=======
result[n] = converter.fromString(a.getVal())
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private Object[] transformedArgs(List<ParameterType> parameterTypes, Step step, LocalizedXStreams.LocalizedXStream xStream, Locale locale) {
    if (xStream == null) {
      throw new NullPointerException("xStream");
    }
    int argumentCount = getArguments().size();
    if (step.getDocString() != null) 
      argumentCount++;
    if (step.getRows() != null) 
      argumentCount++;
    if (parameterTypes != null) {
      if (parameterTypes.size() != argumentCount) {
        List<Argument> arguments = createArgumentsForErrorMessage(step);
        throw new CucumberException("Arity mismatch. Declared parameters: " + parameterTypes + ". Matched arguments: " + arguments);
      }
    }
    else {
      parameterTypes = Utils.listOf(argumentCount, new ParameterType(String.class, null));
    }
    Object[] result = new Object[argumentCount];
    ConverterLookup converterLookup = xStream.getConverterLookup();
    int n = 0;
    for (Argument a : getArguments()) {
      TimeConverter timeConverter = null;
      if (parameterTypes != null) {
        SingleValueConverter converter;
        ParameterType parameterType = parameterTypes.get(n);
        if (parameterType.getDateFormat() != null) {
          converter = new DateConverter(parameterType.getDateFormat(), locale);
        }
        else {
          converter = (SingleValueConverter)converterLookup.lookupConverterForType(parameterType.getParameterClass());
        }
        
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_left_393837b\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java
timeConverter = TimeConverter.getInstance(parameterType, locale)
=======
result[n] = converter.fromString(a.getVal())
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_right_d4ffedd\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java
;
        timeConverter.setOnlyFormat(parameterType.getDateFormat(), locale);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_left_393837b\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java
converter = timeConverter;
=======
result[n] = converter.fromString(a.getVal());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_right_d4ffedd\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java

      }
      ParameterType parameterType = parameterTypes.get(n);
      if (parameterType.getDateFormat() != null) {
        SingleValueConverter converter;
        ParameterType parameterType = parameterTypes.get(n);
        if (parameterType.getDateFormat() != null) {
          converter = new DateConverter(parameterType.getDateFormat(), locale);
        }
        else {
          converter = (SingleValueConverter)converterLookup.lookupConverterForType(parameterType.getParameterClass());
        }
      }
      else {
        converter = (SingleValueConverter)converterLookup.lookupConverterForType(parameterType.getParameterClass());
      }
      try {
        result[n] = converter.fromString(a.getVal());
      }
      finally {
        if (timeConverter != null) {
          timeConverter.removeOnlyFormat();
        }
      }
      n++;
    }
    if (step.getRows() != null) {
      ParameterType parameterType = parameterTypes.get(n);
      xStream.setDateFormat(parameterType.getDateFormat());
      try {
        result[n] = tableArgument(step, n, xStream, parameterType.getDateFormat());
      }
      finally {
        xStream.unsetDateFormat();
      }
    }
    else 
      if (step.getDocString() != null) {
        result[n] = step.getDocString().getValue();
      }
    return result;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_left_393837b\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java,C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_base_9379c6c\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java,C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_right_d4ffedd\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java
CONCLUSAO: FP. MUDANÇAS COMPLEMENTARES.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
converter = timeConverter;
=======
result[n] = converter.fromString(a.getVal());
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private Object[] transformedArgs(List<ParameterType> parameterTypes, Step step, LocalizedXStreams.LocalizedXStream xStream, Locale locale) {
    if (xStream == null) {
      throw new NullPointerException("xStream");
    }
    int argumentCount = getArguments().size();
    if (step.getDocString() != null) 
      argumentCount++;
    if (step.getRows() != null) 
      argumentCount++;
    if (parameterTypes != null) {
      if (parameterTypes.size() != argumentCount) {
        List<Argument> arguments = createArgumentsForErrorMessage(step);
        throw new CucumberException("Arity mismatch. Declared parameters: " + parameterTypes + ". Matched arguments: " + arguments);
      }
    }
    else {
      parameterTypes = Utils.listOf(argumentCount, new ParameterType(String.class, null));
    }
    Object[] result = new Object[argumentCount];
    ConverterLookup converterLookup = xStream.getConverterLookup();
    int n = 0;
    for (Argument a : getArguments()) {
      TimeConverter timeConverter = null;
      if (parameterTypes != null) {
        SingleValueConverter converter;
        ParameterType parameterType = parameterTypes.get(n);
        if (parameterType.getDateFormat() != null) {
          converter = new DateConverter(parameterType.getDateFormat(), locale);
        }
        else {
          converter = (SingleValueConverter)converterLookup.lookupConverterForType(parameterType.getParameterClass());
        }
        
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_left_393837b\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java
timeConverter = TimeConverter.getInstance(parameterType, locale)
=======
result[n] = converter.fromString(a.getVal())
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_right_d4ffedd\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java
;
        timeConverter.setOnlyFormat(parameterType.getDateFormat(), locale);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_left_393837b\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java
converter = timeConverter;
=======
result[n] = converter.fromString(a.getVal());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\cucumber-jvm\revisions\rev_393837b_d4ffedd\rev_right_d4ffedd\core\src\main\java\cucumber\runtime\StepDefinitionMatch.java

      }
      ParameterType parameterType = parameterTypes.get(n);
      if (parameterType.getDateFormat() != null) {
        SingleValueConverter converter;
        ParameterType parameterType = parameterTypes.get(n);
        if (parameterType.getDateFormat() != null) {
          converter = new DateConverter(parameterType.getDateFormat(), locale);
        }
        else {
          converter = (SingleValueConverter)converterLookup.lookupConverterForType(parameterType.getParameterClass());
        }
      }
      else {
        converter = (SingleValueConverter)converterLookup.lookupConverterForType(parameterType.getParameterClass());
      }
      try {
        result[n] = converter.fromString(a.getVal());
      }
      finally {
        if (timeConverter != null) {
          timeConverter.removeOnlyFormat();
        }
      }
      n++;
    }
    if (step.getRows() != null) {
      ParameterType parameterType = parameterTypes.get(n);
      xStream.setDateFormat(parameterType.getDateFormat());
      try {
        result[n] = tableArgument(step, n, xStream, parameterType.getDateFormat());
      }
      finally {
        xStream.unsetDateFormat();
      }
    }
    else 
      if (step.getDocString() != null) {
        result[n] = step.getDocString().getValue();
      }
    return result;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_base_1977d7f\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
CONCLUSAO: FP. DEVS EDITAM/ADICIONAM COMANDOS QUE NÃO APARENTAM TER RELAÇÃO ENTRE SI
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
cacheKeys.add(key)
=======
MapredContext.init(true, new JobConf(jconf))
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override void init(final JobConf jconf, ProcessorContext processorContext, MRTaskReporter mrReporter, Map<String, LogicalInput> inputs, Map<String, LogicalOutput> outputs) throws Exception {
    perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.TEZ_INIT_OPERATORS);
    super.init(jconf, processorContext, mrReporter, inputs, outputs);
    String queryId = HiveConf.getVar(jconf, HiveConf.ConfVars.HIVEQUERYID);
    String key = queryId + processorContext.getTaskVertexName() + MAP_PLAN_KEY;
    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
cacheKeys.add(key)
=======
MapredContext.init(true, new JobConf(jconf))
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
mapWork = (MapWork)cache.retrieve(key, new Callable<Object>() {
        public Object call() {
          return Utilities.getMapWork(jconf);
        }
    });
=======
((TezContext)MapredContext.get()).setInputs(inputs);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java

    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
Utilities.setMapWork(jconf, mapWork)
=======
((TezContext)MapredContext.get()).setTezProcessorContext(processorContext)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
    String prefixes = jconf.get(DagUtils.TEZ_MERGE_WORK_FILE_PREFIXES);
    if (prefixes != null) {
      mergeWorkList = new ArrayList<MapWork>();
      for (final String prefix : prefixes.split(",")) {
        if (prefix == null || prefix.isEmpty()) {
          continue ;
        }
        key = queryId + processorContext.getTaskVertexName() + prefix;
        cacheKeys.add(key);
        mergeWorkList.add((MapWork)cache.retrieve(key, new Callable<Object>() {
            public Object call() {
              return Utilities.getMergeWork(jconf, prefix);
            }
        }));
      }
    }
    legacyMRInput = getMRInput(inputs);
    if (legacyMRInput != null) {
      Configuration updatedConf = legacyMRInput.getConfigUpdates();
      if (updatedConf != null) {
        for (Entry<String, String> entry : updatedConf) {
          jconf.set(entry.getKey(), entry.getValue());
        }
      }
    }
    createOutputMap();
    for (Entry<String, LogicalOutput> outputEntry : outputs.entrySet()) {
      l4j.debug("Starting Output: " + outputEntry.getKey());
      outputEntry.getValue().start();
      ((TezKVOutputCollector)outMap.get(outputEntry.getKey())).initialize();
    }
    try {
      if (mapWork.getVectorMode()) {
        mapOp = new VectorMapOperator();
      }
      else {
        mapOp = new MapOperator();
      }
      mapOp.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
clearConnectedOperators()
=======
setExecContext(execContext)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
      if (mergeWorkList != null) {
        MapOperator mergeMapOp = null;
        for (MapWork mergeMapWork : mergeWorkList) {
          if (mergeMapWork.getVectorMode()) {
            mergeMapOp = new VectorMapOperator();
          }
          else {
            mergeMapOp = new MapOperator();
          }
          mergeMapOpList.add(mergeMapOp);
          if (mergeMapOp != null) {
            mergeMapOp.setConf(mergeMapWork);
            l4j.info("Input name is " + mergeMapWork.getName());
            jconf.set(Utilities.INPUT_NAME, mergeMapWork.getName());
            mergeMapOp.setChildren(jconf);
            DummyStoreOperator dummyOp = getJoinParentOp(mergeMapOp);
            mapOp.setConnectedOperators(mergeMapWork.getTag(), dummyOp);
            mergeMapOp.setExecContext(new ExecMapperContext(jconf));
            mergeMapOp.initializeLocalWork(jconf);
          }
        }
      }
      mapOp.setConf(mapWork);
      l4j.info("Main input name is " + mapWork.getName());
      jconf.set(Utilities.INPUT_NAME, mapWork.getName());
      mapOp.setChildren(jconf);
      l4j.info(mapOp.dump(0));
      MapredContext.init(true, new JobConf(jconf));
      ((TezContext)MapredContext.get()).setInputs(inputs);
      ((TezContext)MapredContext.get()).setTezProcessorContext(processorContext);
      mapOp.setExecContext(execContext);
      mapOp.initializeLocalWork(jconf);
      initializeMapRecordSources();
      mapOp.initialize(jconf, null);
      if ((mergeMapOpList != null) && mergeMapOpList.isEmpty() == false) {
        for (MapOperator mergeMapOp : mergeMapOpList) {
          jconf.set(Utilities.INPUT_NAME, mergeMapOp.getConf().getName());
          mergeMapOp.initialize(jconf, null);
        }
      }
      List<HashTableDummyOperator> dummyOps = mapWork.getDummyOps();
      jconf.set(Utilities.INPUT_NAME, mapWork.getName());
      if (dummyOps != null) {
        for (Operator<? extends OperatorDesc> dummyOp : dummyOps) {
          dummyOp.setExecContext(execContext);
          dummyOp.initialize(jconf, null);
        }
      }
      OperatorUtils.setChildrenCollector(mapOp.getChildOperators(), outMap);
      mapOp.setReporter(reporter);
      MapredContext.get().setReporter(reporter);
    }
    perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.TEZ_INIT_OPERATORS);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_base_1977d7f\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
mapWork = (MapWork)cache.retrieve(key, new Callable<Object>() {
        public Object call() {
          return Utilities.getMapWork(jconf);
        }
    });
=======
((TezContext)MapredContext.get()).setInputs(inputs);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override void init(final JobConf jconf, ProcessorContext processorContext, MRTaskReporter mrReporter, Map<String, LogicalInput> inputs, Map<String, LogicalOutput> outputs) throws Exception {
    perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.TEZ_INIT_OPERATORS);
    super.init(jconf, processorContext, mrReporter, inputs, outputs);
    String queryId = HiveConf.getVar(jconf, HiveConf.ConfVars.HIVEQUERYID);
    String key = queryId + processorContext.getTaskVertexName() + MAP_PLAN_KEY;
    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
cacheKeys.add(key)
=======
MapredContext.init(true, new JobConf(jconf))
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
mapWork = (MapWork)cache.retrieve(key, new Callable<Object>() {
        public Object call() {
          return Utilities.getMapWork(jconf);
        }
    });
=======
((TezContext)MapredContext.get()).setInputs(inputs);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java

    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
Utilities.setMapWork(jconf, mapWork)
=======
((TezContext)MapredContext.get()).setTezProcessorContext(processorContext)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
    String prefixes = jconf.get(DagUtils.TEZ_MERGE_WORK_FILE_PREFIXES);
    if (prefixes != null) {
      mergeWorkList = new ArrayList<MapWork>();
      for (final String prefix : prefixes.split(",")) {
        if (prefix == null || prefix.isEmpty()) {
          continue ;
        }
        key = queryId + processorContext.getTaskVertexName() + prefix;
        cacheKeys.add(key);
        mergeWorkList.add((MapWork)cache.retrieve(key, new Callable<Object>() {
            public Object call() {
              return Utilities.getMergeWork(jconf, prefix);
            }
        }));
      }
    }
    legacyMRInput = getMRInput(inputs);
    if (legacyMRInput != null) {
      Configuration updatedConf = legacyMRInput.getConfigUpdates();
      if (updatedConf != null) {
        for (Entry<String, String> entry : updatedConf) {
          jconf.set(entry.getKey(), entry.getValue());
        }
      }
    }
    createOutputMap();
    for (Entry<String, LogicalOutput> outputEntry : outputs.entrySet()) {
      l4j.debug("Starting Output: " + outputEntry.getKey());
      outputEntry.getValue().start();
      ((TezKVOutputCollector)outMap.get(outputEntry.getKey())).initialize();
    }
    try {
      if (mapWork.getVectorMode()) {
        mapOp = new VectorMapOperator();
      }
      else {
        mapOp = new MapOperator();
      }
      mapOp.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
clearConnectedOperators()
=======
setExecContext(execContext)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
      if (mergeWorkList != null) {
        MapOperator mergeMapOp = null;
        for (MapWork mergeMapWork : mergeWorkList) {
          if (mergeMapWork.getVectorMode()) {
            mergeMapOp = new VectorMapOperator();
          }
          else {
            mergeMapOp = new MapOperator();
          }
          mergeMapOpList.add(mergeMapOp);
          if (mergeMapOp != null) {
            mergeMapOp.setConf(mergeMapWork);
            l4j.info("Input name is " + mergeMapWork.getName());
            jconf.set(Utilities.INPUT_NAME, mergeMapWork.getName());
            mergeMapOp.setChildren(jconf);
            DummyStoreOperator dummyOp = getJoinParentOp(mergeMapOp);
            mapOp.setConnectedOperators(mergeMapWork.getTag(), dummyOp);
            mergeMapOp.setExecContext(new ExecMapperContext(jconf));
            mergeMapOp.initializeLocalWork(jconf);
          }
        }
      }
      mapOp.setConf(mapWork);
      l4j.info("Main input name is " + mapWork.getName());
      jconf.set(Utilities.INPUT_NAME, mapWork.getName());
      mapOp.setChildren(jconf);
      l4j.info(mapOp.dump(0));
      MapredContext.init(true, new JobConf(jconf));
      ((TezContext)MapredContext.get()).setInputs(inputs);
      ((TezContext)MapredContext.get()).setTezProcessorContext(processorContext);
      mapOp.setExecContext(execContext);
      mapOp.initializeLocalWork(jconf);
      initializeMapRecordSources();
      mapOp.initialize(jconf, null);
      if ((mergeMapOpList != null) && mergeMapOpList.isEmpty() == false) {
        for (MapOperator mergeMapOp : mergeMapOpList) {
          jconf.set(Utilities.INPUT_NAME, mergeMapOp.getConf().getName());
          mergeMapOp.initialize(jconf, null);
        }
      }
      List<HashTableDummyOperator> dummyOps = mapWork.getDummyOps();
      jconf.set(Utilities.INPUT_NAME, mapWork.getName());
      if (dummyOps != null) {
        for (Operator<? extends OperatorDesc> dummyOp : dummyOps) {
          dummyOp.setExecContext(execContext);
          dummyOp.initialize(jconf, null);
        }
      }
      OperatorUtils.setChildrenCollector(mapOp.getChildOperators(), outMap);
      mapOp.setReporter(reporter);
      MapredContext.get().setReporter(reporter);
    }
    perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.TEZ_INIT_OPERATORS);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_base_1977d7f\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Utilities.setMapWork(jconf, mapWork)
=======
((TezContext)MapredContext.get()).setTezProcessorContext(processorContext)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override void init(final JobConf jconf, ProcessorContext processorContext, MRTaskReporter mrReporter, Map<String, LogicalInput> inputs, Map<String, LogicalOutput> outputs) throws Exception {
    perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.TEZ_INIT_OPERATORS);
    super.init(jconf, processorContext, mrReporter, inputs, outputs);
    String queryId = HiveConf.getVar(jconf, HiveConf.ConfVars.HIVEQUERYID);
    String key = queryId + processorContext.getTaskVertexName() + MAP_PLAN_KEY;
    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
cacheKeys.add(key)
=======
MapredContext.init(true, new JobConf(jconf))
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
mapWork = (MapWork)cache.retrieve(key, new Callable<Object>() {
        public Object call() {
          return Utilities.getMapWork(jconf);
        }
    });
=======
((TezContext)MapredContext.get()).setInputs(inputs);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java

    
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
Utilities.setMapWork(jconf, mapWork)
=======
((TezContext)MapredContext.get()).setTezProcessorContext(processorContext)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
    String prefixes = jconf.get(DagUtils.TEZ_MERGE_WORK_FILE_PREFIXES);
    if (prefixes != null) {
      mergeWorkList = new ArrayList<MapWork>();
      for (final String prefix : prefixes.split(",")) {
        if (prefix == null || prefix.isEmpty()) {
          continue ;
        }
        key = queryId + processorContext.getTaskVertexName() + prefix;
        cacheKeys.add(key);
        mergeWorkList.add((MapWork)cache.retrieve(key, new Callable<Object>() {
            public Object call() {
              return Utilities.getMergeWork(jconf, prefix);
            }
        }));
      }
    }
    legacyMRInput = getMRInput(inputs);
    if (legacyMRInput != null) {
      Configuration updatedConf = legacyMRInput.getConfigUpdates();
      if (updatedConf != null) {
        for (Entry<String, String> entry : updatedConf) {
          jconf.set(entry.getKey(), entry.getValue());
        }
      }
    }
    createOutputMap();
    for (Entry<String, LogicalOutput> outputEntry : outputs.entrySet()) {
      l4j.debug("Starting Output: " + outputEntry.getKey());
      outputEntry.getValue().start();
      ((TezKVOutputCollector)outMap.get(outputEntry.getKey())).initialize();
    }
    try {
      if (mapWork.getVectorMode()) {
        mapOp = new VectorMapOperator();
      }
      else {
        mapOp = new MapOperator();
      }
      mapOp.
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_left_07253e8\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
clearConnectedOperators()
=======
setExecContext(execContext)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_07253e8_5f7ea30\rev_right_5f7ea30\ql\src\java\org\apache\hadoop\hive\ql\exec\tez\MapRecordProcessor.java
;
      if (mergeWorkList != null) {
        MapOperator mergeMapOp = null;
        for (MapWork mergeMapWork : mergeWorkList) {
          if (mergeMapWork.getVectorMode()) {
            mergeMapOp = new VectorMapOperator();
          }
          else {
            mergeMapOp = new MapOperator();
          }
          mergeMapOpList.add(mergeMapOp);
          if (mergeMapOp != null) {
            mergeMapOp.setConf(mergeMapWork);
            l4j.info("Input name is " + mergeMapWork.getName());
            jconf.set(Utilities.INPUT_NAME, mergeMapWork.getName());
            mergeMapOp.setChildren(jconf);
            DummyStoreOperator dummyOp = getJoinParentOp(mergeMapOp);
            mapOp.setConnectedOperators(mergeMapWork.getTag(), dummyOp);
            mergeMapOp.setExecContext(new ExecMapperContext(jconf));
            mergeMapOp.initializeLocalWork(jconf);
          }
        }
      }
      mapOp.setConf(mapWork);
      l4j.info("Main input name is " + mapWork.getName());
      jconf.set(Utilities.INPUT_NAME, mapWork.getName());
      mapOp.setChildren(jconf);
      l4j.info(mapOp.dump(0));
      MapredContext.init(true, new JobConf(jconf));
      ((TezContext)MapredContext.get()).setInputs(inputs);
      ((TezContext)MapredContext.get()).setTezProcessorContext(processorContext);
      mapOp.setExecContext(execContext);
      mapOp.initializeLocalWork(jconf);
      initializeMapRecordSources();
      mapOp.initialize(jconf, null);
      if ((mergeMapOpList != null) && mergeMapOpList.isEmpty() == false) {
        for (MapOperator mergeMapOp : mergeMapOpList) {
          jconf.set(Utilities.INPUT_NAME, mergeMapOp.getConf().getName());
          mergeMapOp.initialize(jconf, null);
        }
      }
      List<HashTableDummyOperator> dummyOps = mapWork.getDummyOps();
      jconf.set(Utilities.INPUT_NAME, mapWork.getName());
      if (dummyOps != null) {
        for (Operator<? extends OperatorDesc> dummyOp : dummyOps) {
          dummyOp.setExecContext(execContext);
          dummyOp.initialize(jconf, null);
        }
      }
      OperatorUtils.setChildrenCollector(mapOp.getChildOperators(), outMap);
      mapOp.setReporter(reporter);
      MapredContext.get().setReporter(reporter);
    }
    perfLogger.PerfLogEnd(CLASS_NAME, PerfLogger.TEZ_INIT_OPERATORS);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_14c9482_c254557\rev_left_14c9482\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_14c9482_c254557\rev_base_d376157\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_14c9482_c254557\rev_right_c254557\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
dc = handleStaticParts(db, table, tbd, ti);
=======
db.loadPartition(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getPartitionSpec(), tbd.getLoadFileType(), tbd.getInheritTableSpecs(), isSkewedStoredAsDirs(tbd), work.isSrcLocal(), work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID, hasFollowingStatsTask());
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public int execute(DriverContext driverContext) {
    if (Utilities.FILE_OP_LOGGER.isTraceEnabled()) {
      Utilities.FILE_OP_LOGGER.trace("Executing MoveWork " + System.identityHashCode(work) + " with " + work.getLoadFileWork() + "; " + work.getLoadTableWork() + "; " + work.getLoadMultiFilesWork());
    }
    try {
      if (driverContext.getCtx().getExplainAnalyze() == AnalyzeState.RUNNING) {
        return 0;
      }
      Hive db = getHive();
      LoadFileDesc lfd = work.getLoadFileWork();
      if (lfd != null) {
        Path targetPath = lfd.getTargetDir();
        Path sourcePath = lfd.getSourcePath();
        if (targetPath.equals(sourcePath)) {
          Utilities.FILE_OP_LOGGER.debug("MoveTask not moving " + sourcePath);
        }
        else {
          Utilities.FILE_OP_LOGGER.debug("MoveTask moving " + sourcePath + " to " + targetPath);
          if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
            assert lfd.getIsDfsDir();
            FileSystem srcFs = sourcePath.getFileSystem(conf);
            List<Path> newFiles = new ArrayList<>();
            Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
          }
          else {
            moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
          }
        }
      }
      LoadMultiFilesDesc lmfd = work.getLoadMultiFilesWork();
      if (lmfd != null) {
        boolean isDfsDir = lmfd.getIsDfsDir();
        List<String> targetPrefixes = lmfd.getTargetPrefixes();
        for (int i = 0; i < lmfd.getSourceDirs().size(); ++i) {
          Path srcPath = lmfd.getSourceDirs().get(i);
          Path destPath = lmfd.getTargetDirs().get(i);
          String filePrefix = targetPrefixes == null ? null : targetPrefixes.get(i);
          FileSystem destFs = destPath.getFileSystem(conf);
          if (filePrefix == null) {
            if (!destFs.exists(destPath.getParent())) {
              destFs.mkdirs(destPath.getParent());
            }
            Utilities.FILE_OP_LOGGER.debug("MoveTask moving (multi-file) " + srcPath + " to " + destPath);
            moveFile(srcPath, destPath, isDfsDir);
          }
          else {
            if (!destFs.exists(destPath)) {
              destFs.mkdirs(destPath);
            }
            FileSystem srcFs = srcPath.getFileSystem(conf);
            FileStatus[] children = srcFs.listStatus(srcPath);
            if (children != null) {
              for (FileStatus child : children) {
                Path childSrc = child.getPath();
                Path childDest = new Path(destPath, filePrefix + childSrc.getName());
                Utilities.FILE_OP_LOGGER.debug("MoveTask moving (multi-file) " + childSrc + " to " + childDest);
                moveFile(childSrc, childDest, isDfsDir);
              }
            }
            else {
              Utilities.FILE_OP_LOGGER.debug("MoveTask skipping empty directory (multi-file) " + srcPath);
            }
            if (!srcFs.delete(srcPath, false)) {
              throw new IOException("Couldn\'t delete " + srcPath + " after moving all the files");
            }
          }
        }
      }
      LoadTableDesc tbd = work.getLoadTableWork();
      if (tbd != null) {
        StringBuilder mesg = new StringBuilder("Loading data to table ").append(tbd.getTable().getTableName());
        if (tbd.getPartitionSpec().size() > 0) {
          mesg.append(" partition (");
          Map<String, String> partSpec = tbd.getPartitionSpec();
          for (String key : partSpec.keySet()) {
            mesg.append(key).append('=').append(partSpec.get(key)).append(", ");
          }
          mesg.setLength(mesg.length() - 2);
          mesg.append(')');
        }
        String mesg_detail = " from " + tbd.getSourcePath();
        if (Utilities.FILE_OP_LOGGER.isTraceEnabled()) {
          Utilities.FILE_OP_LOGGER.trace(mesg.toString() + " " + mesg_detail);
        }
        console.printInfo(mesg.toString(), mesg_detail);
        Table table = db.getTable(tbd.getTable().getTableName());
        checkFileFormats(db, tbd, table);
        boolean isFullAcidOp = work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID && !tbd.isMmTable();
        DataContainer dc = null;
        if (tbd.getPartitionSpec().size() == 0) {
          dc = new DataContainer(table.getTTable());
          if (Utilities.FILE_OP_LOGGER.isTraceEnabled()) {
            Utilities.FILE_OP_LOGGER.trace("loadTable called from " + tbd.getSourcePath() + " into " + tbd.getTable().getTableName());
          }
          db.loadTable(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getLoadFileType(), work.isSrcLocal(), isSkewedStoredAsDirs(tbd), isFullAcidOp, hasFollowingStatsTask(), tbd.getTxnId(), tbd.getStmtId(), tbd.isMmTable());
          if (work.getOutputs() != null) {
            DDLTask.addIfAbsentByName(new WriteEntity(table, getWriteType(tbd, work.getLoadTableWork().getWriteType())), work.getOutputs());
          }
        }
        else {
          LOG.info("Partition is: " + tbd.getPartitionSpec().toString());
          TaskInformation ti = new TaskInformation(this, tbd.getSourcePath().toUri().toString());
          inferTaskInformation(ti);
          DynamicPartitionCtx dpCtx = tbd.getDPCtx();
          if (dpCtx != null && dpCtx.getNumDPCols() > 0) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_14c9482_c254557\rev_left_14c9482\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
dc = handleDynParts(db, table, tbd, ti, dpCtx);
=======
Map<Map<String, String>, Partition> dp = db.loadDynamicPartitions(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getPartitionSpec(), tbd.getLoadFileType(), dpCtx.getNumDPCols(), isSkewedStoredAsDirs(tbd), work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID, work.getLoadTableWork().getCurrentTransactionId(), hasFollowingStatsTask(), work.getLoadTableWork().getWriteType());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_14c9482_c254557\rev_right_c254557\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

            dc = handleDynParts(db, table, tbd, ti, dpCtx);
          }
          else {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_14c9482_c254557\rev_left_14c9482\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
dc = handleStaticParts(db, table, tbd, ti);
=======
db.loadPartition(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getPartitionSpec(), tbd.getLoadFileType(), tbd.getInheritTableSpecs(), isSkewedStoredAsDirs(tbd), work.isSrcLocal(), work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID, hasFollowingStatsTask());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_14c9482_c254557\rev_right_c254557\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

          }
        }
        if (work.getLineagState() != null && dc != null) {
          List<FieldSchema> tableCols = null;
          switch (work.getLoadTableWork().getWriteType()){
            case DELETE:
            case UPDATE:
            tableCols = new ArrayList<>();
            break ;
            default:
            tableCols = table.getCols();
            break ;
          }
          work.getLineagState().setLineage(tbd.getSourcePath(), dc, tableCols);
        }
        releaseLocks(tbd);
      }
      return 0;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_fa90495_6bd9733\rev_left_fa90495\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_fa90495_6bd9733\rev_base_9071768\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_fa90495_6bd9733\rev_right_6bd9733\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (childClazz.equals(e.getEntity().getClass())) {
                  childs = (List<Object>)childClient.find(childClazz, rsSet.toArray(new String[]{  } ));
                }
                else {
                  childs = (List<Object>)persistenceDelegeator.find(childClazz, rsSet.toArray(new String[]{  } ));
                }
=======
childs = (List<Object>)(childClazz.equals(e.getEntity().getClass()) ? childClient.findAll(childClazz, rsSet.toArray(new String[]{  } )) : persistenceDelegeator.find(childClazz, rsSet.toArray(new String[]{  } )));
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public Object computeGraph(EnhanceEntity e, List<EntitySaveGraph> graphs, Map<Object, Object> collectionHolder, Client client, EntityMetadata m, PersistenceDelegator persistenceDelegeator) throws Exception {
    Client childClient = null;
    Class<?> childClazz = null;
    EntityMetadata childMetadata = null;
    for (EntitySaveGraph g : graphs) {
      Relation relation = m.getRelation(g.getProperty().getName());
      if (relation.isRelatedViaJoinTable()) {
        computeJoinTableRelations(e, client, m, g, persistenceDelegeator, relation);
      }
      else {
        if (e.getEntity().getClass().equals(g.getChildClass())) {
          String relationName = g.getfKeyName();
          Object relationalValue = e.getRelations().get(relationName);
          childClazz = g.getParentClass();
          childMetadata = persistenceDelegeator.getMetadata(childClazz);
          Field f = g.getProperty();
          if (!collectionHolder.containsKey(relationalValue)) {
            childClient = persistenceDelegeator.getClient(childMetadata);
            Object child = null;
            if (childClazz.equals(e.getEntity().getClass())) {
              child = childClient.find(childClazz, childMetadata, relationalValue.toString(), null);
            }
            else {
              child = persistenceDelegeator.find(childClazz, relationalValue.toString(), g);
            }
            collectionHolder.put(relationalValue, child);
          }
          onBiDirection(e, client, g, m, collectionHolder.get(relationalValue), childMetadata, childClient);
          List<Object> collection = new ArrayList<Object>(1);
          collection.add(collectionHolder.get(relationalValue));
          PropertyAccessorHelper.set(e.getEntity(), f, PropertyAccessorHelper.isCollection(f.getType()) ? getFieldInstance(collection, f) : collection.get(0));
        }
        else {
          childClazz = g.getChildClass();
          childMetadata = persistenceDelegeator.getMetadata(childClazz);
          childClient = persistenceDelegeator.getClient(childMetadata);
          String relationName = g.getfKeyName();
          String relationalValue = e.getEntityId();
          Field f = g.getProperty();
          if (!collectionHolder.containsKey(relationalValue)) {
            List<Object> childs = null;
            if (MetadataUtils.useSecondryIndex(childClient.getPersistenceUnit())) {
              childs = childClient.find(relationName, relationalValue, childMetadata);
            }
            else {
              if (g.isSharedPrimaryKey()) {
                childs = new ArrayList();
                childs.add(childClazz.equals(e.getEntity().getClass()) ? childs.add(childClient.find(childClazz, childMetadata, e.getEntityId(), null)) : persistenceDelegeator.find(childClazz, relationalValue.toString()));
              }
              else {
                String query = getQuery(DocumentIndexer.PARENT_ID_CLASS, e.getEntity().getClass().getCanonicalName().toLowerCase(), DocumentIndexer.PARENT_ID_FIELD, e.getEntityId());
                Map<String, String> results = childClient.getIndexManager().search(query);
                Set<String> rsSet = new HashSet<String>(results.values());
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_fa90495_6bd9733\rev_left_fa90495\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java
if (childClazz.equals(e.getEntity().getClass())) {
                  childs = (List<Object>)childClient.find(childClazz, rsSet.toArray(new String[]{  } ));
                }
                else {
                  childs = (List<Object>)persistenceDelegeator.find(childClazz, rsSet.toArray(new String[]{  } ));
                }
=======
childs = (List<Object>)(childClazz.equals(e.getEntity().getClass()) ? childClient.findAll(childClazz, rsSet.toArray(new String[]{  } )) : persistenceDelegeator.find(childClazz, rsSet.toArray(new String[]{  } )));
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_fa90495_6bd9733\rev_right_6bd9733\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java

              }
            }
            collectionHolder.put(relationalValue, childs);
            if (childs != null) {
              for (Object child : childs) {
                onBiDirection(e, client, g, m, child, childMetadata, childClient);
              }
            }
          }
          onReflect(e.getEntity(), f, (List)collectionHolder.get(relationalValue));
        }
      }
    }
    return e.getEntity();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\astyanax\revisions\rev_f90264e_8143e9c\rev_left_f90264e\src\main\java\com\netflix\astyanax\serializers\SerializerTypeInferer.java,C:\Users\user\Desktop\gjcc\amostra\projects\astyanax\revisions\rev_f90264e_8143e9c\rev_base_8c71eab\src\main\java\com\netflix\astyanax\serializers\SerializerTypeInferer.java,C:\Users\user\Desktop\gjcc\amostra\projects\astyanax\revisions\rev_f90264e_8143e9c\rev_right_8143e9c\src\main\java\com\netflix\astyanax\serializers\SerializerTypeInferer.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
{
                          for (Class face : valueClass.getInterfaces()) {
                            if (face.equals(StringCoercible.class)) {
                              serializer = StringCoercibleSerializer.get();
                            }
                          }
                          if (serializer == null) {
                            serializer = ObjectSerializer.get();
                          }
                        }
=======
if (valueClass.equals(Date.class)) {
                            serializer = DateSerializer.get();
                          }
                          else {
                            serializer = ObjectSerializer.get();
                          }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @SuppressWarnings(value = {"rawtypes", "unchecked", }) public static  <> Serializer<T> getSerializer(Class<?> valueClass) {
    Serializer serializer = null;
    if (valueClass.equals(UUID.class)) {
      serializer = UUIDSerializer.get();
    }
    else 
      if (valueClass.equals(String.class)) {
        serializer = StringSerializer.get();
      }
      else 
        if (valueClass.equals(Long.class) || valueClass.equals(long.class)) {
          serializer = LongSerializer.get();
        }
        else 
          if (valueClass.equals(Integer.class) || valueClass.equals(int.class)) {
            serializer = Int32Serializer.get();
          }
          else 
            if (valueClass.equals(Short.class) || valueClass.equals(short.class)) {
              serializer = ShortSerializer.get();
            }
            else 
              if (valueClass.equals(Byte.class) || valueClass.equals(byte.class)) {
                serializer = ByteSerializer.get();
              }
              else 
                if (valueClass.equals(Float.class) || valueClass.equals(float.class)) {
                  serializer = FloatSerializer.get();
                }
                else 
                  if (valueClass.equals(Double.class) || valueClass.equals(double.class)) {
                    serializer = DoubleSerializer.get();
                  }
                  else 
                    if (valueClass.equals(Boolean.class) || valueClass.equals(boolean.class)) {
                      serializer = BooleanSerializer.get();
                    }
                    else 
                      if (valueClass.equals(byte[].class)) {
                        serializer = BytesArraySerializer.get();
                      }
                      else 
                        if (valueClass.equals(ByteBuffer.class)) {
                          serializer = ByteBufferSerializer.get();
                        }
                        else 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\astyanax\revisions\rev_f90264e_8143e9c\rev_left_f90264e\src\main\java\com\netflix\astyanax\serializers\SerializerTypeInferer.java
{
                          for (Class face : valueClass.getInterfaces()) {
                            if (face.equals(StringCoercible.class)) {
                              serializer = StringCoercibleSerializer.get();
                            }
                          }
                          if (serializer == null) {
                            serializer = ObjectSerializer.get();
                          }
                        }
=======
if (valueClass.equals(Date.class)) {
                            serializer = DateSerializer.get();
                          }
                          else {
                            serializer = ObjectSerializer.get();
                          }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\astyanax\revisions\rev_f90264e_8143e9c\rev_right_8143e9c\src\main\java\com\netflix\astyanax\serializers\SerializerTypeInferer.java

    return serializer;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_4935a97_c136530\rev_left_4935a97\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_4935a97_c136530\rev_base_f669fc4\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_4935a97_c136530\rev_right_c136530\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (filterDirection) {
          assert query.getDirection() != Direction.BOTH;
          iter = Iterables.filter(iter, new Predicate<Entry>() {
              @Override public boolean apply(@Nullable Entry entry) {
                return edgeSerializer.parseDirection(entry) == query.getDirection();
              }
          });
        }
=======
return Iterables.transform(iter, new Function<Entry, TitanRelation>() {
            @Override public TitanRelation apply(@Nullable Entry entry) {
              return edgeSerializer.readRelation(v, entry);
            }
        }).iterator();
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
      @Override public Iterator<TitanRelation> execute(final VertexCentricQuery query, final SliceQuery sq, final Object exeInfo) {
        assert exeInfo == null;
        if (query.getVertex().isNew()) 
          return Iterators.emptyIterator();
        final InternalVertex v = query.getVertex();
        Iterable<Entry> iter = v.loadRelations(sq, new Retriever<SliceQuery, List<Entry>>() {
            @Override public List<Entry> get(SliceQuery query) {
              return graph.edgeQuery(v.getID(), query, txHandle);
            }
        });
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_4935a97_c136530\rev_left_4935a97\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java
if (filterDirection) {
          assert query.getDirection() != Direction.BOTH;
          iter = Iterables.filter(iter, new Predicate<Entry>() {
              @Override public boolean apply(@Nullable Entry entry) {
                return edgeSerializer.parseDirection(entry) == query.getDirection();
              }
          });
        }
=======
return Iterables.transform(iter, new Function<Entry, TitanRelation>() {
            @Override public TitanRelation apply(@Nullable Entry entry) {
              return edgeSerializer.readRelation(v, entry);
            }
        }).iterator();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_4935a97_c136530\rev_right_c136530\titan-core\src\main\java\com\thinkaurelius\titan\graphdb\transaction\StandardTitanTx.java

        return Iterables.transform(iter, new Function<Entry, TitanRelation>() {
            @Override public TitanRelation apply(@Nullable Entry entry) {
              return edgeSerializer.readRelation(v, entry);
            }
        }).iterator();
      }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_base_6c9b3d5\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
String typeName = sourceMethod.getTypeRoot().getElementName();
=======
IType declaringType = sourceMethod.getDeclaringType();
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static org.eclipse.jdt.core.dom.MethodDeclaration getRealMethodDeclarationNode(org.eclipse.jdt.core.IMethod sourceMethod, org.eclipse.jdt.core.dom.CompilationUnit cuUnit) throws JavaModelException {
    MethodDeclaration methodDeclarationNode = ASTNodeSearchUtil.getMethodDeclarationNode(sourceMethod, cuUnit);
    if (isGenerated(methodDeclarationNode)) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
String typeName = sourceMethod.getTypeRoot().getElementName();
=======
IType declaringType = sourceMethod.getDeclaringType();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
String methodName = sourceMethod.getElementName();
=======
Stack<IType> typeStack = new Stack<IType>();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
for (Object type : cuUnit.types()) {
        org.eclipse.jdt.core.dom.AbstractTypeDeclaration typeDeclaration = (AbstractTypeDeclaration)type;
        if ((typeDeclaration.getName() + ".java").equals(typeName)) {
          for (Object declaration : typeDeclaration.bodyDeclarations()) {
            if (declaration instanceof org.eclipse.jdt.core.dom.MethodDeclaration) {
              org.eclipse.jdt.core.dom.MethodDeclaration methodDeclaration = (org.eclipse.jdt.core.dom.MethodDeclaration)declaration;
              if (methodDeclaration.getName().toString().equals(methodName)) {
                return methodDeclaration;
              }
            }
          }
        }
      }
=======
while (declaringType != null){
        typeStack.push(declaringType);
        declaringType = declaringType.getDeclaringType();
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

    }
    return methodDeclarationNode;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_base_6c9b3d5\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
String methodName = sourceMethod.getElementName();
=======
Stack<IType> typeStack = new Stack<IType>();
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static org.eclipse.jdt.core.dom.MethodDeclaration getRealMethodDeclarationNode(org.eclipse.jdt.core.IMethod sourceMethod, org.eclipse.jdt.core.dom.CompilationUnit cuUnit) throws JavaModelException {
    MethodDeclaration methodDeclarationNode = ASTNodeSearchUtil.getMethodDeclarationNode(sourceMethod, cuUnit);
    if (isGenerated(methodDeclarationNode)) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
String typeName = sourceMethod.getTypeRoot().getElementName();
=======
IType declaringType = sourceMethod.getDeclaringType();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
String methodName = sourceMethod.getElementName();
=======
Stack<IType> typeStack = new Stack<IType>();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
for (Object type : cuUnit.types()) {
        org.eclipse.jdt.core.dom.AbstractTypeDeclaration typeDeclaration = (AbstractTypeDeclaration)type;
        if ((typeDeclaration.getName() + ".java").equals(typeName)) {
          for (Object declaration : typeDeclaration.bodyDeclarations()) {
            if (declaration instanceof org.eclipse.jdt.core.dom.MethodDeclaration) {
              org.eclipse.jdt.core.dom.MethodDeclaration methodDeclaration = (org.eclipse.jdt.core.dom.MethodDeclaration)declaration;
              if (methodDeclaration.getName().toString().equals(methodName)) {
                return methodDeclaration;
              }
            }
          }
        }
      }
=======
while (declaringType != null){
        typeStack.push(declaringType);
        declaringType = declaringType.getDeclaringType();
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

    }
    return methodDeclarationNode;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_base_6c9b3d5\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
for (Object type : cuUnit.types()) {
        org.eclipse.jdt.core.dom.AbstractTypeDeclaration typeDeclaration = (AbstractTypeDeclaration)type;
        if ((typeDeclaration.getName() + ".java").equals(typeName)) {
          for (Object declaration : typeDeclaration.bodyDeclarations()) {
            if (declaration instanceof org.eclipse.jdt.core.dom.MethodDeclaration) {
              org.eclipse.jdt.core.dom.MethodDeclaration methodDeclaration = (org.eclipse.jdt.core.dom.MethodDeclaration)declaration;
              if (methodDeclaration.getName().toString().equals(methodName)) {
                return methodDeclaration;
              }
            }
          }
        }
      }
=======
while (declaringType != null){
        typeStack.push(declaringType);
        declaringType = declaringType.getDeclaringType();
      }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static org.eclipse.jdt.core.dom.MethodDeclaration getRealMethodDeclarationNode(org.eclipse.jdt.core.IMethod sourceMethod, org.eclipse.jdt.core.dom.CompilationUnit cuUnit) throws JavaModelException {
    MethodDeclaration methodDeclarationNode = ASTNodeSearchUtil.getMethodDeclarationNode(sourceMethod, cuUnit);
    if (isGenerated(methodDeclarationNode)) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
String typeName = sourceMethod.getTypeRoot().getElementName();
=======
IType declaringType = sourceMethod.getDeclaringType();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
String methodName = sourceMethod.getElementName();
=======
Stack<IType> typeStack = new Stack<IType>();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_left_3027618\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java
for (Object type : cuUnit.types()) {
        org.eclipse.jdt.core.dom.AbstractTypeDeclaration typeDeclaration = (AbstractTypeDeclaration)type;
        if ((typeDeclaration.getName() + ".java").equals(typeName)) {
          for (Object declaration : typeDeclaration.bodyDeclarations()) {
            if (declaration instanceof org.eclipse.jdt.core.dom.MethodDeclaration) {
              org.eclipse.jdt.core.dom.MethodDeclaration methodDeclaration = (org.eclipse.jdt.core.dom.MethodDeclaration)declaration;
              if (methodDeclaration.getName().toString().equals(methodName)) {
                return methodDeclaration;
              }
            }
          }
        }
      }
=======
while (declaringType != null){
        typeStack.push(declaringType);
        declaringType = declaringType.getDeclaringType();
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_3027618_bf354e3\rev_right_bf354e3\src\eclipseAgent\lombok\eclipse\agent\PatchFixes.java

    }
    return methodDeclarationNode;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_c4397bd_e4a3108\rev_left_c4397bd\processing\src\main\java\io\druid\query\groupby\GroupByQueryRunnerFactory.java,C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_c4397bd_e4a3108\rev_base_b3aad48\processing\src\main\java\io\druid\query\groupby\GroupByQueryRunnerFactory.java,C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_c4397bd_e4a3108\rev_right_e4a3108\processing\src\main\java\io\druid\query\groupby\GroupByQueryRunnerFactory.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
ListenableFuture<Sequence<Row>> future = queryExecutor.submit(new Callable<Sequence<Row>>() {
                      @Override public Sequence<Row> call() throws Exception {
                        return new ExecutorExecutingSequence<Row>(input.run(query, context), queryExecutor);
                      }
                  });
=======
final GroupByQuery queryParam = (GroupByQuery)query;
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
                @Override public Sequence<Row> run(final Query<Row> query, final Map<String, Object> context) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_c4397bd_e4a3108\rev_left_c4397bd\processing\src\main\java\io\druid\query\groupby\GroupByQueryRunnerFactory.java
ListenableFuture<Sequence<Row>> future = queryExecutor.submit(new Callable<Sequence<Row>>() {
                      @Override public Sequence<Row> call() throws Exception {
                        return new ExecutorExecutingSequence<Row>(input.run(query, context), queryExecutor);
                      }
                  });
=======
final GroupByQuery queryParam = (GroupByQuery)query;
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\druid\revisions\rev_c4397bd_e4a3108\rev_right_e4a3108\processing\src\main\java\io\druid\query\groupby\GroupByQueryRunnerFactory.java

                  try {
                    queryWatcher.registerQuery(query, future);
                    final Number timeout = query.getContextValue("timeout", (Number)null);
                    return timeout == null ? future.get() : future.get(timeout.longValue(), TimeUnit.MILLISECONDS);
                  }
                  catch (InterruptedException e) {
                    log.warn(e, "Query interrupted, cancelling pending results, query id [%s]", query.getId());
                    future.cancel(true);
                    throw new QueryInterruptedException("Query interrupted");
                  }
                  catch (CancellationException e) {
                    throw new QueryInterruptedException("Query cancelled");
                  }
                  catch (TimeoutException e) {
                    log.info("Query timeout, cancelling pending results for query id [%s]", query.getId());
                    future.cancel(true);
                    throw new QueryInterruptedException("Query timeout");
                  }
                  catch (ExecutionException e) {
                    throw Throwables.propagate(e.getCause());
                  }
                }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\vrapper\revisions\rev_d392d75_6ed1662\rev_left_d392d75\net.sourceforge.vrapper.core\src\net\sourceforge\vrapper\vim\commands\motions\MoveWordRightForUpdate.java,C:\Users\user\Desktop\gjcc\amostra\projects\vrapper\revisions\rev_d392d75_6ed1662\rev_base_37a6da8\net.sourceforge.vrapper.core\src\net\sourceforge\vrapper\vim\commands\motions\MoveWordRightForUpdate.java,C:\Users\user\Desktop\gjcc\amostra\projects\vrapper\revisions\rev_d392d75_6ed1662\rev_right_6ed1662\net.sourceforge.vrapper.core\src\net\sourceforge\vrapper\vim\commands\motions\MoveWordRightForUpdate.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
offsetWithoutLastNewline(originalOffset, delegatePosition.getModelOffset(), editorAdaptor.getModelContent())
=======
MoveWordRightUtils.offsetWithoutLastNewline(originalOffset, parentPosition.getModelOffset(), editorAdaptor.getModelContent())
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public Position destination(EditorAdaptor editorAdaptor, int count) throws CommandExecutionException {
    int originalOffset = editorAdaptor.getPosition().getModelOffset();
    Position parentPosition = super.destination(editorAdaptor, count);
    int newOffset = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\vrapper\revisions\rev_d392d75_6ed1662\rev_left_d392d75\net.sourceforge.vrapper.core\src\net\sourceforge\vrapper\vim\commands\motions\MoveWordRightForUpdate.java
offsetWithoutLastNewline(originalOffset, delegatePosition.getModelOffset(), editorAdaptor.getModelContent())
=======
MoveWordRightUtils.offsetWithoutLastNewline(originalOffset, parentPosition.getModelOffset(), editorAdaptor.getModelContent())
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\vrapper\revisions\rev_d392d75_6ed1662\rev_right_6ed1662\net.sourceforge.vrapper.core\src\net\sourceforge\vrapper\vim\commands\motions\MoveWordRightForUpdate.java
;
    return editorAdaptor.getCursorService().newPositionForModelOffset(newOffset);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_left_e557413\src\core\lombok\eclipse\handlers\HandleLog.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_base_7d51842\src\core\lombok\eclipse\handlers\HandleLog.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_right_fbab1ca\src\core\lombok\eclipse\handlers\HandleLog.java
CONCLUSAO: FP. MUDANÇAS COMPLEMENTARES.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
logFieldName
=======
loggerCategory
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static void processAnnotation(LoggingFramework framework, AnnotationValues<? extends java.lang.annotation.Annotation> annotation, Annotation source, EclipseNode annotationNode, String loggerCategory) {
    EclipseNode owner = annotationNode.up();
    switch (owner.getKind()){
      case TYPE:
      String logFieldName = annotationNode.getAst().readConfiguration(ConfigurationKeys.LOG_ANY_FIELD_NAME);
      if (logFieldName == null) 
        logFieldName = "log";
      boolean useStatic = !Boolean.FALSE.equals(annotationNode.getAst().readConfiguration(ConfigurationKeys.LOG_ANY_FIELD_IS_STATIC));
      TypeDeclaration typeDecl = null;
      if (owner.get() instanceof TypeDeclaration) 
        typeDecl = (TypeDeclaration)owner.get();
      int modifiers = typeDecl == null ? 0 : typeDecl.modifiers;
      boolean notAClass = (modifiers & (ClassFileConstants.AccInterface | ClassFileConstants.AccAnnotation)) != 0;
      if (typeDecl == null || notAClass) {
        annotationNode.addError(framework.getAnnotationAsString() + " is legal only on classes and enums.");
        return ;
      }
      if (fieldExists(logFieldName, owner) != MemberExistsResult.NOT_EXISTS) {
        annotationNode.addWarning("Field \'" + logFieldName + "\' already exists.");
        return ;
      }
      ClassLiteralAccess loggingType = selfType(owner, source);
      FieldDeclaration fieldDeclaration = createField(framework, source, loggingType, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_left_e557413\src\core\lombok\eclipse\handlers\HandleLog.java
logFieldName
=======
loggerCategory
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_right_fbab1ca\src\core\lombok\eclipse\handlers\HandleLog.java
, useStatic);
      fieldDeclaration.traverse(new SetGeneratedByVisitor(source), typeDecl.staticInitializerScope);
      injectField(owner, fieldDeclaration);
      owner.rebuild();
      break ;
      default:
      break ;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_left_e557413\src\core\lombok\eclipse\handlers\HandleLog.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_base_7d51842\src\core\lombok\eclipse\handlers\HandleLog.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_right_fbab1ca\src\core\lombok\eclipse\handlers\HandleLog.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
String logFieldName
=======
String loggerCategory
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static FieldDeclaration createField(LoggingFramework framework, Annotation source, ClassLiteralAccess loggingType, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_left_e557413\src\core\lombok\eclipse\handlers\HandleLog.java
String logFieldName
=======
String loggerCategory
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_right_fbab1ca\src\core\lombok\eclipse\handlers\HandleLog.java
, boolean useStatic);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_left_e557413\src\core\lombok\javac\handlers\HandleLog.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_base_7d51842\src\core\lombok\javac\handlers\HandleLog.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_right_fbab1ca\src\core\lombok\javac\handlers\HandleLog.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
logFieldName
=======
loggerCategory
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static void processAnnotation(LoggingFramework framework, AnnotationValues<?> annotation, JavacNode annotationNode, String loggerCategory) {
    deleteAnnotationIfNeccessary(annotationNode, framework.getAnnotationClass());
    JavacNode typeNode = annotationNode.up();
    switch (typeNode.getKind()){
      case TYPE:
      String logFieldName = annotationNode.getAst().readConfiguration(ConfigurationKeys.LOG_ANY_FIELD_NAME);
      if (logFieldName == null) 
        logFieldName = "log";
      boolean useStatic = !Boolean.FALSE.equals(annotationNode.getAst().readConfiguration(ConfigurationKeys.LOG_ANY_FIELD_IS_STATIC));
      if ((((JCClassDecl)typeNode.get()).mods.flags & Flags.INTERFACE) != 0) {
        annotationNode.addError("@Log is legal only on classes and enums.");
        return ;
      }
      if (fieldExists(logFieldName, typeNode) != MemberExistsResult.NOT_EXISTS) {
        annotationNode.addWarning("Field \'" + logFieldName + "\' already exists.");
        return ;
      }
      JCFieldAccess loggingType = selfType(typeNode);
      createField(framework, typeNode, loggingType, annotationNode.get(), 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_left_e557413\src\core\lombok\javac\handlers\HandleLog.java
logFieldName
=======
loggerCategory
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_right_fbab1ca\src\core\lombok\javac\handlers\HandleLog.java
, useStatic);
      break ;
      default:
      annotationNode.addError("@Log is legal only on types.");
      break ;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_left_e557413\src\core\lombok\javac\handlers\HandleLog.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_base_7d51842\src\core\lombok\javac\handlers\HandleLog.java,C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_right_fbab1ca\src\core\lombok\javac\handlers\HandleLog.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
String logFieldName
=======
String loggerCategory
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static boolean createField(LoggingFramework framework, JavacNode typeNode, JCFieldAccess loggingType, JCTree source, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_left_e557413\src\core\lombok\javac\handlers\HandleLog.java
String logFieldName
=======
String loggerCategory
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\lombok\revisions\rev_e557413_fbab1ca\rev_right_fbab1ca\src\core\lombok\javac\handlers\HandleLog.java
, boolean useStatic);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_11ae23a_601bc4c\rev_left_11ae23a\curator-recipes\src\main\java\org\apache\curator\framework\recipes\cache\PathChildrenCache.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_11ae23a_601bc4c\rev_base_97cda39\curator-recipes\src\main\java\org\apache\curator\framework\recipes\cache\PathChildrenCache.java,C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_11ae23a_601bc4c\rev_right_601bc4c\curator-recipes\src\main\java\org\apache\curator\framework\recipes\cache\PathChildrenCache.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (state.compareAndSet(State.STARTED, State.CLOSED)) {
      client.getConnectionStateListenable().removeListener(connectionStateListener);
      executorService.shutdownNow();
    }
=======
executorService.close();
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public void close() throws IOException {
    if (state.compareAndSet(State.STARTED, State.CLOSED)) {
      client.getConnectionStateListenable().removeListener(connectionStateListener);
      executorService.shutdownNow();
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_11ae23a_601bc4c\rev_left_11ae23a\curator-recipes\src\main\java\org\apache\curator\framework\recipes\cache\PathChildrenCache.java
if (state.compareAndSet(State.STARTED, State.CLOSED)) {
      client.getConnectionStateListenable().removeListener(connectionStateListener);
      executorService.shutdownNow();
    }
=======
executorService.close();
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\curator\revisions\rev_11ae23a_601bc4c\rev_right_601bc4c\curator-recipes\src\main\java\org\apache\curator\framework\recipes\cache\PathChildrenCache.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_7d35db6_a4b5fbe\rev_left_7d35db6\core\src\main\java\org\elasticsearch\search\sort\SortParseElement.java,C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_7d35db6_a4b5fbe\rev_base_c9e1ccf\core\src\main\java\org\elasticsearch\search\sort\SortParseElement.java,C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_7d35db6_a4b5fbe\rev_right_a4b5fbe\core\src\main\java\org\elasticsearch\search\sort\SortParseElement.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
{
                              throw new IllegalArgumentException("sort option [" + innerJsonName + "] not supported");
                            }
=======
if ("nested_path".equals(innerJsonName) || "nestedPath".equals(innerJsonName)) {
                                if (nestedFilterParseHelper == null) {
                                  nestedFilterParseHelper = new NestedInnerQueryParseSupport(parser, context.getQueryShardContext());
                                }
                                nestedFilterParseHelper.setPath(parser.text());
                              }
                              else {
                                throw new IllegalArgumentException("sort option [" + innerJsonName + "] not supported");
                              }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void addCompoundSortField(XContentParser parser, SearchContext context, List<SortField> sortFields) throws Exception {
    XContentParser.Token token;
    while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT){
      if (token == XContentParser.Token.FIELD_NAME) {
        String fieldName = parser.currentName();
        boolean reverse = false;
        String missing = null;
        String innerJsonName = null;
        String unmappedType = null;
        MultiValueMode sortMode = null;
        NestedInnerQueryParseSupport nestedFilterParseHelper = null;
        token = parser.nextToken();
        if (token == XContentParser.Token.VALUE_STRING) {
          String direction = parser.text();
          if (direction.equals("asc")) {
            reverse = SCORE_FIELD_NAME.equals(fieldName);
          }
          else 
            if (direction.equals("desc")) {
              reverse = !SCORE_FIELD_NAME.equals(fieldName);
            }
            else {
              throw new IllegalArgumentException("sort direction [" + fieldName + "] not supported");
            }
          addSortField(context, sortFields, fieldName, reverse, unmappedType, missing, sortMode, nestedFilterParseHelper);
        }
        else {
          if (PARSERS.containsKey(fieldName)) {
            sortFields.add(PARSERS.get(fieldName).parse(parser, context.getQueryShardContext()));
          }
          else {
            while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT){
              if (token == XContentParser.Token.FIELD_NAME) {
                innerJsonName = parser.currentName();
              }
              else 
                if (token.isValue()) {
                  if ("reverse".equals(innerJsonName)) {
                    reverse = parser.booleanValue();
                  }
                  else 
                    if ("order".equals(innerJsonName)) {
                      if ("asc".equals(parser.text())) {
                        reverse = SCORE_FIELD_NAME.equals(fieldName);
                      }
                      else 
                        if ("desc".equals(parser.text())) {
                          reverse = !SCORE_FIELD_NAME.equals(fieldName);
                        }
                    }
                    else 
                      if ("missing".equals(innerJsonName)) {
                        missing = parser.textOrNull();
                      }
                      else 
                        if (context.parseFieldMatcher().match(innerJsonName, UNMAPPED_TYPE)) {
                          unmappedType = parser.textOrNull();
                        }
                        else 
                          if ("mode".equals(innerJsonName)) {
                            sortMode = MultiValueMode.fromString(parser.text());
                          }
                          else 
                            if ("nested_path".equals(innerJsonName) || "nestedPath".equals(innerJsonName)) {
                              if (nestedFilterParseHelper == null) {
                                nestedFilterParseHelper = new NestedInnerQueryParseSupport(parser, context);
                              }
                              nestedFilterParseHelper.setPath(parser.text());
                            }
                            else 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_7d35db6_a4b5fbe\rev_left_7d35db6\core\src\main\java\org\elasticsearch\search\sort\SortParseElement.java
{
                              throw new IllegalArgumentException("sort option [" + innerJsonName + "] not supported");
                            }
=======
if ("nested_path".equals(innerJsonName) || "nestedPath".equals(innerJsonName)) {
                                if (nestedFilterParseHelper == null) {
                                  nestedFilterParseHelper = new NestedInnerQueryParseSupport(parser, context.getQueryShardContext());
                                }
                                nestedFilterParseHelper.setPath(parser.text());
                              }
                              else {
                                throw new IllegalArgumentException("sort option [" + innerJsonName + "] not supported");
                              }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\elasticsearch\revisions\rev_7d35db6_a4b5fbe\rev_right_a4b5fbe\core\src\main\java\org\elasticsearch\search\sort\SortParseElement.java

                }
            }
            addSortField(context, sortFields, fieldName, reverse, unmappedType, missing, sortMode, nestedFilterParseHelper);
          }
        }
      }
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_8f7be2e_aae4793\rev_left_8f7be2e\ambry-store\src\main\java\com.github.ambry.store\PersistentIndex.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_8f7be2e_aae4793\rev_base_0954224\ambry-store\src\main\java\com.github.ambry.store\PersistentIndex.java,C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_8f7be2e_aae4793\rev_right_aae4793\ambry-store\src\main\java\com.github.ambry.store\PersistentIndex.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
indexes.subMap(startEntry.getKey(), true, endEntry.getKey(), true)
=======
new ConcurrentSkipListMap<Long, IndexSegment>()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public boolean exists(StoreKey key, FileSpan fileSpan) throws StoreException {
    final Timer.Context context = metrics.findTime.time();
    System.out.println("Searching for " + key + " in index with filespan ranging from " + fileSpan.getStartOffset() + " to " + fileSpan.getEndOffset());
    logger.trace("Searching for " + key + " in index with filespan ranging from " + fileSpan.getStartOffset() + " to " + fileSpan.getEndOffset());
    try {
      Map.Entry<Long, IndexSegment> startEntry = indexes.floorEntry(fileSpan.getStartOffset());
      Map.Entry<Long, IndexSegment> endEntry = indexes.floorEntry(fileSpan.getEndOffset());
      ConcurrentNavigableMap<Long, IndexSegment> interestedSegmentsMap = 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_8f7be2e_aae4793\rev_left_8f7be2e\ambry-store\src\main\java\com.github.ambry.store\PersistentIndex.java
indexes.subMap(startEntry.getKey(), true, endEntry.getKey(), true)
=======
new ConcurrentSkipListMap<Long, IndexSegment>()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\ambry\revisions\rev_8f7be2e_aae4793\rev_right_aae4793\ambry-store\src\main\java\com.github.ambry.store\PersistentIndex.java
;
      boolean foundValue = false;
      for (Map.Entry<Long, IndexSegment> entry : interestedSegmentsMap.entrySet()) {
        logger.trace("Index : {} searching index with start offset {}", dataDir, entry.getKey());
        IndexValue value = entry.getValue().find(key);
        if (value != null) {
          logger.trace("Index : {} found value offset {} size {} ttl {}", dataDir, value.getOffset(), value.getSize(), value.getTimeToLiveInMs());
          foundValue = true;
          break ;
        }
      }
      return foundValue;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_left_7d3ea8d\src\main\java\com\thinkaurelius\faunus\FaunusElement.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_base_3194e54\src\main\java\com\thinkaurelius\faunus\FaunusElement.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_right_340c929\src\main\java\com\thinkaurelius\faunus\FaunusElement.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
(T)Long.valueOf(this.pathCount())
=======
(T)(Object)this.pathCount()
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public  <> T getProperty(final String key) {
    if (key.equals(Tokens._COUNT)) 
      return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_left_7d3ea8d\src\main\java\com\thinkaurelius\faunus\FaunusElement.java
(T)Long.valueOf(this.pathCount())
=======
(T)(Object)this.pathCount()
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_right_340c929\src\main\java\com\thinkaurelius\faunus\FaunusElement.java
;
    return null == this.properties ? null : (T)this.properties.get(key);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_left_7d3ea8d\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_base_3194e54\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_right_340c929\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
final Vertex inVertex
=======
Vertex vertex
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public Edge addEdge(final String label, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_left_7d3ea8d\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java
final Vertex inVertex
=======
Vertex vertex
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_right_340c929\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_left_7d3ea8d\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_base_3194e54\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_right_340c929\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
this.addEdge(Direction.OUT, new FaunusEdge(this.getIdAsLong(), ((FaunusVertex)inVertex).getIdAsLong(), label))
=======
addEdge(Direction.OUT, new FaunusEdge(this.getIdAsLong(), ((FaunusVertex)vertex).getIdAsLong(), label))
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public Edge addEdge(final String label, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_left_7d3ea8d\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java
final Vertex inVertex
=======
Vertex vertex
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_right_340c929\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java
) {
    return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_left_7d3ea8d\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java
this.addEdge(Direction.OUT, new FaunusEdge(this.getIdAsLong(), ((FaunusVertex)inVertex).getIdAsLong(), label))
=======
addEdge(Direction.OUT, new FaunusEdge(this.getIdAsLong(), ((FaunusVertex)vertex).getIdAsLong(), label))
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_7d3ea8d_340c929\rev_right_340c929\src\main\java\com\thinkaurelius\faunus\FaunusVertex.java
;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_35c0a67_9461ead\rev_left_35c0a67\ql\src\java\org\apache\hadoop\hive\ql\optimizer\GenMapRedUtils.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_35c0a67_9461ead\rev_base_7c6cc58\ql\src\java\org\apache\hadoop\hive\ql\optimizer\GenMapRedUtils.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_35c0a67_9461ead\rev_right_9461ead\ql\src\java\org\apache\hadoop\hive\ql\optimizer\GenMapRedUtils.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
opProcCtx.addSeenOp(task, topOp);
=======
if (!local) {
      while (iterPath.hasNext()){
        assert iterPartnDesc.hasNext();
        String path = iterPath.next().toString();
        PartitionDesc prtDesc = iterPartnDesc.next();
        if (plan.getPathToAliases().get(path) == null) {
          plan.getPathToAliases().put(path, new ArrayList<String>());
        }
        plan.getPathToAliases().get(path).add(alias_id);
        plan.getPathToPartitionInfo().put(path, prtDesc);
        if (LOG.isDebugEnabled()) {
          LOG.debug("Information added for path " + path);
        }
      }
      assert plan.getAliasToWork().get(alias_id) == null;
      plan.getAliasToWork().put(alias_id, topOp);
    }
    else {
      MapredLocalWork localPlan = plan.getMapLocalWork();
      if (localPlan == null) {
        localPlan = new MapredLocalWork(new LinkedHashMap<String, Operator<? extends OperatorDesc>>(), new LinkedHashMap<String, FetchWork>());
      }
      assert localPlan.getAliasToWork().get(alias_id) == null;
      assert localPlan.getAliasToFetchWork().get(alias_id) == null;
      localPlan.getAliasToWork().put(alias_id, topOp);
      if (tblDir == null) {
        tblDesc = Utilities.getTableDesc(partsList.getSourceTable());
        localPlan.getAliasToFetchWork().put(alias_id, new FetchWork(partDir, partDesc, tblDesc));
      }
      else {
        localPlan.getAliasToFetchWork().put(alias_id, new FetchWork(tblDir, tblDesc));
      }
      plan.setMapLocalWork(localPlan);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static void setTaskPlan(String alias_id, Operator<? extends OperatorDesc> topOp, Task<?> task, boolean local, GenMRProcContext opProcCtx, PrunedPartitionList pList) throws SemanticException {
    setMapWork(((MapredWork)task.getWork()).getMapWork(), opProcCtx.getParseCtx(), opProcCtx.getInputs(), pList, topOp, alias_id, opProcCtx.getConf(), local);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_35c0a67_9461ead\rev_left_35c0a67\ql\src\java\org\apache\hadoop\hive\ql\optimizer\GenMapRedUtils.java
opProcCtx.addSeenOp(task, topOp);
=======
if (!local) {
      while (iterPath.hasNext()){
        assert iterPartnDesc.hasNext();
        String path = iterPath.next().toString();
        PartitionDesc prtDesc = iterPartnDesc.next();
        if (plan.getPathToAliases().get(path) == null) {
          plan.getPathToAliases().put(path, new ArrayList<String>());
        }
        plan.getPathToAliases().get(path).add(alias_id);
        plan.getPathToPartitionInfo().put(path, prtDesc);
        if (LOG.isDebugEnabled()) {
          LOG.debug("Information added for path " + path);
        }
      }
      assert plan.getAliasToWork().get(alias_id) == null;
      plan.getAliasToWork().put(alias_id, topOp);
    }
    else {
      MapredLocalWork localPlan = plan.getMapLocalWork();
      if (localPlan == null) {
        localPlan = new MapredLocalWork(new LinkedHashMap<String, Operator<? extends OperatorDesc>>(), new LinkedHashMap<String, FetchWork>());
      }
      assert localPlan.getAliasToWork().get(alias_id) == null;
      assert localPlan.getAliasToFetchWork().get(alias_id) == null;
      localPlan.getAliasToWork().put(alias_id, topOp);
      if (tblDir == null) {
        tblDesc = Utilities.getTableDesc(partsList.getSourceTable());
        localPlan.getAliasToFetchWork().put(alias_id, new FetchWork(partDir, partDesc, tblDesc));
      }
      else {
        localPlan.getAliasToFetchWork().put(alias_id, new FetchWork(tblDir, tblDesc));
      }
      plan.setMapLocalWork(localPlan);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_35c0a67_9461ead\rev_right_9461ead\ql\src\java\org\apache\hadoop\hive\ql\optimizer\GenMapRedUtils.java

  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\jackson-databind\revisions\rev_ab494a1_23d49e3\rev_left_ab494a1\src\main\java\com\fasterxml\jackson\databind\deser\std\NumberDeserializers.java,C:\Users\user\Desktop\gjcc\amostra\projects\jackson-databind\revisions\rev_ab494a1_23d49e3\rev_base_8d5bd66\src\main\java\com\fasterxml\jackson\databind\deser\std\NumberDeserializers.java,C:\Users\user\Desktop\gjcc\amostra\projects\jackson-databind\revisions\rev_ab494a1_23d49e3\rev_right_23d49e3\src\main\java\com\fasterxml\jackson\databind\deser\std\NumberDeserializers.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
(Character)_coerceNullToken(ctxt, _primitive)
=======
_deserializeFromArray(p, ctxt)
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
    @Override public Character deserialize(JsonParser p, DeserializationContext ctxt) throws IOException {
      switch (p.getCurrentTokenId()){
        case JsonTokenId.ID_NUMBER_INT:
        int value = p.getIntValue();
        if (value >= 0 && value <= 0xFFFF) {
          return Character.valueOf((char)value);
        }
        break ;
        case JsonTokenId.ID_STRING:
        String text = p.getText();
        if (text.length() == 1) {
          return Character.valueOf(text.charAt(0));
        }
        if (text.length() == 0) {
          return (Character)_coerceEmptyString(ctxt, _primitive);
        }
        break ;
        case JsonTokenId.ID_NULL:
        return 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\jackson-databind\revisions\rev_ab494a1_23d49e3\rev_left_ab494a1\src\main\java\com\fasterxml\jackson\databind\deser\std\NumberDeserializers.java
(Character)_coerceNullToken(ctxt, _primitive)
=======
_deserializeFromArray(p, ctxt)
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\jackson-databind\revisions\rev_ab494a1_23d49e3\rev_right_23d49e3\src\main\java\com\fasterxml\jackson\databind\deser\std\NumberDeserializers.java
;
        case JsonTokenId.ID_START_ARRAY:
        if (ctxt.isEnabled(DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS)) {
          p.nextToken();
          final Character C = deserialize(p, ctxt);
          if (p.nextToken() != JsonToken.END_ARRAY) {
            handleMissingEndArrayForSingle(p, ctxt);
          }
          return C;
        }
        default:
      }
      return (Character)ctxt.handleUnexpectedToken(_valueClass, p);
    }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\hbase-handler\src\java\org\apache\hadoop\hive\hbase\HBaseStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_base_200c631\hbase-handler\src\java\org\apache\hadoop\hive\hbase\HBaseStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\hbase-handler\src\java\org\apache\hadoop\hive\hbase\HBaseStatsAggregator.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public boolean connect(Configuration hiveconf, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\hbase-handler\src\java\org\apache\hadoop\hive\hbase\HBaseStatsAggregator.java
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\hbase-handler\src\java\org\apache\hadoop\hive\hbase\HBaseStatsAggregator.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\DummyStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_base_200c631\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\DummyStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\DummyStatsAggregator.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public boolean connect(Configuration hconf, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\DummyStatsAggregator.java
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\DummyStatsAggregator.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\KeyVerifyingStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_base_200c631\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\KeyVerifyingStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\KeyVerifyingStatsAggregator.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public boolean connect(Configuration hconf, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\KeyVerifyingStatsAggregator.java
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\itests\util\src\main\java\org\apache\hadoop\hive\ql\stats\KeyVerifyingStatsAggregator.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\ql\src\java\org\apache\hadoop\hive\ql\plan\StatsWork.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_base_200c631\ql\src\java\org\apache\hadoop\hive\ql\plan\StatsWork.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\ql\src\java\org\apache\hadoop\hive\ql\plan\StatsWork.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void setSourceTask(
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\ql\src\java\org\apache\hadoop\hive\ql\plan\StatsWork.java
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\ql\src\java\org\apache\hadoop\hive\ql\plan\StatsWork.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\ql\src\java\org\apache\hadoop\hive\ql\stats\CounterStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_base_200c631\ql\src\java\org\apache\hadoop\hive\ql\stats\CounterStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\ql\src\java\org\apache\hadoop\hive\ql\stats\CounterStatsAggregator.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public boolean connect(Configuration hconf, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\ql\src\java\org\apache\hadoop\hive\ql\stats\CounterStatsAggregator.java
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\ql\src\java\org\apache\hadoop\hive\ql\stats\CounterStatsAggregator.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\ql\src\java\org\apache\hadoop\hive\ql\stats\StatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_base_200c631\ql\src\java\org\apache\hadoop\hive\ql\stats\StatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\ql\src\java\org\apache\hadoop\hive\ql\stats\StatsAggregator.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public boolean connect(Configuration hconf, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\ql\src\java\org\apache\hadoop\hive\ql\stats\StatsAggregator.java
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\ql\src\java\org\apache\hadoop\hive\ql\stats\StatsAggregator.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\ql\src\java\org\apache\hadoop\hive\ql\stats\jdbc\JDBCStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_base_200c631\ql\src\java\org\apache\hadoop\hive\ql\stats\jdbc\JDBCStatsAggregator.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\ql\src\java\org\apache\hadoop\hive\ql\stats\jdbc\JDBCStatsAggregator.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public boolean connect(Configuration hiveconf, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_left_2d4709b\ql\src\java\org\apache\hadoop\hive\ql\stats\jdbc\JDBCStatsAggregator.java
Task<?> sourceTask
=======
Task sourceTask
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_2d4709b_c164a97\rev_right_c164a97\ql\src\java\org\apache\hadoop\hive\ql\stats\jdbc\JDBCStatsAggregator.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_left_4f097fd\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_base_5fd1167\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_right_88482c3\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
boolean returnNone
=======
OrcProto.BloomFilterIndex[] bloomFilterIndices
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
    public boolean[] pickRowGroups(StripeInformation stripe, OrcProto.RowIndex[] indexes, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_left_4f097fd\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
boolean returnNone
=======
OrcProto.BloomFilterIndex[] bloomFilterIndices
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_right_88482c3\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
);
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_left_4f097fd\ql\src\java\org\apache\hadoop\hive\ql\parse\TezCompiler.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_base_5fd1167\ql\src\java\org\apache\hadoop\hive\ql\parse\TezCompiler.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_right_88482c3\ql\src\java\org\apache\hadoop\hive\ql\parse\TezCompiler.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if ("llap".equalsIgnoreCase(conf.getVar(HiveConf.ConfVars.HIVE_EXECUTION_MODE))) {
      physicalCtx = new LlapDecider().resolve(physicalCtx);
    }
    else {
      LOG.debug("Skipping llap decider");
    }
=======
if ((conf.getBoolVar(HiveConf.ConfVars.HIVE_TEZ_ENABLE_MEMORY_MANAGER)) && (conf.getBoolVar(HiveConf.ConfVars.HIVEUSEHYBRIDGRACEHASHJOIN))) {
      physicalCtx = new MemoryDecider().resolve(physicalCtx);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override protected void optimizeTaskPlan(List<Task<? extends Serializable>> rootTasks, ParseContext pCtx, Context ctx) throws SemanticException {
    PhysicalContext physicalCtx = new PhysicalContext(conf, pCtx, pCtx.getContext(), rootTasks, pCtx.getFetchTask());
    if (conf.getBoolVar(HiveConf.ConfVars.HIVENULLSCANOPTIMIZE)) {
      physicalCtx = new NullScanOptimizer().resolve(physicalCtx);
    }
    else {
      LOG.debug("Skipping null scan query optimization");
    }
    if (conf.getBoolVar(HiveConf.ConfVars.HIVEMETADATAONLYQUERIES)) {
      physicalCtx = new MetadataOnlyOptimizer().resolve(physicalCtx);
    }
    else {
      LOG.debug("Skipping metadata only query optimization");
    }
    if (conf.getBoolVar(HiveConf.ConfVars.HIVE_CHECK_CROSS_PRODUCT)) {
      physicalCtx = new CrossProductCheck().resolve(physicalCtx);
    }
    else {
      LOG.debug("Skipping cross product analysis");
    }
    if (conf.getBoolVar(HiveConf.ConfVars.HIVE_VECTORIZATION_ENABLED)) {
      physicalCtx = new Vectorizer().resolve(physicalCtx);
    }
    else {
      LOG.debug("Skipping vectorization");
    }
    if (!"none".equalsIgnoreCase(conf.getVar(HiveConf.ConfVars.HIVESTAGEIDREARRANGE))) {
      physicalCtx = new StageIDsRearranger().resolve(physicalCtx);
    }
    else {
      LOG.debug("Skipping stage id rearranger");
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_left_4f097fd\ql\src\java\org\apache\hadoop\hive\ql\parse\TezCompiler.java
if ("llap".equalsIgnoreCase(conf.getVar(HiveConf.ConfVars.HIVE_EXECUTION_MODE))) {
      physicalCtx = new LlapDecider().resolve(physicalCtx);
    }
    else {
      LOG.debug("Skipping llap decider");
    }
=======
if ((conf.getBoolVar(HiveConf.ConfVars.HIVE_TEZ_ENABLE_MEMORY_MANAGER)) && (conf.getBoolVar(HiveConf.ConfVars.HIVEUSEHYBRIDGRACEHASHJOIN))) {
      physicalCtx = new MemoryDecider().resolve(physicalCtx);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_4f097fd_88482c3\rev_right_88482c3\ql\src\java\org\apache\hadoop\hive\ql\parse\TezCompiler.java

    return ;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\fastjson\revisions\rev_c76d44b_a12ff69\rev_left_c76d44b\src\main\java\com\alibaba\fastjson\parser\deserializer\JavaBeanDeserializer.java,C:\Users\user\Desktop\gjcc\amostra\projects\fastjson\revisions\rev_c76d44b_a12ff69\rev_base_490213c\src\main\java\com\alibaba\fastjson\parser\deserializer\JavaBeanDeserializer.java,C:\Users\user\Desktop\gjcc\amostra\projects\fastjson\revisions\rev_c76d44b_a12ff69\rev_right_a12ff69\src\main\java\com\alibaba\fastjson\parser\deserializer\JavaBeanDeserializer.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
userType = config.checkAutoType(typeName, expectClass);
=======
if (expectClass == null || (userType != null && expectClass.isAssignableFrom(userType))) {
                  deserializer = parser.getConfig().getDeserializer(userType);
                }
                else {
                  throw new JSONException("type not match");
                }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @SuppressWarnings(value = {"unchecked", "rawtypes", }) protected  <> T deserialze(DefaultJSONParser parser, Type type, Object fieldName, Object object, int features, int[] setFlags) {
    if (type == JSON.class || type == JSONObject.class) {
      return (T)parser.parse();
    }
    final JSONLexerBase lexer = (JSONLexerBase)parser.lexer;
    int token = lexer.token();
    if (token == JSONToken.NULL) {
      lexer.nextToken(JSONToken.COMMA);
      return null;
    }
    ParseContext context = parser.getContext();
    if (object != null && context != null) {
      context = context.parent;
    }
    ParseContext childContext = null;
    try {
      Map<String, Object> fieldValues = null;
      if (token == JSONToken.RBRACE) {
        lexer.nextToken(JSONToken.COMMA);
        if (object == null) {
          object = createInstance(parser, type);
        }
        return (T)object;
      }
      if (token == JSONToken.LBRACKET) {
        final int mask = Feature.SupportArrayToBean.mask;
        boolean isSupportArrayToBean = (beanInfo.parserFeatures & mask) != 0 || lexer.isEnabled(Feature.SupportArrayToBean) || (features & mask) != 0;
        if (isSupportArrayToBean) {
          return deserialzeArrayMapping(parser, type, fieldName, object);
        }
      }
      if (token != JSONToken.LBRACE && token != JSONToken.COMMA) {
        if (lexer.isBlankInput()) {
          return null;
        }
        if (token == JSONToken.LITERAL_STRING) {
          String strVal = lexer.stringVal();
          if (strVal.length() == 0) {
            lexer.nextToken();
            return null;
          }
        }
        if (token == JSONToken.LBRACKET && lexer.getCurrent() == ']') {
          lexer.next();
          lexer.nextToken();
          return null;
        }
        StringBuffer buf = (new StringBuffer()).append("syntax error, expect {, actual ").append(lexer.tokenName()).append(", pos ").append(lexer.pos());
        if (fieldName instanceof String) {
          buf.append(", fieldName ").append(fieldName);
        }
        throw new JSONException(buf.toString());
      }
      if (parser.resolveStatus == DefaultJSONParser.TypeNameRedirect) {
        parser.resolveStatus = DefaultJSONParser.NONE;
      }
      for (int fieldIndex = 0; true; fieldIndex++) {
        String key = null;
        FieldDeserializer fieldDeser = null;
        FieldInfo fieldInfo = null;
        Class<?> fieldClass = null;
        JSONField feildAnnotation = null;
        if (fieldIndex < sortedFieldDeserializers.length) {
          fieldDeser = sortedFieldDeserializers[fieldIndex];
          fieldInfo = fieldDeser.fieldInfo;
          fieldClass = fieldInfo.fieldClass;
          feildAnnotation = fieldInfo.getAnnotation();
        }
        boolean matchField = false;
        boolean valueParsed = false;
        Object fieldValue = null;
        if (fieldDeser != null) {
          char[] name_chars = fieldInfo.name_chars;
          if (fieldClass == int.class || fieldClass == Integer.class) {
            fieldValue = lexer.scanFieldInt(name_chars);
            if (lexer.matchStat > 0) {
              matchField = true;
              valueParsed = true;
            }
            else 
              if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                continue ;
              }
          }
          else 
            if (fieldClass == long.class || fieldClass == Long.class) {
              fieldValue = lexer.scanFieldLong(name_chars);
              if (lexer.matchStat > 0) {
                matchField = true;
                valueParsed = true;
              }
              else 
                if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                  continue ;
                }
            }
            else 
              if (fieldClass == String.class) {
                fieldValue = lexer.scanFieldString(name_chars);
                if (lexer.matchStat > 0) {
                  matchField = true;
                  valueParsed = true;
                }
                else 
                  if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                    continue ;
                  }
              }
              else 
                if (fieldClass == boolean.class || fieldClass == Boolean.class) {
                  fieldValue = lexer.scanFieldBoolean(name_chars);
                  if (lexer.matchStat > 0) {
                    matchField = true;
                    valueParsed = true;
                  }
                  else 
                    if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                      continue ;
                    }
                }
                else 
                  if (fieldClass == float.class || fieldClass == Float.class) {
                    fieldValue = lexer.scanFieldFloat(name_chars);
                    if (lexer.matchStat > 0) {
                      matchField = true;
                      valueParsed = true;
                    }
                    else 
                      if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                        continue ;
                      }
                  }
                  else 
                    if (fieldClass == double.class || fieldClass == Double.class) {
                      fieldValue = lexer.scanFieldDouble(name_chars);
                      if (lexer.matchStat > 0) {
                        matchField = true;
                        valueParsed = true;
                      }
                      else 
                        if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                          continue ;
                        }
                    }
                    else 
                      if (fieldClass.isEnum() && parser.getConfig().getDeserializer(fieldClass) instanceof EnumDeserializer && (feildAnnotation == null || feildAnnotation.deserializeUsing() == Void.class)) {
                        if (fieldDeser instanceof DefaultFieldDeserializer) {
                          ObjectDeserializer fieldValueDeserilizer = ((DefaultFieldDeserializer)fieldDeser).fieldValueDeserilizer;
                          fieldValue = this.scanEnum(lexer, name_chars, fieldValueDeserilizer);
                          if (lexer.matchStat > 0) {
                            matchField = true;
                            valueParsed = true;
                          }
                          else 
                            if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                              continue ;
                            }
                        }
                      }
                      else 
                        if (fieldClass == int[].class) {
                          fieldValue = lexer.scanFieldIntArray(name_chars);
                          if (lexer.matchStat > 0) {
                            matchField = true;
                            valueParsed = true;
                          }
                          else 
                            if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                              continue ;
                            }
                        }
                        else 
                          if (fieldClass == float[].class) {
                            fieldValue = lexer.scanFieldFloatArray(name_chars);
                            if (lexer.matchStat > 0) {
                              matchField = true;
                              valueParsed = true;
                            }
                            else 
                              if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                                continue ;
                              }
                          }
                          else 
                            if (fieldClass == float[][].class) {
                              fieldValue = lexer.scanFieldFloatArray2(name_chars);
                              if (lexer.matchStat > 0) {
                                matchField = true;
                                valueParsed = true;
                              }
                              else 
                                if (lexer.matchStat == JSONLexer.NOT_MATCH_NAME) {
                                  continue ;
                                }
                            }
                            else 
                              if (lexer.matchField(name_chars)) {
                                matchField = true;
                              }
                              else {
                                continue ;
                              }
        }
        if (!matchField) {
          key = lexer.scanSymbol(parser.symbolTable);
          if (key == null) {
            token = lexer.token();
            if (token == JSONToken.RBRACE) {
              lexer.nextToken(JSONToken.COMMA);
              break ;
            }
            if (token == JSONToken.COMMA) {
              if (lexer.isEnabled(Feature.AllowArbitraryCommas)) {
                continue ;
              }
            }
          }
          if ("$ref" == key) {
            lexer.nextTokenWithColon(JSONToken.LITERAL_STRING);
            token = lexer.token();
            if (token == JSONToken.LITERAL_STRING) {
              String ref = lexer.stringVal();
              if ("@".equals(ref)) {
                object = context.object;
              }
              else 
                if ("..".equals(ref)) {
                  ParseContext parentContext = context.parent;
                  if (parentContext.object != null) {
                    object = parentContext.object;
                  }
                  else {
                    parser.addResolveTask(new ResolveTask(parentContext, ref));
                    parser.resolveStatus = DefaultJSONParser.NeedToResolve;
                  }
                }
                else 
                  if ("$".equals(ref)) {
                    ParseContext rootContext = context;
                    while (rootContext.parent != null){
                      rootContext = rootContext.parent;
                    }
                    if (rootContext.object != null) {
                      object = rootContext.object;
                    }
                    else {
                      parser.addResolveTask(new ResolveTask(rootContext, ref));
                      parser.resolveStatus = DefaultJSONParser.NeedToResolve;
                    }
                  }
                  else {
                    parser.addResolveTask(new ResolveTask(context, ref));
                    parser.resolveStatus = DefaultJSONParser.NeedToResolve;
                  }
            }
            else {
              throw new JSONException("illegal ref, " + JSONToken.name(token));
            }
            lexer.nextToken(JSONToken.RBRACE);
            if (lexer.token() != JSONToken.RBRACE) {
              throw new JSONException("illegal ref");
            }
            lexer.nextToken(JSONToken.COMMA);
            parser.setContext(context, object, fieldName);
            return (T)object;
          }
          if (JSON.DEFAULT_TYPE_KEY == key) {
            lexer.nextTokenWithColon(JSONToken.LITERAL_STRING);
            if (lexer.token() == JSONToken.LITERAL_STRING) {
              String typeName = lexer.stringVal();
              lexer.nextToken(JSONToken.COMMA);
              if (typeName.equals(beanInfo.typeName) || parser.isEnabled(Feature.IgnoreType)) {
                if (lexer.token() == JSONToken.RBRACE) {
                  lexer.nextToken();
                  break ;
                }
                continue ;
              }
              ParserConfig config = parser.getConfig();
              ObjectDeserializer deserializer = getSeeAlso(config, this.beanInfo, typeName);
              Class<?> userType = null;
              if (deserializer == null) {
                Class<?> expectClass = TypeUtils.getClass(type);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\fastjson\revisions\rev_c76d44b_a12ff69\rev_left_c76d44b\src\main\java\com\alibaba\fastjson\parser\deserializer\JavaBeanDeserializer.java
userType = config.checkAutoType(typeName, expectClass);
=======
if (expectClass == null || (userType != null && expectClass.isAssignableFrom(userType))) {
                  deserializer = parser.getConfig().getDeserializer(userType);
                }
                else {
                  throw new JSONException("type not match");
                }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\fastjson\revisions\rev_c76d44b_a12ff69\rev_right_a12ff69\src\main\java\com\alibaba\fastjson\parser\deserializer\JavaBeanDeserializer.java

                deserizer = parser.getConfig().getDeserializer(userType);
              }
              return (T)deserizer.deserialze(parser, userType, fieldName);
            }
          }
        }
        if (object == null && fieldValues == null) {
          object = createInstance(parser, type);
          if (object == null) {
            fieldValues = new HashMap<String, Object>(this.fieldDeserializers.length);
          }
          childContext = parser.setContext(context, object, fieldName);
        }
        if (matchField) {
          if (!valueParsed) {
            fieldDeser.parseField(parser, object, type, fieldValues);
          }
          else {
            if (object == null) {
              fieldValues.put(fieldInfo.name, fieldValue);
            }
            else 
              if (fieldValue == null) {
                if (fieldClass != int.class && fieldClass != long.class && fieldClass != float.class && fieldClass != double.class && fieldClass != boolean.class) {
                  fieldDeser.setValue(object, fieldValue);
                }
              }
              else {
                fieldDeser.setValue(object, fieldValue);
              }
            if (lexer.matchStat == JSONLexer.END) {
              break ;
            }
          }
        }
        else {
          boolean match = parseField(parser, key, object, type, fieldValues, setFlags);
          if (!match) {
            if (lexer.token() == JSONToken.RBRACE) {
              lexer.nextToken();
              break ;
            }
            continue ;
          }
          else 
            if (lexer.token() == JSONToken.COLON) {
              throw new JSONException("syntax error, unexpect token \':\'");
            }
        }
        if (lexer.token() == JSONToken.COMMA) {
          continue ;
        }
        if (lexer.token() == JSONToken.RBRACE) {
          lexer.nextToken(JSONToken.COMMA);
          break ;
        }
        if (lexer.token() == JSONToken.IDENTIFIER || lexer.token() == JSONToken.ERROR) {
          throw new JSONException("syntax error, unexpect token " + JSONToken.name(lexer.token()));
        }
      }
      if (object == null) {
        if (fieldValues == null) {
          object = createInstance(parser, type);
          if (childContext == null) {
            childContext = parser.setContext(context, object, fieldName);
          }
          return (T)object;
        }
        FieldInfo[] fieldInfoList = beanInfo.fields;
        int size = fieldInfoList.length;
        Object[] params = new Object[size];
        for (int i = 0; i < size; ++i) {
          FieldInfo fieldInfo = fieldInfoList[i];
          Object param = fieldValues.get(fieldInfo.name);
          if (param == null) {
            Type fieldType = fieldInfo.fieldType;
            if (fieldType == byte.class) {
              param = (byte)0;
            }
            else 
              if (fieldType == short.class) {
                param = (short)0;
              }
              else 
                if (fieldType == int.class) {
                  param = 0;
                }
                else 
                  if (fieldType == long.class) {
                    param = 0L;
                  }
                  else 
                    if (fieldType == float.class) {
                      param = 0F;
                    }
                    else 
                      if (fieldType == double.class) {
                        param = 0D;
                      }
                      else 
                        if (fieldType == boolean.class) {
                          param = Boolean.FALSE;
                        }
          }
          params[i] = param;
        }
        if (beanInfo.creatorConstructor != null) {
          try {
            object = beanInfo.creatorConstructor.newInstance(params);
          }
          catch (Exception e) {
            throw new JSONException("create instance error, " + beanInfo.creatorConstructor.toGenericString(), e);
          }
        }
        else 
          if (beanInfo.factoryMethod != null) {
            try {
              object = beanInfo.factoryMethod.invoke(null, params);
            }
            catch (Exception e) {
              throw new JSONException("create factory method error, " + beanInfo.factoryMethod.toString(), e);
            }
          }
      }
      Method buildMethod = beanInfo.buildMethod;
      if (buildMethod == null) {
        return (T)object;
      }
      Object builtObj;
      try {
        builtObj = buildMethod.invoke(object);
      }
      catch (Exception e) {
        throw new JSONException("build object error", e);
      }
      return (T)builtObj;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_left_b33f815\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_base_f6bf40e\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_right_abf2ae4\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java
CONCLUSAO: FP. JDIME INTEGROU MÉTODOS COM O MESMO NOME, MAS ASSINATURAS DIFERENTES.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
onRelation(entity, relationsMap, relation, m, pd, lazilyloaded);
=======
if (relation.getType().equals(ForeignKey.MANY_TO_MANY)) {
        Field f = relation.getProperty();
        Object object = PropertyAccessorHelper.getObject(entity, f);
        final Object entityId = PropertyAccessorHelper.getId(entity, m);
        if (object != null && !ProxyHelper.isProxyCollection(object)) {
          PersistenceCacheManager.addEntityToPersistenceCache(entity, pd, entityId);
        }
        associationBuilder.populateRelationForM2M(entity, m, pd, relation, object, relationsMap);
      }
      else {
        onRelation(entity, relationsMap, relation, m, pd, lazilyloaded);
      }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void onRelation(final Object entity, final Map<String, Object> relationsMap, final EntityMetadata m, final PersistenceDelegator pd, Relation relation, ForeignKey relationType, boolean lazilyloaded) {
    FetchType fetchType = relation.getFetchType();
    if (relation.getType().equals(ForeignKey.MANY_TO_MANY)) {
      Field f = relation.getProperty();
      Object object = PropertyAccessorHelper.getObject(entity, f);
      final Object entityId = PropertyAccessorHelper.getId(entity, m);
      PersistenceCacheManager.addEntityToPersistenceCache(entity, pd, entityId);
      associationBuilder.populateRelationForM2M(entity, m, pd, relation, object, relationsMap);
    }
    else {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_left_b33f815\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java
onRelation(entity, relationsMap, relation, m, pd, lazilyloaded);
=======
if (relation.getType().equals(ForeignKey.MANY_TO_MANY)) {
        Field f = relation.getProperty();
        Object object = PropertyAccessorHelper.getObject(entity, f);
        final Object entityId = PropertyAccessorHelper.getId(entity, m);
        if (object != null && !ProxyHelper.isProxyCollection(object)) {
          PersistenceCacheManager.addEntityToPersistenceCache(entity, pd, entityId);
        }
        associationBuilder.populateRelationForM2M(entity, m, pd, relation, object, relationsMap);
      }
      else {
        onRelation(entity, relationsMap, relation, m, pd, lazilyloaded);
      }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_right_abf2ae4\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java

    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_left_b33f815\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_base_f6bf40e\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java,C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_right_abf2ae4\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
setRelationToEntity(relationEntity, originalEntity, relation);
=======
if (relation.getType().equals(ForeignKey.ONE_TO_ONE)) {
            if ((associationObject == null || ProxyHelper.isProxyOrCollection(associationObject))) {
              PropertyAccessorHelper.set(relationEntity, relation.getProperty(), originalEntity);
            }
          }
          else 
            if (relationsMap != null && relationsMap.containsKey(relation.getJoinColumnName())) {
              PropertyAccessorHelper.set(relationEntity, relation.getProperty(), originalEntity);
            }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void parseRelations(final Object originalEntity, final Object relationEntity, final Map<String, Object> relationsMap, final PersistenceDelegator pd, final EntityMetadata metadata, boolean lazilyloaded) {
    for (Relation relation : metadata.getRelations()) {
      FetchType fetchType = relation.getFetchType();
      if (relation.isUnary() && relation.getTargetEntity().isAssignableFrom(originalEntity.getClass())) {
        final Object associationObject = PropertyAccessorHelper.getObject(relationEntity, relation.getProperty());
        if (relation.getType().equals(ForeignKey.ONE_TO_ONE) || ((associationObject == null || ProxyHelper.isProxyOrCollection(associationObject)))) {
          PropertyAccessorHelper.set(relationEntity, relation.getProperty(), originalEntity);
        }
        else 
          if (relationsMap != null && relationsMap.containsKey(relation.getJoinColumnName())) {
            PropertyAccessorHelper.set(relationEntity, relation.getProperty(), originalEntity);
          }
      }
      else {
        final Object entityId = PropertyAccessorHelper.getId(relationEntity, metadata);
        Object relationValue = relationsMap != null ? relationsMap.get(relation.getJoinColumnName()) : null;
        final EntityMetadata targetEntityMetadata = KunderaMetadataManager.getEntityMetadata(relation.getTargetEntity());
        List immediateRelations = fetchRelations(relation, metadata, pd, entityId, relationValue, targetEntityMetadata);
        if (immediateRelations != null && !immediateRelations.isEmpty()) {
          for (Object immediateRelation : immediateRelations) {
            if (!compareTo(getEntity(immediateRelation), originalEntity)) {
              onParseRelation(relationEntity, pd, targetEntityMetadata, immediateRelation, relation, lazilyloaded);
            }
          }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_left_b33f815\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java
setRelationToEntity(relationEntity, originalEntity, relation);
=======
if (relation.getType().equals(ForeignKey.ONE_TO_ONE)) {
            if ((associationObject == null || ProxyHelper.isProxyOrCollection(associationObject))) {
              PropertyAccessorHelper.set(relationEntity, relation.getProperty(), originalEntity);
            }
          }
          else 
            if (relationsMap != null && relationsMap.containsKey(relation.getJoinColumnName())) {
              PropertyAccessorHelper.set(relationEntity, relation.getProperty(), originalEntity);
            }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\Kundera\revisions\rev_b33f815_abf2ae4\rev_right_abf2ae4\kundera-core\src\main\java\com\impetus\kundera\persistence\AbstractEntityReader.java

        }
      }
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_left_5b3c797\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_base_5608300\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_right_fb07a11\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (targetPath.equals(sourcePath)) {
          Utilities.LOG14535.info("MoveTask not moving LFD " + sourcePath);
        }
        else {
          Utilities.LOG14535.info("MoveTask moving LFD " + sourcePath + " to " + targetPath);
          if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
            assert lfd.getIsDfsDir();
            FileSystem srcFs = sourcePath.getFileSystem(conf);
            List<Path> newFiles = new ArrayList<>();
            Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
          }
          else {
            moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
          }
        }
=======
if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
          assert lfd.getIsDfsDir();
          FileSystem srcFs = sourcePath.getFileSystem(conf);
          List<Path> newFiles = new ArrayList<>();
          Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
        }
        else {
          moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
        }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public int execute(DriverContext driverContext) {
    if (work.isNoop()) 
      return 0;
    Utilities.LOG14535.info("Executing MoveWork " + System.identityHashCode(work) + " with " + work.getLoadFileWork() + "; " + work.getLoadTableWork() + "; " + work.getLoadMultiFilesWork());
    try {
      if (driverContext.getCtx().getExplainAnalyze() == AnalyzeState.RUNNING) {
        return 0;
      }
      Hive db = getHive();
      LoadFileDesc lfd = work.getLoadFileWork();
      if (lfd != null) {
        Path targetPath = lfd.getTargetDir();
        Path sourcePath = lfd.getSourcePath();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_left_5b3c797\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
if (targetPath.equals(sourcePath)) {
          Utilities.LOG14535.info("MoveTask not moving LFD " + sourcePath);
        }
        else {
          Utilities.LOG14535.info("MoveTask moving LFD " + sourcePath + " to " + targetPath);
          if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
            assert lfd.getIsDfsDir();
            FileSystem srcFs = sourcePath.getFileSystem(conf);
            List<Path> newFiles = new ArrayList<>();
            Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
          }
          else {
            moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
          }
        }
=======
if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
          assert lfd.getIsDfsDir();
          FileSystem srcFs = sourcePath.getFileSystem(conf);
          List<Path> newFiles = new ArrayList<>();
          Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
        }
        else {
          moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
        }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_right_fb07a11\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

      }
      LoadMultiFilesDesc lmfd = work.getLoadMultiFilesWork();
      if (lmfd != null) {
        boolean isDfsDir = lmfd.getIsDfsDir();
        List<String> targetPrefixes = lmfd.getTargetPrefixes();
        for (int i = 0; i < lmfd.getSourceDirs().size(); ++i) {
          Path srcPath = lmfd.getSourceDirs().get(i);
          Path destPath = lmfd.getTargetDirs().get(i);
          String filePrefix = targetPrefixes == null ? null : targetPrefixes.get(i);
          FileSystem destFs = destPath.getFileSystem(conf);
          if (filePrefix == null) {
            if (!destFs.exists(destPath.getParent())) {
              destFs.mkdirs(destPath.getParent());
            }
            Utilities.LOG14535.info("MoveTask moving LMFD " + srcPath + " to " + destPath);
            moveFile(srcPath, destPath, isDfsDir);
          }
          else {
            if (!destFs.exists(destPath)) {
              destFs.mkdirs(destPath);
            }
            FileSystem srcFs = srcPath.getFileSystem(conf);
            FileStatus[] children = srcFs.listStatus(srcPath);
            if (children != null) {
              for (FileStatus child : children) {
                Path childSrc = child.getPath();
                Path childDest = new Path(destPath, filePrefix + childSrc.getName());
                Utilities.LOG14535.info("MoveTask moving LMFD " + childSrc + " to " + childDest);
                moveFile(childSrc, childDest, isDfsDir);
              }
            }
            else {
              Utilities.LOG14535.info("MoveTask skipping empty directory LMFD " + srcPath);
            }
            if (!srcFs.delete(srcPath, false)) {
              throw new IOException("Couldn\'t delete " + srcPath + " after moving all the files");
            }
          }
        }
      }
      LoadTableDesc tbd = work.getLoadTableWork();
      if (tbd != null) {
        StringBuilder mesg = new StringBuilder("Loading data to table ").append(tbd.getTable().getTableName());
        if (tbd.getPartitionSpec().size() > 0) {
          mesg.append(" partition (");
          Map<String, String> partSpec = tbd.getPartitionSpec();
          for (String key : partSpec.keySet()) {
            mesg.append(key).append('=').append(partSpec.get(key)).append(", ");
          }
          mesg.setLength(mesg.length() - 2);
          mesg.append(')');
        }
        String mesg_detail = " from " + tbd.getSourcePath();
        Utilities.LOG14535.info("" + mesg.toString() + " " + mesg_detail);
        console.printInfo(mesg.toString(), mesg_detail);
        Table table = db.getTable(tbd.getTable().getTableName());
        checkFileFormats(db, tbd, table);
        boolean isFullAcidOp = work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID && !tbd.isMmTable();
        DataContainer dc = null;
        if (tbd.getPartitionSpec().size() == 0) {
          dc = new DataContainer(table.getTTable());
          Utilities.LOG14535.info("loadTable called from " + tbd.getSourcePath() + " into " + tbd.getTable().getTableName());
          if (tbd.isMmTable() && !tbd.isCommitMmWrite()) {
            throw new HiveException("Only single-partition LoadTableDesc can skip commiting write ID");
          }
          db.loadTable(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getReplace(), work.isSrcLocal(), isSkewedStoredAsDirs(tbd), isFullAcidOp, hasFollowingStatsTask(), tbd.getTxnId(), tbd.getStmtId(), tbd.isMmTable());
          if (work.getOutputs() != null) {
            DDLTask.addIfAbsentByName(new WriteEntity(table, getWriteType(tbd, work.getLoadTableWork().getWriteType())), work.getOutputs());
          }
        }
        else {
          LOG.info("Partition is: " + tbd.getPartitionSpec().toString());
          TaskInformation ti = new TaskInformation(this, tbd.getSourcePath().toUri().toString());
          inferTaskInformation(ti);
          DynamicPartitionCtx dpCtx = tbd.getDPCtx();
          if (dpCtx != null && dpCtx.getNumDPCols() > 0) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_left_5b3c797\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
dc = handleDynParts(db, table, tbd, ti, dpCtx);
=======
Map<Map<String, String>, Partition> dp = db.loadDynamicPartitions(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getPartitionSpec(), tbd.getReplace(), dpCtx.getNumDPCols(), isSkewedStoredAsDirs(tbd), work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID, work.getLoadTableWork().getCurrentTransactionId(), hasFollowingStatsTask(), work.getLoadTableWork().getWriteType());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_right_fb07a11\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_left_5b3c797\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
dc = handleDynParts(db, table, tbd, ti, dpCtx);
=======
for (Map.Entry<Map<String, String>, Partition> entry : dp.entrySet()) {
              Partition partn = entry.getValue();
              if (bucketCols != null || sortCols != null) {
                updatePartitionBucketSortColumns(db, table, partn, bucketCols, numBuckets, sortCols);
              }
              WriteEntity enty = new WriteEntity(partn, getWriteType(tbd, work.getLoadTableWork().getWriteType()));
              if (work.getOutputs() != null) {
                DDLTask.addIfAbsentByName(enty, work.getOutputs());
              }
              if (queryPlan.getOutputs() == null) {
                queryPlan.setOutputs(new LinkedHashSet<WriteEntity>());
              }
              queryPlan.getOutputs().add(enty);
              dc = new DataContainer(table.getTTable(), partn.getTPartition());
              if (work.getLineagState() != null && work.getLoadTableWork().getWriteType() != AcidUtils.Operation.DELETE && work.getLoadTableWork().getWriteType() != AcidUtils.Operation.UPDATE) {
                work.getLineagState().setLineage(tbd.getSourcePath(), dc, table.getCols());
              }
              LOG.info("\tLoading partition " + entry.getKey());
            }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_right_fb07a11\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

          }
        }
        if (SessionState.get() != null && dc != null) {
          List<FieldSchema> tableCols = null;
          switch (work.getLoadTableWork().getWriteType()){
            case DELETE:
            case UPDATE:
            tableCols = new ArrayList<FieldSchema>();
            break ;
            default:
            tableCols = table.getCols();
            break ;
          }
          SessionState.get().getLineageState().setLineage(tbd.getSourcePath(), dc, tableCols);
        }
        releaseLocks(tbd);
      }
      return 0;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_left_5b3c797\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_base_5608300\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_right_fb07a11\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (targetPath.equals(sourcePath)) {
          Utilities.LOG14535.info("MoveTask not moving LFD " + sourcePath);
        }
        else {
          Utilities.LOG14535.info("MoveTask moving LFD " + sourcePath + " to " + targetPath);
          if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
            assert lfd.getIsDfsDir();
            FileSystem srcFs = sourcePath.getFileSystem(conf);
            List<Path> newFiles = new ArrayList<>();
            Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
          }
          else {
            moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
          }
        }
=======
if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
          assert lfd.getIsDfsDir();
          FileSystem srcFs = sourcePath.getFileSystem(conf);
          List<Path> newFiles = new ArrayList<>();
          Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
        }
        else {
          moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
        }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public int execute(DriverContext driverContext) {
    if (work.isNoop()) 
      return 0;
    Utilities.LOG14535.info("Executing MoveWork " + System.identityHashCode(work) + " with " + work.getLoadFileWork() + "; " + work.getLoadTableWork() + "; " + work.getLoadMultiFilesWork());
    try {
      if (driverContext.getCtx().getExplainAnalyze() == AnalyzeState.RUNNING) {
        return 0;
      }
      Hive db = getHive();
      LoadFileDesc lfd = work.getLoadFileWork();
      if (lfd != null) {
        Path targetPath = lfd.getTargetDir();
        Path sourcePath = lfd.getSourcePath();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_left_5b3c797\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
if (targetPath.equals(sourcePath)) {
          Utilities.LOG14535.info("MoveTask not moving LFD " + sourcePath);
        }
        else {
          Utilities.LOG14535.info("MoveTask moving LFD " + sourcePath + " to " + targetPath);
          if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
            assert lfd.getIsDfsDir();
            FileSystem srcFs = sourcePath.getFileSystem(conf);
            List<Path> newFiles = new ArrayList<>();
            Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
          }
          else {
            moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
          }
        }
=======
if (lfd.getWriteType() == AcidUtils.Operation.INSERT) {
          assert lfd.getIsDfsDir();
          FileSystem srcFs = sourcePath.getFileSystem(conf);
          List<Path> newFiles = new ArrayList<>();
          Hive.moveAcidFiles(srcFs, srcFs.globStatus(sourcePath), targetPath, newFiles);
        }
        else {
          moveFile(sourcePath, targetPath, lfd.getIsDfsDir());
        }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_right_fb07a11\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

      }
      LoadMultiFilesDesc lmfd = work.getLoadMultiFilesWork();
      if (lmfd != null) {
        boolean isDfsDir = lmfd.getIsDfsDir();
        List<String> targetPrefixes = lmfd.getTargetPrefixes();
        for (int i = 0; i < lmfd.getSourceDirs().size(); ++i) {
          Path srcPath = lmfd.getSourceDirs().get(i);
          Path destPath = lmfd.getTargetDirs().get(i);
          String filePrefix = targetPrefixes == null ? null : targetPrefixes.get(i);
          FileSystem destFs = destPath.getFileSystem(conf);
          if (filePrefix == null) {
            if (!destFs.exists(destPath.getParent())) {
              destFs.mkdirs(destPath.getParent());
            }
            Utilities.LOG14535.info("MoveTask moving LMFD " + srcPath + " to " + destPath);
            moveFile(srcPath, destPath, isDfsDir);
          }
          else {
            if (!destFs.exists(destPath)) {
              destFs.mkdirs(destPath);
            }
            FileSystem srcFs = srcPath.getFileSystem(conf);
            FileStatus[] children = srcFs.listStatus(srcPath);
            if (children != null) {
              for (FileStatus child : children) {
                Path childSrc = child.getPath();
                Path childDest = new Path(destPath, filePrefix + childSrc.getName());
                Utilities.LOG14535.info("MoveTask moving LMFD " + childSrc + " to " + childDest);
                moveFile(childSrc, childDest, isDfsDir);
              }
            }
            else {
              Utilities.LOG14535.info("MoveTask skipping empty directory LMFD " + srcPath);
            }
            if (!srcFs.delete(srcPath, false)) {
              throw new IOException("Couldn\'t delete " + srcPath + " after moving all the files");
            }
          }
        }
      }
      LoadTableDesc tbd = work.getLoadTableWork();
      if (tbd != null) {
        StringBuilder mesg = new StringBuilder("Loading data to table ").append(tbd.getTable().getTableName());
        if (tbd.getPartitionSpec().size() > 0) {
          mesg.append(" partition (");
          Map<String, String> partSpec = tbd.getPartitionSpec();
          for (String key : partSpec.keySet()) {
            mesg.append(key).append('=').append(partSpec.get(key)).append(", ");
          }
          mesg.setLength(mesg.length() - 2);
          mesg.append(')');
        }
        String mesg_detail = " from " + tbd.getSourcePath();
        Utilities.LOG14535.info("" + mesg.toString() + " " + mesg_detail);
        console.printInfo(mesg.toString(), mesg_detail);
        Table table = db.getTable(tbd.getTable().getTableName());
        checkFileFormats(db, tbd, table);
        boolean isFullAcidOp = work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID && !tbd.isMmTable();
        DataContainer dc = null;
        if (tbd.getPartitionSpec().size() == 0) {
          dc = new DataContainer(table.getTTable());
          Utilities.LOG14535.info("loadTable called from " + tbd.getSourcePath() + " into " + tbd.getTable().getTableName());
          if (tbd.isMmTable() && !tbd.isCommitMmWrite()) {
            throw new HiveException("Only single-partition LoadTableDesc can skip commiting write ID");
          }
          db.loadTable(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getReplace(), work.isSrcLocal(), isSkewedStoredAsDirs(tbd), isFullAcidOp, hasFollowingStatsTask(), tbd.getTxnId(), tbd.getStmtId(), tbd.isMmTable());
          if (work.getOutputs() != null) {
            DDLTask.addIfAbsentByName(new WriteEntity(table, getWriteType(tbd, work.getLoadTableWork().getWriteType())), work.getOutputs());
          }
        }
        else {
          LOG.info("Partition is: " + tbd.getPartitionSpec().toString());
          TaskInformation ti = new TaskInformation(this, tbd.getSourcePath().toUri().toString());
          inferTaskInformation(ti);
          DynamicPartitionCtx dpCtx = tbd.getDPCtx();
          if (dpCtx != null && dpCtx.getNumDPCols() > 0) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_left_5b3c797\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
dc = handleDynParts(db, table, tbd, ti, dpCtx);
=======
Map<Map<String, String>, Partition> dp = db.loadDynamicPartitions(tbd.getSourcePath(), tbd.getTable().getTableName(), tbd.getPartitionSpec(), tbd.getReplace(), dpCtx.getNumDPCols(), isSkewedStoredAsDirs(tbd), work.getLoadTableWork().getWriteType() != AcidUtils.Operation.NOT_ACID, work.getLoadTableWork().getCurrentTransactionId(), hasFollowingStatsTask(), work.getLoadTableWork().getWriteType());
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_right_fb07a11\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_left_5b3c797\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java
dc = handleDynParts(db, table, tbd, ti, dpCtx);
=======
for (Map.Entry<Map<String, String>, Partition> entry : dp.entrySet()) {
              Partition partn = entry.getValue();
              if (bucketCols != null || sortCols != null) {
                updatePartitionBucketSortColumns(db, table, partn, bucketCols, numBuckets, sortCols);
              }
              WriteEntity enty = new WriteEntity(partn, getWriteType(tbd, work.getLoadTableWork().getWriteType()));
              if (work.getOutputs() != null) {
                DDLTask.addIfAbsentByName(enty, work.getOutputs());
              }
              if (queryPlan.getOutputs() == null) {
                queryPlan.setOutputs(new LinkedHashSet<WriteEntity>());
              }
              queryPlan.getOutputs().add(enty);
              dc = new DataContainer(table.getTTable(), partn.getTPartition());
              if (work.getLineagState() != null && work.getLoadTableWork().getWriteType() != AcidUtils.Operation.DELETE && work.getLoadTableWork().getWriteType() != AcidUtils.Operation.UPDATE) {
                work.getLineagState().setLineage(tbd.getSourcePath(), dc, table.getCols());
              }
              LOG.info("\tLoading partition " + entry.getKey());
            }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_5b3c797_fb07a11\rev_right_fb07a11\ql\src\java\org\apache\hadoop\hive\ql\exec\MoveTask.java

          }
        }
        if (SessionState.get() != null && dc != null) {
          List<FieldSchema> tableCols = null;
          switch (work.getLoadTableWork().getWriteType()){
            case DELETE:
            case UPDATE:
            tableCols = new ArrayList<FieldSchema>();
            break ;
            default:
            tableCols = table.getCols();
            break ;
          }
          SessionState.get().getLineageState().setLineage(tbd.getSourcePath(), dc, tableCols);
        }
        releaseLocks(tbd);
      }
      return 0;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_left_f14e0b2\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java,C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_base_67178e0\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java,C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_right_f357d84\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
switch (inputFormatClass){
        case "org.apache.storm.sql.runtime.serde.json.JsonScheme":
        scheme = new JsonScheme(fieldNames);
        break ;
        case "org.apache.storm.sql.runtime.serde.json.TsvScheme":
        String delimiter = properties.getProperty("tsv.delimiter", "\t");
        scheme = new TsvScheme(fieldNames, delimiter.charAt(0));
        break ;
        case "org.apache.storm.sql.runtime.serde.json.CsvScheme":
        scheme = new CsvScheme(fieldNames);
        break ;
        case "org.apache.storm.sql.runtime.serde.avro.AvroScheme":
        String schemaString = properties.getProperty("avro.schema");
        Preconditions.checkArgument(isNotEmpty(schemaString), "avro.schema can not be empty");
        scheme = new AvroScheme(schemaString, fieldNames);
        break ;
        default:
        scheme = Utils.newInstance(inputFormatClass);
      }
=======
if (JsonScheme.class.getName().equals(inputFormatClass)) {
        scheme = new JsonScheme(fieldNames);
      }
      else 
        if (AvroScheme.class.getName().equals(inputFormatClass)) {
          String schemaString = properties.getProperty("input.avro.schema");
          Preconditions.checkArgument(isNotEmpty(schemaString), "input.avro.schema can not be empty");
          scheme = new AvroScheme(schemaString, fieldNames);
        }
        else {
          scheme = Utils.newInstance(inputFormatClass);
        }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static Scheme getScheme(String inputFormatClass, Properties properties, List<String> fieldNames) {
    Scheme scheme;
    if (isNotEmpty(inputFormatClass)) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_left_f14e0b2\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java
switch (inputFormatClass){
        case "org.apache.storm.sql.runtime.serde.json.JsonScheme":
        scheme = new JsonScheme(fieldNames);
        break ;
        case "org.apache.storm.sql.runtime.serde.json.TsvScheme":
        String delimiter = properties.getProperty("tsv.delimiter", "\t");
        scheme = new TsvScheme(fieldNames, delimiter.charAt(0));
        break ;
        case "org.apache.storm.sql.runtime.serde.json.CsvScheme":
        scheme = new CsvScheme(fieldNames);
        break ;
        case "org.apache.storm.sql.runtime.serde.avro.AvroScheme":
        String schemaString = properties.getProperty("avro.schema");
        Preconditions.checkArgument(isNotEmpty(schemaString), "avro.schema can not be empty");
        scheme = new AvroScheme(schemaString, fieldNames);
        break ;
        default:
        scheme = Utils.newInstance(inputFormatClass);
      }
=======
if (JsonScheme.class.getName().equals(inputFormatClass)) {
        scheme = new JsonScheme(fieldNames);
      }
      else 
        if (AvroScheme.class.getName().equals(inputFormatClass)) {
          String schemaString = properties.getProperty("input.avro.schema");
          Preconditions.checkArgument(isNotEmpty(schemaString), "input.avro.schema can not be empty");
          scheme = new AvroScheme(schemaString, fieldNames);
        }
        else {
          scheme = Utils.newInstance(inputFormatClass);
        }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_right_f357d84\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java

    }
    return scheme;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_left_f14e0b2\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java,C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_base_67178e0\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java,C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_right_f357d84\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
switch (outputFormatClass){
        case "org.apache.storm.sql.runtime.serde.json.JsonSerializer":
        serializer = new JsonSerializer(fieldNames);
        break ;
        case "org.apache.storm.sql.runtime.serde.json.TsvSerializer":
        String delimiter = properties.getProperty("tsv.delimiter", "\t");
        serializer = new TsvSerializer(fieldNames, delimiter.charAt(0));
        break ;
        case "org.apache.storm.sql.runtime.serde.json.CsvSerializer":
        serializer = new CsvSerializer(fieldNames);
        break ;
        case "org.apache.storm.sql.runtime.serde.avro.AvroSerializer":
        String schemaString = properties.getProperty("avro.schema");
        Preconditions.checkArgument(isNotEmpty(schemaString), "avro.schema can not be empty");
        serializer = new AvroSerializer(schemaString, fieldNames);
        break ;
        default:
        serializer = Utils.newInstance(outputFormatClass);
      }
=======
if (JsonSerializer.class.getName().equals(outputFormatClass)) {
        serializer = new JsonSerializer(fieldNames);
      }
      else 
        if (AvroSerializer.class.getName().equals(outputFormatClass)) {
          String schemaString = properties.getProperty("output.avro.schema");
          Preconditions.checkArgument(isNotEmpty(schemaString), "output.avro.schema can not be empty");
          serializer = new AvroSerializer(schemaString, fieldNames);
        }
        else {
          serializer = Utils.newInstance(outputFormatClass);
        }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static IOutputSerializer getSerializer(String outputFormatClass, Properties properties, List<String> fieldNames) {
    IOutputSerializer serializer;
    if (isNotEmpty(outputFormatClass)) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_left_f14e0b2\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java
switch (outputFormatClass){
        case "org.apache.storm.sql.runtime.serde.json.JsonSerializer":
        serializer = new JsonSerializer(fieldNames);
        break ;
        case "org.apache.storm.sql.runtime.serde.json.TsvSerializer":
        String delimiter = properties.getProperty("tsv.delimiter", "\t");
        serializer = new TsvSerializer(fieldNames, delimiter.charAt(0));
        break ;
        case "org.apache.storm.sql.runtime.serde.json.CsvSerializer":
        serializer = new CsvSerializer(fieldNames);
        break ;
        case "org.apache.storm.sql.runtime.serde.avro.AvroSerializer":
        String schemaString = properties.getProperty("avro.schema");
        Preconditions.checkArgument(isNotEmpty(schemaString), "avro.schema can not be empty");
        serializer = new AvroSerializer(schemaString, fieldNames);
        break ;
        default:
        serializer = Utils.newInstance(outputFormatClass);
      }
=======
if (JsonSerializer.class.getName().equals(outputFormatClass)) {
        serializer = new JsonSerializer(fieldNames);
      }
      else 
        if (AvroSerializer.class.getName().equals(outputFormatClass)) {
          String schemaString = properties.getProperty("output.avro.schema");
          Preconditions.checkArgument(isNotEmpty(schemaString), "output.avro.schema can not be empty");
          serializer = new AvroSerializer(schemaString, fieldNames);
        }
        else {
          serializer = Utils.newInstance(outputFormatClass);
        }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\storm\revisions\rev_f14e0b2_f357d84\rev_right_f357d84\external\sql\storm-sql-runtime\src\jvm\org\apache\storm\sql\runtime\utils\SerdeUtils.java

    }
    return serializer;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\auto\revisions\rev_658d11d_6520620\rev_left_658d11d\value\src\main\java\com\google\auto\value\processor\AutoValueProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\auto\revisions\rev_658d11d_6520620\rev_base_b6f51d9\value\src\main\java\com\google\auto\value\processor\AutoValueProcessor.java,C:\Users\user\Desktop\gjcc\amostra\projects\auto\revisions\rev_658d11d_6520620\rev_right_6520620\value\src\main\java\com\google\auto\value\processor\AutoValueProcessor.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (!appliedExtensions.isEmpty()) {
      final Set<String> methodsToRemove = Sets.newHashSet();
      for (int i = appliedExtensions.size() - 1; i >= 0; i--) {
        AutoValueExtension extension = appliedExtensions.get(i);
        methodsToRemove.addAll(extension.consumeProperties(context));
      }
      if (!methodsToRemove.isEmpty()) {
        context.setProperties(newImmutableBiMapRemovingKeys(properties, methodsToRemove));
        Set<ExecutableElement> newMethods = Sets.newLinkedHashSet(methods);
        for (java.util.Iterator<javax.lang.model.element.ExecutableElement> it = newMethods.iterator(); it.hasNext(); ) {
          if (methodsToRemove.contains(it.next().getSimpleName().toString())) {
            it.remove();
          }
        }
        methods = ImmutableSet.copyOf(newMethods);
      }
    }
=======
if (appliedExtensions.size() > 0) {
      final Set<String> methodsToRemove = Sets.newHashSet();
      for (int i = appliedExtensions.size() - 1; i >= 0; i--) {
        AutoValueExtension extension = appliedExtensions.get(i);
        methodsToRemove.addAll(extension.consumeProperties(context));
      }
      if (methodsToRemove.size() > 0) {
        context.setProperties(newImmutableBiMapRemovingKeys(properties, methodsToRemove));
        methods = newFilteredImmutableSet(methods, new Predicate<ExecutableElement>() {
            @Override public boolean apply(ExecutableElement executableElement) {
              return !methodsToRemove.contains(executableElement.getSimpleName().toString());
            }
        });
      }
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  private void processType(TypeElement type) {
    AutoValue autoValue = type.getAnnotation(AutoValue.class);
    if (autoValue == null) {
      errorReporter.abortWithError("annotation processor for @AutoValue was invoked with a type" + " that does not have that annotation; this is probably a compiler bug", type);
    }
    if (type.getKind() != ElementKind.CLASS) {
      errorReporter.abortWithError("@" + AutoValue.class.getName() + " only applies to classes", type);
    }
    if (ancestorIsAutoValue(type)) {
      errorReporter.abortWithError("One @AutoValue class may not extend another", type);
    }
    if (implementsAnnotation(type)) {
      errorReporter.abortWithError("@AutoValue may not be used to implement an annotation" + " interface; try using @AutoAnnotation instead", type);
    }
    checkTopLevelOrStatic(type);
    ImmutableSet<ExecutableElement> methods = getLocalAndInheritedMethods(type, processingEnv.getElementUtils());
    ImmutableSet<ExecutableElement> methodsToImplement = methodsToImplement(type, methods);
    ImmutableBiMap<String, ExecutableElement> properties = propertyNameToMethodMap(methodsToImplement);
    String fqExtClass = TypeSimplifier.classNameOf(type);
    List<AutoValueExtension> appliedExtensions = new ArrayList<AutoValueExtension>();
    ExtensionContext context = new ExtensionContext(processingEnv, type, properties);
    for (AutoValueExtension extension : extensions) {
      if (extension.applicable(context)) {
        if (extension.mustBeFinal(context)) {
          appliedExtensions.add(0, extension);
        }
        else {
          appliedExtensions.add(extension);
        }
      }
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\auto\revisions\rev_658d11d_6520620\rev_left_658d11d\value\src\main\java\com\google\auto\value\processor\AutoValueProcessor.java
if (!appliedExtensions.isEmpty()) {
      final Set<String> methodsToRemove = Sets.newHashSet();
      for (int i = appliedExtensions.size() - 1; i >= 0; i--) {
        AutoValueExtension extension = appliedExtensions.get(i);
        methodsToRemove.addAll(extension.consumeProperties(context));
      }
      if (!methodsToRemove.isEmpty()) {
        context.setProperties(newImmutableBiMapRemovingKeys(properties, methodsToRemove));
        Set<ExecutableElement> newMethods = Sets.newLinkedHashSet(methods);
        for (java.util.Iterator<javax.lang.model.element.ExecutableElement> it = newMethods.iterator(); it.hasNext(); ) {
          if (methodsToRemove.contains(it.next().getSimpleName().toString())) {
            it.remove();
          }
        }
        methods = ImmutableSet.copyOf(newMethods);
      }
    }
=======
if (appliedExtensions.size() > 0) {
      final Set<String> methodsToRemove = Sets.newHashSet();
      for (int i = appliedExtensions.size() - 1; i >= 0; i--) {
        AutoValueExtension extension = appliedExtensions.get(i);
        methodsToRemove.addAll(extension.consumeProperties(context));
      }
      if (methodsToRemove.size() > 0) {
        context.setProperties(newImmutableBiMapRemovingKeys(properties, methodsToRemove));
        methods = newFilteredImmutableSet(methods, new Predicate<ExecutableElement>() {
            @Override public boolean apply(ExecutableElement executableElement) {
              return !methodsToRemove.contains(executableElement.getSimpleName().toString());
            }
        });
      }
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\auto\revisions\rev_658d11d_6520620\rev_right_6520620\value\src\main\java\com\google\auto\value\processor\AutoValueProcessor.java

    String finalSubclass = generatedSubclassName(type, 0);
    String subclass = generatedSubclassName(type, appliedExtensions.size());
    AutoValueTemplateVars vars = new AutoValueTemplateVars();
    vars.pkg = TypeSimplifier.packageNameOf(type);
    vars.origClass = fqExtClass;
    vars.simpleClassName = TypeSimplifier.simpleNameOf(vars.origClass);
    vars.subclass = TypeSimplifier.simpleNameOf(subclass);
    vars.finalSubclass = TypeSimplifier.simpleNameOf(finalSubclass);
    vars.isFinal = appliedExtensions.isEmpty();
    vars.types = processingEnv.getTypeUtils();
    defineVarsForType(type, vars, methods);
    GwtCompatibility gwtCompatibility = new GwtCompatibility(type);
    vars.gwtCompatibleAnnotation = gwtCompatibility.gwtCompatibleAnnotationString();
    String text = vars.toText();
    text = Reformatter.fixup(text);
    writeSourceFile(subclass, text, type);
    GwtSerialization gwtSerialization = new GwtSerialization(gwtCompatibility, processingEnv, type);
    gwtSerialization.maybeWriteGwtSerializer(vars);
    String extClass = TypeSimplifier.simpleNameOf(subclass);
    for (int i = appliedExtensions.size() - 1; i >= 0; i--) {
      AutoValueExtension extension = appliedExtensions.remove(i);
      String fqClassName = generatedSubclassName(type, i);
      String className = TypeSimplifier.simpleNameOf(fqClassName);
      boolean isFinal = (i == 0);
      String source = extension.generateClass(context, className, extClass, isFinal);
      if (source == null || source.isEmpty()) {
        errorReporter.reportError("Extension returned no source code.", type);
        return ;
      }
      source = Reformatter.fixup(source);
      writeSourceFile(fqClassName, source, type);
      extClass = className;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_left_f389e91\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\DownsamplerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_base_2c5f63e\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\DownsamplerTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_right_431ccaf\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\DownsamplerTest.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
options
=======
DecodeFormat.PREFER_ARGB_8888
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Test public void testAlwaysArgb8888() throws FileNotFoundException {
    Bitmap rgb565 = Bitmap.createBitmap(100, 100, Bitmap.Config.RGB_565);
    compressBitmap(rgb565, Bitmap.CompressFormat.JPEG);
    Downsampler downsampler = Downsampler.AT_LEAST;
    InputStream is = new FileInputStream(tempFile);
    options.put(Downsampler.KEY_DECODE_FORMAT, DecodeFormat.ALWAYS_ARGB_8888);
    try {
      Bitmap result = downsampler.decode(is, mock(BitmapPool.class), 100, 100, 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_left_f389e91\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\DownsamplerTest.java
options
=======
DecodeFormat.PREFER_ARGB_8888
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_right_431ccaf\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\DownsamplerTest.java
);
      assertEquals(Bitmap.Config.ARGB_8888, result.getConfig());
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_left_f389e91\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\VideoBitmapDecoderTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_base_2c5f63e\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\VideoBitmapDecoderTest.java,C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_right_431ccaf\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\VideoBitmapDecoderTest.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
resource = mock(ParcelFileDescriptor.class);
=======
decodeFormat = DecodeFormat.PREFER_ARGB_8888;
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Before public void setup() {
    bitmapPool = mock(BitmapPool.class);
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_left_f389e91\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\VideoBitmapDecoderTest.java
resource = mock(ParcelFileDescriptor.class);
=======
decodeFormat = DecodeFormat.PREFER_ARGB_8888;
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\glide\revisions\rev_f389e91_431ccaf\rev_right_431ccaf\library\src\androidTest\java\com\bumptech\glide\load\resource\bitmap\VideoBitmapDecoderTest.java

    factory = mock(VideoBitmapDecoder.MediaMetadataRetrieverFactory.class);
    retriever = mock(MediaMetadataRetriever.class);
    when(factory.build()).thenReturn(retriever);
    decoder = new VideoBitmapDecoder(new VideoBitmapDecoder.MediaMetadataRetrieverFactory() {
        @Override public MediaMetadataRetriever build() {
          return factory.build();
        }
    });
    options = new HashMap<>();
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_left_36aa3e9\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_base_5e223d4\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_right_35a7a81\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
advanceToNextRow(reader, rowInStripe + rowBaseInStripe, true);
=======
try {
      final Object result = reader.next(previous);
      rowInStripe += 1;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      if (isLogTraceEnabled) {
        LOG.trace("row from " + reader.path);
        LOG.trace("orc row = " + result);
      }
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public Object next(Object previous) throws IOException {
    try {
      final Object result = reader.next(previous);
      rowInStripe += 1;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      if (isLogTraceEnabled) {
        LOG.trace("row from " + reader.path);
        LOG.trace("orc row = " + result);
      }
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_left_36aa3e9\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
advanceToNextRow(reader, rowInStripe + rowBaseInStripe, true);
=======
try {
      final Object result = reader.next(previous);
      rowInStripe += 1;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      if (isLogTraceEnabled) {
        LOG.trace("row from " + reader.path);
        LOG.trace("orc row = " + result);
      }
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_right_35a7a81\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java

    advanceToNextRow(reader, rowInStripe + rowBaseInStripe, true);
    return result;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_left_36aa3e9\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_base_5e223d4\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_right_35a7a81\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
long batchSize = computeBatchSize(VectorizedRowBatch.DEFAULT_SIZE);
=======
try {
      final VectorizedRowBatch result;
      if (rowInStripe >= rowCountInStripe) {
        currentStripe += 1;
        readStripe();
      }
      long batchSize = 0;
      if (rowIndexStride != 0 && includedRowGroups != null && rowInStripe < rowCountInStripe) {
        int startRowGroup = (int)(rowInStripe / rowIndexStride);
        if (!includedRowGroups[startRowGroup]) {
          while (startRowGroup < includedRowGroups.length && !includedRowGroups[startRowGroup]){
            startRowGroup += 1;
          }
        }
        int endRowGroup = startRowGroup;
        while (endRowGroup < includedRowGroups.length && includedRowGroups[endRowGroup]){
          endRowGroup += 1;
        }
        final long markerPosition = (endRowGroup * rowIndexStride) < rowCountInStripe ? (endRowGroup * rowIndexStride) : rowCountInStripe;
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (markerPosition - rowInStripe));
        if (isLogDebugEnabled && batchSize < VectorizedRowBatch.DEFAULT_SIZE) {
          LOG.debug("markerPosition: " + markerPosition + " batchSize: " + batchSize);
        }
      }
      else {
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (rowCountInStripe - rowInStripe));
      }
      rowInStripe += batchSize;
      if (previous == null) {
        ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
        result = new VectorizedRowBatch(cols.length);
        result.cols = cols;
      }
      else {
        result = previous;
        result.selectedInUse = false;
        reader.nextVector(result.cols, (int)batchSize);
      }
      result.size = (int)batchSize;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public VectorizedRowBatch nextBatch(VectorizedRowBatch previous) throws IOException {
    try {
      final VectorizedRowBatch result;
      if (rowInStripe >= rowCountInStripe) {
        currentStripe += 1;
        readStripe();
      }
      long batchSize = 0;
      if (rowIndexStride != 0 && includedRowGroups != null && rowInStripe < rowCountInStripe) {
        int startRowGroup = (int)(rowInStripe / rowIndexStride);
        if (!includedRowGroups[startRowGroup]) {
          while (startRowGroup < includedRowGroups.length && !includedRowGroups[startRowGroup]){
            startRowGroup += 1;
          }
        }
        int endRowGroup = startRowGroup;
        while (endRowGroup < includedRowGroups.length && includedRowGroups[endRowGroup]){
          endRowGroup += 1;
        }
        final long markerPosition = (endRowGroup * rowIndexStride) < rowCountInStripe ? (endRowGroup * rowIndexStride) : rowCountInStripe;
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (markerPosition - rowInStripe));
        if (isLogDebugEnabled && batchSize < VectorizedRowBatch.DEFAULT_SIZE) {
          LOG.debug("markerPosition: " + markerPosition + " batchSize: " + batchSize);
        }
      }
      else {
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (rowCountInStripe - rowInStripe));
      }
      rowInStripe += batchSize;
      if (previous == null) {
        ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
        result = new VectorizedRowBatch(cols.length);
        result.cols = cols;
      }
      else {
        result = previous;
        result.selectedInUse = false;
        reader.nextVector(result.cols, (int)batchSize);
      }
      result.size = (int)batchSize;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_left_36aa3e9\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
long batchSize = computeBatchSize(VectorizedRowBatch.DEFAULT_SIZE);
=======
try {
      final VectorizedRowBatch result;
      if (rowInStripe >= rowCountInStripe) {
        currentStripe += 1;
        readStripe();
      }
      long batchSize = 0;
      if (rowIndexStride != 0 && includedRowGroups != null && rowInStripe < rowCountInStripe) {
        int startRowGroup = (int)(rowInStripe / rowIndexStride);
        if (!includedRowGroups[startRowGroup]) {
          while (startRowGroup < includedRowGroups.length && !includedRowGroups[startRowGroup]){
            startRowGroup += 1;
          }
        }
        int endRowGroup = startRowGroup;
        while (endRowGroup < includedRowGroups.length && includedRowGroups[endRowGroup]){
          endRowGroup += 1;
        }
        final long markerPosition = (endRowGroup * rowIndexStride) < rowCountInStripe ? (endRowGroup * rowIndexStride) : rowCountInStripe;
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (markerPosition - rowInStripe));
        if (isLogDebugEnabled && batchSize < VectorizedRowBatch.DEFAULT_SIZE) {
          LOG.debug("markerPosition: " + markerPosition + " batchSize: " + batchSize);
        }
      }
      else {
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (rowCountInStripe - rowInStripe));
      }
      rowInStripe += batchSize;
      if (previous == null) {
        ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
        result = new VectorizedRowBatch(cols.length);
        result.cols = cols;
      }
      else {
        result = previous;
        result.selectedInUse = false;
        reader.nextVector(result.cols, (int)batchSize);
      }
      result.size = (int)batchSize;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_right_35a7a81\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_left_36aa3e9\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
advanceToNextRow(reader, rowInStripe + rowBaseInStripe, true);
=======
try {
      final VectorizedRowBatch result;
      if (rowInStripe >= rowCountInStripe) {
        currentStripe += 1;
        readStripe();
      }
      long batchSize = 0;
      if (rowIndexStride != 0 && includedRowGroups != null && rowInStripe < rowCountInStripe) {
        int startRowGroup = (int)(rowInStripe / rowIndexStride);
        if (!includedRowGroups[startRowGroup]) {
          while (startRowGroup < includedRowGroups.length && !includedRowGroups[startRowGroup]){
            startRowGroup += 1;
          }
        }
        int endRowGroup = startRowGroup;
        while (endRowGroup < includedRowGroups.length && includedRowGroups[endRowGroup]){
          endRowGroup += 1;
        }
        final long markerPosition = (endRowGroup * rowIndexStride) < rowCountInStripe ? (endRowGroup * rowIndexStride) : rowCountInStripe;
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (markerPosition - rowInStripe));
        if (isLogDebugEnabled && batchSize < VectorizedRowBatch.DEFAULT_SIZE) {
          LOG.debug("markerPosition: " + markerPosition + " batchSize: " + batchSize);
        }
      }
      else {
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (rowCountInStripe - rowInStripe));
      }
      rowInStripe += batchSize;
      if (previous == null) {
        ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
        result = new VectorizedRowBatch(cols.length);
        result.cols = cols;
      }
      else {
        result = previous;
        result.selectedInUse = false;
        reader.nextVector(result.cols, (int)batchSize);
      }
      result.size = (int)batchSize;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_right_35a7a81\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java

    rowInStripe += batchSize;
    if (previous == null) {
      ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
      result = new VectorizedRowBatch(cols.length);
      result.cols = cols;
    }
    else {
      result = (VectorizedRowBatch)previous;
      result.selectedInUse = false;
      reader.nextVector(result.cols, (int)batchSize);
    }
    result.size = (int)batchSize;
    advanceToNextRow(reader, rowInStripe + rowBaseInStripe, true);
    return result;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_left_36aa3e9\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_base_5e223d4\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java,C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_right_35a7a81\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
advanceToNextRow(reader, rowInStripe + rowBaseInStripe, true);
=======
try {
      final VectorizedRowBatch result;
      if (rowInStripe >= rowCountInStripe) {
        currentStripe += 1;
        readStripe();
      }
      long batchSize = 0;
      if (rowIndexStride != 0 && includedRowGroups != null && rowInStripe < rowCountInStripe) {
        int startRowGroup = (int)(rowInStripe / rowIndexStride);
        if (!includedRowGroups[startRowGroup]) {
          while (startRowGroup < includedRowGroups.length && !includedRowGroups[startRowGroup]){
            startRowGroup += 1;
          }
        }
        int endRowGroup = startRowGroup;
        while (endRowGroup < includedRowGroups.length && includedRowGroups[endRowGroup]){
          endRowGroup += 1;
        }
        final long markerPosition = (endRowGroup * rowIndexStride) < rowCountInStripe ? (endRowGroup * rowIndexStride) : rowCountInStripe;
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (markerPosition - rowInStripe));
        if (isLogDebugEnabled && batchSize < VectorizedRowBatch.DEFAULT_SIZE) {
          LOG.debug("markerPosition: " + markerPosition + " batchSize: " + batchSize);
        }
      }
      else {
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (rowCountInStripe - rowInStripe));
      }
      rowInStripe += batchSize;
      if (previous == null) {
        ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
        result = new VectorizedRowBatch(cols.length);
        result.cols = cols;
      }
      else {
        result = previous;
        result.selectedInUse = false;
        reader.nextVector(result.cols, (int)batchSize);
      }
      result.size = (int)batchSize;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  @Override public VectorizedRowBatch nextBatch(VectorizedRowBatch previous) throws IOException {
    try {
      final VectorizedRowBatch result;
      if (rowInStripe >= rowCountInStripe) {
        currentStripe += 1;
        readStripe();
      }
      long batchSize = 0;
      if (rowIndexStride != 0 && includedRowGroups != null && rowInStripe < rowCountInStripe) {
        int startRowGroup = (int)(rowInStripe / rowIndexStride);
        if (!includedRowGroups[startRowGroup]) {
          while (startRowGroup < includedRowGroups.length && !includedRowGroups[startRowGroup]){
            startRowGroup += 1;
          }
        }
        int endRowGroup = startRowGroup;
        while (endRowGroup < includedRowGroups.length && includedRowGroups[endRowGroup]){
          endRowGroup += 1;
        }
        final long markerPosition = (endRowGroup * rowIndexStride) < rowCountInStripe ? (endRowGroup * rowIndexStride) : rowCountInStripe;
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (markerPosition - rowInStripe));
        if (isLogDebugEnabled && batchSize < VectorizedRowBatch.DEFAULT_SIZE) {
          LOG.debug("markerPosition: " + markerPosition + " batchSize: " + batchSize);
        }
      }
      else {
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (rowCountInStripe - rowInStripe));
      }
      rowInStripe += batchSize;
      if (previous == null) {
        ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
        result = new VectorizedRowBatch(cols.length);
        result.cols = cols;
      }
      else {
        result = previous;
        result.selectedInUse = false;
        reader.nextVector(result.cols, (int)batchSize);
      }
      result.size = (int)batchSize;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_left_36aa3e9\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
long batchSize = computeBatchSize(VectorizedRowBatch.DEFAULT_SIZE);
=======
try {
      final VectorizedRowBatch result;
      if (rowInStripe >= rowCountInStripe) {
        currentStripe += 1;
        readStripe();
      }
      long batchSize = 0;
      if (rowIndexStride != 0 && includedRowGroups != null && rowInStripe < rowCountInStripe) {
        int startRowGroup = (int)(rowInStripe / rowIndexStride);
        if (!includedRowGroups[startRowGroup]) {
          while (startRowGroup < includedRowGroups.length && !includedRowGroups[startRowGroup]){
            startRowGroup += 1;
          }
        }
        int endRowGroup = startRowGroup;
        while (endRowGroup < includedRowGroups.length && includedRowGroups[endRowGroup]){
          endRowGroup += 1;
        }
        final long markerPosition = (endRowGroup * rowIndexStride) < rowCountInStripe ? (endRowGroup * rowIndexStride) : rowCountInStripe;
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (markerPosition - rowInStripe));
        if (isLogDebugEnabled && batchSize < VectorizedRowBatch.DEFAULT_SIZE) {
          LOG.debug("markerPosition: " + markerPosition + " batchSize: " + batchSize);
        }
      }
      else {
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (rowCountInStripe - rowInStripe));
      }
      rowInStripe += batchSize;
      if (previous == null) {
        ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
        result = new VectorizedRowBatch(cols.length);
        result.cols = cols;
      }
      else {
        result = previous;
        result.selectedInUse = false;
        reader.nextVector(result.cols, (int)batchSize);
      }
      result.size = (int)batchSize;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_right_35a7a81\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java

<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_left_36aa3e9\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java
advanceToNextRow(reader, rowInStripe + rowBaseInStripe, true);
=======
try {
      final VectorizedRowBatch result;
      if (rowInStripe >= rowCountInStripe) {
        currentStripe += 1;
        readStripe();
      }
      long batchSize = 0;
      if (rowIndexStride != 0 && includedRowGroups != null && rowInStripe < rowCountInStripe) {
        int startRowGroup = (int)(rowInStripe / rowIndexStride);
        if (!includedRowGroups[startRowGroup]) {
          while (startRowGroup < includedRowGroups.length && !includedRowGroups[startRowGroup]){
            startRowGroup += 1;
          }
        }
        int endRowGroup = startRowGroup;
        while (endRowGroup < includedRowGroups.length && includedRowGroups[endRowGroup]){
          endRowGroup += 1;
        }
        final long markerPosition = (endRowGroup * rowIndexStride) < rowCountInStripe ? (endRowGroup * rowIndexStride) : rowCountInStripe;
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (markerPosition - rowInStripe));
        if (isLogDebugEnabled && batchSize < VectorizedRowBatch.DEFAULT_SIZE) {
          LOG.debug("markerPosition: " + markerPosition + " batchSize: " + batchSize);
        }
      }
      else {
        batchSize = Math.min(VectorizedRowBatch.DEFAULT_SIZE, (rowCountInStripe - rowInStripe));
      }
      rowInStripe += batchSize;
      if (previous == null) {
        ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
        result = new VectorizedRowBatch(cols.length);
        result.cols = cols;
      }
      else {
        result = previous;
        result.selectedInUse = false;
        reader.nextVector(result.cols, (int)batchSize);
      }
      result.size = (int)batchSize;
      advanceToNextRow(rowInStripe + rowBaseInStripe);
      return result;
    }
    catch (IOException e) {
      throw new IOException("Error reading file: " + path, e);
    }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\hive\revisions\rev_36aa3e9_35a7a81\rev_right_35a7a81\ql\src\java\org\apache\hadoop\hive\ql\io\orc\RecordReaderImpl.java

    rowInStripe += batchSize;
    if (previous == null) {
      ColumnVector[] cols = (ColumnVector[])reader.nextVector(null, (int)batchSize);
      result = new VectorizedRowBatch(cols.length);
      result.cols = cols;
    }
    else {
      result = (VectorizedRowBatch)previous;
      result.selectedInUse = false;
      reader.nextVector(result.cols, (int)batchSize);
    }
    result.size = (int)batchSize;
    advanceToNextRow(reader, rowInStripe + rowBaseInStripe, true);
    return result;
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_01e5d5b_e443529\rev_left_01e5d5b\core\src\processing\core\PSurfaceAWT.java,C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_01e5d5b_e443529\rev_base_194e6f2\core\src\processing\core\PSurfaceAWT.java,C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_01e5d5b_e443529\rev_right_e443529\core\src\processing\core\PSurfaceAWT.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
setFrameSize();
=======
frame.setLocationRelativeTo(null);
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public void setSize(int wide, int high) {
    sketchWidth = wide;
    sketchHeight = high;
    if (frame != null) {
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_01e5d5b_e443529\rev_left_01e5d5b\core\src\processing\core\PSurfaceAWT.java
setFrameSize();
=======
frame.setLocationRelativeTo(null);
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\processing\revisions\rev_01e5d5b_e443529\rev_right_e443529\core\src\processing\core\PSurfaceAWT.java

    }
    setCanvasSize();
    GraphicsConfiguration gc = canvas.getGraphicsConfiguration();
    if (gc == null) {
      System.err.println("GraphicsConfiguration null in setSize()");
      GraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();
      gc = ge.getDefaultScreenDevice().getDefaultConfiguration();
    }
    int factor = graphics.pixelFactor;
    graphics.image = gc.createCompatibleImage(wide * factor, high * factor);
    sketch.width = wide;
    sketch.height = high;
    graphics.setSize(wide, high);
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_base_472e913\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
CONCLUSAO: MESMO CONFLITO, DIFERENTE TEXTO SSMERGE.
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
p1 = b1.position()
=======
result
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static final int compare(ByteBuffer b1, ByteBuffer b2) {
    if (b1 == b2) {
      return 0;
    }
    int ia = 0;
    int ib = 0;
    int 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p1 = b1.position()
=======
result
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
, p2 = b2.position();
    while (p1 < b1.limit() || p2 < b2.limit()){
      boolean aHasRemaining = ia + a.position() < a.limit();
      boolean bHasRemaining = ib + b.position() < b.limit();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
if (p1 >= b1.limit()) 
        return -1;
      else 
        if (p2 >= b2.limit()) 
          return 1;
        else {
          byte c1 = b1.get(), c2 = b2.get();
          if (c1 != c2) {
            if (c1 >= 0 && c2 >= 0) {
              if (c1 < c2) 
                return -1;
              else 
                if (c1 > c2) {
                  return 1;
                }
            }
            else 
              if (c1 < 0 && c2 < 0) {
                if (c1 < c2) 
                  return -1;
                else 
                  if (c1 > c2) {
                    return 1;
                  }
              }
              else 
                if (c1 >= 0 && c2 < 0) 
                  return -1;
                else 
                  return 1;
          }
        }
=======
if (!aHasRemaining && bHasRemaining) {
        result = -1;
        break ;
      }
      else 
        if (aHasRemaining && bHasRemaining) {
          byte ca = a.get(a.position() + ia), cb = b.get(b.position() + ib);
          if (ca != cb) {
            if (ca >= 0 && cb >= 0) {
              if (ca < cb) {
                result = -1;
                break ;
              }
              else 
                if (ca > cb) {
                  result = 1;
                  break ;
                }
            }
            else 
              if (ca < 0 && cb < 0) {
                if (ca < cb) {
                  result = -1;
                  break ;
                }
                else 
                  if (ca > cb) {
                    result = 1;
                    break ;
                  }
              }
              else 
                if (ca >= 0 && cb < 0) {
                  result = -1;
                  break ;
                }
                else {
                  result = 1;
                  break ;
                }
          }
        }
        else 
          if (aHasRemaining && !bHasRemaining) {
            result = 1;
            break ;
          }
          else {
            result = 0;
            break ;
          }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java

      
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p1
=======
ia
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
++;
      
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p2
=======
ib
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
++;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_base_472e913\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
if (p1 >= b1.limit()) 
        return -1;
      else 
        if (p2 >= b2.limit()) 
          return 1;
        else {
          byte c1 = b1.get(), c2 = b2.get();
          if (c1 != c2) {
            if (c1 >= 0 && c2 >= 0) {
              if (c1 < c2) 
                return -1;
              else 
                if (c1 > c2) {
                  return 1;
                }
            }
            else 
              if (c1 < 0 && c2 < 0) {
                if (c1 < c2) 
                  return -1;
                else 
                  if (c1 > c2) {
                    return 1;
                  }
              }
              else 
                if (c1 >= 0 && c2 < 0) 
                  return -1;
                else 
                  return 1;
          }
        }
=======
if (!aHasRemaining && bHasRemaining) {
        result = -1;
        break ;
      }
      else 
        if (aHasRemaining && bHasRemaining) {
          byte ca = a.get(a.position() + ia), cb = b.get(b.position() + ib);
          if (ca != cb) {
            if (ca >= 0 && cb >= 0) {
              if (ca < cb) {
                result = -1;
                break ;
              }
              else 
                if (ca > cb) {
                  result = 1;
                  break ;
                }
            }
            else 
              if (ca < 0 && cb < 0) {
                if (ca < cb) {
                  result = -1;
                  break ;
                }
                else 
                  if (ca > cb) {
                    result = 1;
                    break ;
                  }
              }
              else 
                if (ca >= 0 && cb < 0) {
                  result = -1;
                  break ;
                }
                else {
                  result = 1;
                  break ;
                }
          }
        }
        else 
          if (aHasRemaining && !bHasRemaining) {
            result = 1;
            break ;
          }
          else {
            result = 0;
            break ;
          }
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static final int compare(ByteBuffer b1, ByteBuffer b2) {
    if (b1 == b2) {
      return 0;
    }
    int ia = 0;
    int ib = 0;
    int 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p1 = b1.position()
=======
result
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
, p2 = b2.position();
    while (p1 < b1.limit() || p2 < b2.limit()){
      boolean aHasRemaining = ia + a.position() < a.limit();
      boolean bHasRemaining = ib + b.position() < b.limit();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
if (p1 >= b1.limit()) 
        return -1;
      else 
        if (p2 >= b2.limit()) 
          return 1;
        else {
          byte c1 = b1.get(), c2 = b2.get();
          if (c1 != c2) {
            if (c1 >= 0 && c2 >= 0) {
              if (c1 < c2) 
                return -1;
              else 
                if (c1 > c2) {
                  return 1;
                }
            }
            else 
              if (c1 < 0 && c2 < 0) {
                if (c1 < c2) 
                  return -1;
                else 
                  if (c1 > c2) {
                    return 1;
                  }
              }
              else 
                if (c1 >= 0 && c2 < 0) 
                  return -1;
                else 
                  return 1;
          }
        }
=======
if (!aHasRemaining && bHasRemaining) {
        result = -1;
        break ;
      }
      else 
        if (aHasRemaining && bHasRemaining) {
          byte ca = a.get(a.position() + ia), cb = b.get(b.position() + ib);
          if (ca != cb) {
            if (ca >= 0 && cb >= 0) {
              if (ca < cb) {
                result = -1;
                break ;
              }
              else 
                if (ca > cb) {
                  result = 1;
                  break ;
                }
            }
            else 
              if (ca < 0 && cb < 0) {
                if (ca < cb) {
                  result = -1;
                  break ;
                }
                else 
                  if (ca > cb) {
                    result = 1;
                    break ;
                  }
              }
              else 
                if (ca >= 0 && cb < 0) {
                  result = -1;
                  break ;
                }
                else {
                  result = 1;
                  break ;
                }
          }
        }
        else 
          if (aHasRemaining && !bHasRemaining) {
            result = 1;
            break ;
          }
          else {
            result = 0;
            break ;
          }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java

      
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p1
=======
ia
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
++;
      
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p2
=======
ib
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
++;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_base_472e913\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
p1
=======
ia
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static final int compare(ByteBuffer b1, ByteBuffer b2) {
    if (b1 == b2) {
      return 0;
    }
    int ia = 0;
    int ib = 0;
    int 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p1 = b1.position()
=======
result
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
, p2 = b2.position();
    while (p1 < b1.limit() || p2 < b2.limit()){
      boolean aHasRemaining = ia + a.position() < a.limit();
      boolean bHasRemaining = ib + b.position() < b.limit();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
if (p1 >= b1.limit()) 
        return -1;
      else 
        if (p2 >= b2.limit()) 
          return 1;
        else {
          byte c1 = b1.get(), c2 = b2.get();
          if (c1 != c2) {
            if (c1 >= 0 && c2 >= 0) {
              if (c1 < c2) 
                return -1;
              else 
                if (c1 > c2) {
                  return 1;
                }
            }
            else 
              if (c1 < 0 && c2 < 0) {
                if (c1 < c2) 
                  return -1;
                else 
                  if (c1 > c2) {
                    return 1;
                  }
              }
              else 
                if (c1 >= 0 && c2 < 0) 
                  return -1;
                else 
                  return 1;
          }
        }
=======
if (!aHasRemaining && bHasRemaining) {
        result = -1;
        break ;
      }
      else 
        if (aHasRemaining && bHasRemaining) {
          byte ca = a.get(a.position() + ia), cb = b.get(b.position() + ib);
          if (ca != cb) {
            if (ca >= 0 && cb >= 0) {
              if (ca < cb) {
                result = -1;
                break ;
              }
              else 
                if (ca > cb) {
                  result = 1;
                  break ;
                }
            }
            else 
              if (ca < 0 && cb < 0) {
                if (ca < cb) {
                  result = -1;
                  break ;
                }
                else 
                  if (ca > cb) {
                    result = 1;
                    break ;
                  }
              }
              else 
                if (ca >= 0 && cb < 0) {
                  result = -1;
                  break ;
                }
                else {
                  result = 1;
                  break ;
                }
          }
        }
        else 
          if (aHasRemaining && !bHasRemaining) {
            result = 1;
            break ;
          }
          else {
            result = 0;
            break ;
          }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java

      
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p1
=======
ia
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
++;
      
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p2
=======
ib
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
++;
    }
  }
----------------------------

############################

C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_base_472e913\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java,C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
TYPE
 SAME_POSITION 
----------------------------
JFSTMERGE_CONF
<EMPTY>
----------------------------
JDIME_CONF
<<<<<<< MINE
p2
=======
ib
>>>>>>> YOURS
----------------------------
JFSTMERGE_DECL
<EMPTY
----------------------------
JDIME_DECL
  public static final int compare(ByteBuffer b1, ByteBuffer b2) {
    if (b1 == b2) {
      return 0;
    }
    int ia = 0;
    int ib = 0;
    int 
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p1 = b1.position()
=======
result
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
, p2 = b2.position();
    while (p1 < b1.limit() || p2 < b2.limit()){
      boolean aHasRemaining = ia + a.position() < a.limit();
      boolean bHasRemaining = ib + b.position() < b.limit();
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
if (p1 >= b1.limit()) 
        return -1;
      else 
        if (p2 >= b2.limit()) 
          return 1;
        else {
          byte c1 = b1.get(), c2 = b2.get();
          if (c1 != c2) {
            if (c1 >= 0 && c2 >= 0) {
              if (c1 < c2) 
                return -1;
              else 
                if (c1 > c2) {
                  return 1;
                }
            }
            else 
              if (c1 < 0 && c2 < 0) {
                if (c1 < c2) 
                  return -1;
                else 
                  if (c1 > c2) {
                    return 1;
                  }
              }
              else 
                if (c1 >= 0 && c2 < 0) 
                  return -1;
                else 
                  return 1;
          }
        }
=======
if (!aHasRemaining && bHasRemaining) {
        result = -1;
        break ;
      }
      else 
        if (aHasRemaining && bHasRemaining) {
          byte ca = a.get(a.position() + ia), cb = b.get(b.position() + ib);
          if (ca != cb) {
            if (ca >= 0 && cb >= 0) {
              if (ca < cb) {
                result = -1;
                break ;
              }
              else 
                if (ca > cb) {
                  result = 1;
                  break ;
                }
            }
            else 
              if (ca < 0 && cb < 0) {
                if (ca < cb) {
                  result = -1;
                  break ;
                }
                else 
                  if (ca > cb) {
                    result = 1;
                    break ;
                  }
              }
              else 
                if (ca >= 0 && cb < 0) {
                  result = -1;
                  break ;
                }
                else {
                  result = 1;
                  break ;
                }
          }
        }
        else 
          if (aHasRemaining && !bHasRemaining) {
            result = 1;
            break ;
          }
          else {
            result = 0;
            break ;
          }
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java

      
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p1
=======
ia
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
++;
      
<<<<<<< C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_left_d90fe73\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
p2
=======
ib
>>>>>>> C:\Users\user\Desktop\gjcc\amostra\projects\titan\revisions\rev_d90fe73_2933976\rev_right_2933976\titan-core\src\main\java\com\thinkaurelius\titan\diskstorage\util\ByteBufferUtil.java
++;
    }
  }
----------------------------
